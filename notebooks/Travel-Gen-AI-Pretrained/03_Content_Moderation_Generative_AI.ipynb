{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15f81e3-0976-4ff7-8ae1-ddb5fbdf1d94",
   "metadata": {},
   "source": [
    "# Content moderation for generative AI applications\n",
    "\n",
    "As we've seen in these workshops, leveraging generative AI to generate creative content such as marketing copy and images can improve the quality of your messaging and provide a boost to productivity. However, turning over this important task to AI is not without risks. Most foundation models are trained and implemented with safeguards to prevent them from generating unsafe or inappropriate content. For example, you can read more about [\"Claude's Constitution\"](https://www.anthropic.com/index/claudes-constitution) which outlines the \"values\" that Anthropic built into the FM we used in the first notebook. In addition, Amazon Bedrock has its own [abuse detection](https://docs.aws.amazon.com/bedrock/latest/userguide/abuse-detection.html) layer on top of the FMs that it provides access to. Nevertheless, adding a moderation step to ensure that generated content remains consistent with the voice of your brand and does not inadvertently include any inappropriate themes or messages can add a layer of confidence to scaling generative AI across your organization. Content moderation can be implemented many different ways. For example, you could use a large language model to evaluate itself by building a prompt that expresses your standards and asks the model to evaluate text that it's generated against those standards. Or you can use separate AI models or services designed and tuned for classification tasks to check your work with generative AI.\n",
    "\n",
    "In this notebook, we will use another FM available in Amazon Bedrock, Titan Text Embeddings, to generate embeddings that will be used to train a classifier model. Embeddings are numerical representations of values or objects like text, images, and audio that can be fed to machine learning models. In this case, the model will be trained on examples of compliant and non-compliant text so that it is able to predict whether our text is compliant. \n",
    "\n",
    "For generated banner image, will take a different approach of using [Amazon Rekognition](https://aws.amazon.com/rekognition/) to identify unsafe/inappropriate in images.\n",
    "\n",
    "## Notebook overview\n",
    "\n",
    "We will complete the following steps in this notebook.\n",
    "\n",
    "1. Text moderation:\n",
    "    - Load and examine the labeled dataset of toxic and non-toxic text.\n",
    "    - Generate embeddings using the Amazon Titan Text Embedding model for all text values in the dataset.\n",
    "    - Split the dataset 80/20 into training and testing portions.\n",
    "    - Train a classifier model using the embeddings of the training data using the scikit-learn [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "    - Calculate and review metrics that measure the accuracy of the model's ability to propertly classify the text in the held-out test data.\n",
    "    - Finally, use the model to classify the email subject and email body that we generated in the previous notebook.\n",
    "1. Image moderation:\n",
    "    - Use the Amazon Rekognition [DetectModerationLabels](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectModerationLabels.html) API for a test image that we expect to return some moderation labels.\n",
    "    - Use the Amazon Rekognition [DetectModerationLabels](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectModerationLabels.html) API for the images we created in the previous notebook to ensure that no moderation labels are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc708a77-1dc2-4032-8a8c-5a85b6111dee",
   "metadata": {},
   "source": [
    "## Upgrade and install dependencies <a id=\"installdeps\"></a>\n",
    "\n",
    "Run the below cell to install/update Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdf603-a8a9-4888-92b8-b1eca9cc2aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade --no-deps --force-reinstall boto3\n",
    "!{sys.executable} -m pip install --upgrade --no-deps --force-reinstall botocore\n",
    "!{sys.executable} -m pip install --quiet \"pillow>=9.5,<10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd18cf",
   "metadata": {},
   "source": [
    "### Load variables\n",
    "\n",
    "Let's load the variables passed from the prior notebooks to we can access them in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81fac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdaa599",
   "metadata": {},
   "source": [
    "### Import dependencies\n",
    "\n",
    "Let's load some of the dependencies that we'll need for this notebook as well as print their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228be2a-b4b4-4862-b31f-f3294d14fbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Get the Boto3 version\n",
    "boto3_version = boto3.__version__\n",
    "\n",
    "# Get the Botocore version\n",
    "botocore_version = botocore.__version__\n",
    "\n",
    "# Print the Boto3 version\n",
    "print(\"Current Boto3 Version:\", boto3_version)\n",
    "\n",
    "# Print the Botocore version\n",
    "print(\"Current Botocore Version:\", botocore_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5530b40-b6df-4f51-a862-025ded60d513",
   "metadata": {},
   "source": [
    "### Initialize AWS service clients\n",
    "\n",
    "Let's initialize the boto3 client to use for S3 and Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d82998-f5d1-4624-a54f-f9d04422b8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "bedrock = boto3.client(\"bedrock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e292d-32b2-49ce-b1fb-066b70cc5cde",
   "metadata": {},
   "source": [
    "# Foundation models that generate embeddings from text\n",
    "\n",
    "Now we're ready to get started. Let's first ask Bedrock to list the foundation models that it currently supports with an output modality of embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10722be-2f83-4f8c-89a4-7d9b181029f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock.list_foundation_models(\n",
    "    byOutputModality = \"EMBEDDING\"\n",
    ")\n",
    "print(json.dumps(response[\"modelSummaries\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6903113",
   "metadata": {},
   "source": [
    "For this notebook, we will be using the \"Titan Embeddings G1 - Text\" model which has a modelId of `amazon.titan-embed-text-v1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616d517",
   "metadata": {},
   "source": [
    "## Prepare custom classification training dataset \n",
    "Download and unzip the sample data toxicity.zip to the local volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\n",
    "    \"personalize-solution-staging-us-east-1\", \n",
    "    \"personalize-immersionday-travel/toxicity.zip\", \n",
    "    data_dir + \"/toxicity.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c18329",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o $data_dir/toxicity.zip -d $data_dir/toxicity_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1d198",
   "metadata": {},
   "source": [
    "This CSV file contains 500 toxic and 500 non-toxic comments from a variety of popular social media platforms. Click on toxicity_en.csv to see a spreadsheet of 1000 English examples.\n",
    "\n",
    "Columns:\n",
    "- text: the text of the comment\n",
    "- is_toxic: whether or not the comment is toxic\n",
    "\n",
    "(The dataset contained in **$data_dir/toxicity.zip** is an unaltered redistribution of [the toxicity dataset](https://github.com/surge-ai/toxicity) made available by Surge AI under MIT License.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4caae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_df = pd.read_csv(data_dir + \"/toxicity_dataset/toxicity_en.csv\")\n",
    "toxicity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc4fa3-4196-4f4f-b85b-6b492beb8161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of toxic and not toxic labels\n",
    "toxicity_df[\"is_toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec00d8-8af4-49c1-8566-0fd865f6810d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5f862-9a08-4c85-a789-e34ff85cb69c",
   "metadata": {},
   "source": [
    "Embeddings are a key concept in generative AI and machine learning in general. An embedding is a representation of an object (like a word, image, video, etc.) in a vector space. Typically, semantically similar objects will have embeddings that are close together in the vector space. These are very powerful for use-cases like semantic search, recommendations, and classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a67abc-6541-4317-943a-95f7e353eeec",
   "metadata": {},
   "source": [
    "## Define embedding utility function\n",
    "\n",
    "The following function will generate and return an embedding for a piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6629f8e-3500-40e2-8154-c4844a57fd16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "def get_embedding(body, model_id, accept = \"application/json\", content_type = \"application/json\"):\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body.get('embedding')\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f467b0-2f52-46d5-8e57-0b13c0c76769",
   "metadata": {},
   "source": [
    "## Generate embedding vectors for labeled text dataset\n",
    "\n",
    "Next we'll generate embeddings for the labeled text in our dataset. This should take about 2 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d219c2c9-27c7-4a80-875d-d4c218119efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize a list to store the results\n",
    "embeddings = []\n",
    "\n",
    "model_id = \"amazon.titan-embed-text-v1\"\n",
    "\n",
    "print(f\"Generating embeddings for {len(toxicity_df)} labeled text\")\n",
    "\n",
    "for _,row in toxicity_df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    label = row[\"is_toxic\"]\n",
    "    \n",
    "    # Calculate the embedding for the text\n",
    "    body = json.dumps({\"inputText\": text})\n",
    "    embedding = get_embedding(body, model_id)\n",
    "\n",
    "    embeddings.append({\n",
    "        'label': label,\n",
    "        'embedding': embedding\n",
    "    })\n",
    "\n",
    "# The results can be saved to a file so they can be re-used later if necessary.\n",
    "with open('moderation_vectors.json', 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(embeddings, output_file, indent=2)\n",
    "\n",
    "print('Embedding vectors have been saved to moderation_vectors.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5059e-f8de-43e0-94cd-d19d87bf8a72",
   "metadata": {},
   "source": [
    "# Train classifier model\n",
    "\n",
    "With the embeddings generated, we can now train our classifier.\n",
    "\n",
    "## Split embeddings for training and evaluation\n",
    "\n",
    "So that we can evaluate the accuracy of the classifier we will split the dataset into training and test. We'll use an 80/20 split where we train on 80% of the data and test on the 20% that was held-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bba6e-eccf-4a07-8902-8bdafce1f0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the first 100 and last 100 records\n",
    "first_100_records = embeddings[:100]\n",
    "last_100_records = embeddings[-100:]\n",
    "\n",
    "# Create 'test.json' with the combined 200 records\n",
    "test_data = first_100_records + last_100_records\n",
    "with open('test.json', 'w') as test_file:\n",
    "    json.dump(test_data, test_file)\n",
    "\n",
    "# Create 'train.json' with the remaining 800 records\n",
    "train_data = embeddings[100:-100]\n",
    "with open('train.json', 'w') as train_file:\n",
    "    json.dump(train_data, train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb83f9-c3e9-4aeb-8b2c-62c1a1cdd8f3",
   "metadata": {},
   "source": [
    "### Training a model - RandomForestClassifier by embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759db9e6-c1d1-437f-b80b-ec7d3c0b6815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Extract features (embedding vectors) and labels from the datasets\n",
    "X_train = [data_point[\"embedding\"] for data_point in train_data]\n",
    "y_train = [data_point[\"label\"] for data_point in train_data]\n",
    "\n",
    "X_test = [data_point[\"embedding\"] for data_point in test_data]\n",
    "y_test = [data_point[\"label\"] for data_point in test_data]\n",
    "\n",
    "# Convert lists to numpy arrays for scikit-learn\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Build the classification model (Random Forest in this example)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate and print recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate and print F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Calculate and print ROC-AUC score (Note: ROC-AUC is typically used for binary classification)\n",
    "if len(np.unique(y_test)) == 2:  # Check if it's a binary classification problem\n",
    "    roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "# Print the detailed classification report\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_report_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76308f17-55cf-4caf-a60c-87488cdfec0f",
   "metadata": {},
   "source": [
    "### Save the trained classifier model\n",
    "\n",
    "The model can then be saved to a file so that it can be loaded later to perform inference. You can use the joblib library to save and load scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08aea5a-a698-40f8-afee-5e653fa53f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the model after training:\n",
    "from joblib import dump\n",
    "\n",
    "# Save the trained model to a file\n",
    "dump(clf, 'trained_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de89b2",
   "metadata": {},
   "source": [
    "Then if later you want to load the trained model, it can be loaded from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727022d6-51e2-4d99-9d8c-2c0bea2426ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the trained model from a file\n",
    "from joblib import load\n",
    "\n",
    "clf = load('trained_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935ee84",
   "metadata": {},
   "source": [
    "## Classify text using model\n",
    "\n",
    "We'll create a utility function to perform inference against the model. This function will generate an embedding for our input text and then use the model to predict the label for the text as well as predict probabilities for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text: str, model_id: str) -> (str, list):\n",
    "    embedding = get_embedding(json.dumps({\"inputText\": text}), model_id)\n",
    "    predicted_label = clf.predict([embedding])\n",
    "    probability_estimates = clf.predict_proba([embedding])\n",
    "    return predicted_label[0], probability_estimates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9b88c",
   "metadata": {},
   "source": [
    "### Classify sample text\n",
    "\n",
    "To test our classifier, let's test with a string that should be classified as `Toxic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classify_text(\"Why don''t you shoot him?! I hate you all!\", model_id)\n",
    "print(f\"Test string classification: {prediction[0]} with probability {prediction[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec139be",
   "metadata": {},
   "source": [
    "## Classify generated email subject and body\n",
    "\n",
    "Now let's try our our classifier on the generated email subject and body from the last notebook. First, we need to isolate the email subject and title from the generated response from the Claude Instant model. If you recall from the prompt in the last notebook, we asked Claude to place the email title/subject and body within XML tags. This instruction in the prompt allows us to more easily parse the response to separate these two pieces of content. To do so, we'll wrap the output in an outer `<email></email>` tag and then parse it as an XML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06203e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "root = ET.fromstring(\"<email>\" + email2 + \"</email>\")\n",
    "subject = root.find(\"email_title\").text.strip()\n",
    "body = root.find(\"email_body\").text.strip()\n",
    "\n",
    "print(f\"Email subject: {subject}\")\n",
    "print(f\"Email body: {body}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c5163",
   "metadata": {},
   "source": [
    "### Clasify email subject\n",
    "\n",
    "Let's start with the email subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classify_text(subject, model_id)\n",
    "print(f\"Email subject classification: {prediction[0]} with probability {prediction[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d200a77",
   "metadata": {},
   "source": [
    "### Clasify email body\n",
    "\n",
    "Now let's run the email body through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fafac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classify_text(body, model_id)\n",
    "print(f\"Email body classification: {prediction[0]} with probability {prediction[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d54ae7",
   "metadata": {},
   "source": [
    "# Moderate images\n",
    "\n",
    "Finally let's explore how we can add moderation for the images generated with foundation models like Stable Diffusion. We'll use the AWS AI service, [Amazon Rekognition](https://aws.amazon.com/rekognition/), for this task.\n",
    "\n",
    "## Moderate sample image\n",
    "We'll start with a sample image that should flag some suggestive content in an image. The image contains a lady in a bikini and Rekognition Image Moderation will label it as \"Suggestive\".\n",
    "\n",
    "Here is the sample image:\n",
    "\n",
    "![Moderate Image](images/yoga_swimwear.jpg \"Test image to moderate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db694f73",
   "metadata": {},
   "source": [
    "### Upload and moderate sample image\n",
    "\n",
    "Let's upload the image to our S3 bucket to stage it for moderation by Amazon Rekognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8efdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = 'content-moderation-im/image-moderation/yoga_swimwear.jpg'\n",
    "s3.upload_file(\"images/yoga_swimwear.jpg\", bucket_name, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ace965",
   "metadata": {},
   "source": [
    "Next we'll create an SDK client for Rekognition and call the [DetectModerationLabels](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectModerationLabels.html) API for our test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rekognition = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.detect_moderation_labels(\n",
    "    Image={\n",
    "       'S3Object': {\n",
    "           'Bucket': bucket_name,\n",
    "           'Name': s3_key,\n",
    "       }\n",
    "    }\n",
    ")\n",
    "print(json.dumps(response[\"ModerationLabels\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb0eac",
   "metadata": {},
   "source": [
    "Note the response from a call to DetectModerationLabels:\n",
    "\n",
    "- ModerationLabels – The example shows a list of labels for inappropriate or offensive content found in the image. The list includes the top-level label and each second-level label that are detected in the image. Please see Amazon Rekognition doucmentation for the complete list of supported top/second level labels.\n",
    "\n",
    "- Name/ParentName – Each label has a name, an estimation of the confidence that Amazon Rekognition has that the label is accurate, and the name of its parent label. The parent name for a top-level label is \"\".\n",
    "\n",
    "- Confidence – Each label has a confidence value between 0 and 100 that indicates the percentage confidence that Amazon Rekognition has that the label is correct. You specify the minimal confidence level for a label to be returned in the response in the API operation request.\n",
    "\n",
    "As we can see in the Rekognition response, the Image Moderation API labeled the image in 3 categories with confidence scores:\n",
    "\n",
    "- Top level category: Suggestive with a confidence score > 99%\n",
    "- Second level category: Female Swimwear Or Underwear with a confidence score > 99%\n",
    "- Second level category: Revealing Clothes with a confidence score > 89%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997dc63f",
   "metadata": {},
   "source": [
    "## Moderate email campaign banner images\n",
    "\n",
    "Now let's run the generated images from the last notebook through Rekognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(image_1_path)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = 'content-moderation-im/image-moderation/image_1.png'\n",
    "s3.upload_file(image_1_path, bucket_name, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.detect_moderation_labels(\n",
    "    Image={\n",
    "       'S3Object': {\n",
    "           'Bucket': bucket_name,\n",
    "           'Name': s3_key,\n",
    "       }\n",
    "    }\n",
    ")\n",
    "print(json.dumps(response[\"ModerationLabels\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f40b3",
   "metadata": {},
   "source": [
    "If there were no moderation labels returned (i.e., an empty list `[]`), then there were no findings from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_2_path)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ff68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = 'content-moderation-im/image-moderation/image_2.png'\n",
    "s3.upload_file(image_2_path, bucket_name, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rekognition.detect_moderation_labels(\n",
    "    Image={\n",
    "       'S3Object': {\n",
    "           'Bucket': bucket_name,\n",
    "           'Name': s3_key,\n",
    "       }\n",
    "    }\n",
    ")\n",
    "print(json.dumps(response[\"ModerationLabels\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38305af2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we illustrated how to train a random forest classifier model using embeddings generated using the Amazon Titan Text Embeddings FM from Amazon Bedrock. This model was then used to test the email subject and email body generated in the previous notebook for unsafe and inappropriate content. Then we used the AWS AI service [Amazon Rekognition](https://aws.amazon.com/rekognition/) to perform a similar analysis of the images we generated in the previous notebook. Adding a content moderation step to the use of generative AI can help safeguard against unsafe and inappropriate content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7844166",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "To clean up the Amazon Personalize resources created in the first notebook, you can execute the `04_Clean_Up` notebook. If you're running these notebooks as part of an AWS-led workshop where temporary AWS accounts are provided for you, this cleanup will be done automatically for you. Otherwise, if you're running this notebook in a personal or work account, be sure to run the `04-Clean_Up` notebook to shutdown resources that can create ongoing AWS charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf59dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
