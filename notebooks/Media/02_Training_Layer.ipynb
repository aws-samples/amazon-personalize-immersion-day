{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Evaluating Solutions <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "In this notebook, you will train several models using Amazon Personalize, specifically: \n",
    "\n",
    "1. User Personalization - what items are most relevant to a specific user.\n",
    "1. Similar Items - given an item, what items are similar to it.\n",
    "1. Personalized Ranking - given a user and a collection of items, in what order are they most releveant.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "1. [Create solutions](#solutions)\n",
    "1. [Evaluate solutions](#eval)\n",
    "1. [Using evaluation metrics](#use)\n",
    "1. [Storing useful variables](#vars)\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "To recap, the algorithms in Amazon Personalize (called recipes) look to solve different personalization use cases, explained here:\n",
    "\n",
    "- **User Personalization** - predicts the items that a user will interact with based on Interactions, Items, and Users datasets. If you are building a recommendation system that provides personalized recommendations for each of your users, you should train your model with a User Personalization recipe\n",
    "    - User-Personalization - The `aws-user-personalization` recipe is optimized for all personalized recommendation scenarios. It predicts the items that a user will interact with based on Interactions, Items, and Users datasets. When recommending items, it uses automatic item exploration.\n",
    "    - Popularity-Count - The `aws-popularity-count` recipe recommends the most popular item items based on all of your user behavioral data. The most popular items have the most interactions with unique users. The recipe returns the same popular items for all users.\n",
    "    - Legacy recipes - The functionality in the legacy `aws-hrnn`, `aws-hrnn-coldstart`, and `aws-hrnn-metadata` recipes has been unified and improved in the `aws-user-personalization` recipe. Therefore, it is recommended to use the `aws-user-personalization` recipe rather than the HRNN recipes.\n",
    "- **Personalized Ranking** - provides recommendations in ranked order based on predicted interest level.\n",
    "    - Personalized-Ranking - the `aws-personalized-ranking` recipe generates personalized rankings of items. A personalized ranking is a list of recommended items that are re-ranked for a specific user. This is useful if you have a collection of ordered items, such as search results, promotions, or curated lists, and you want to provide a personalized re-ranking for each of your users.\n",
    "- **Related Items** - recipes that return items similar to an item that you specify when you get recommendations\n",
    "    - Similar-Items - the `aws-similar-items` recipe generates recommendations for items that are similar to an item you specify. Similarity is calculated based on both interactions data and item metadata. Use Similar-Items when you have a catalog that includes many new items with item metadata but little to no interactions data.\n",
    "    - SIMS - the `aws-sims` recipe, or item-to-item similarities (SIMS) recipe, generates items similar to a given item based on the co-occurrence of the item in user history in your Interactions dataset. If sufficient user behavior data for an item isn't available, or if the specified item ID isn't found, the recipe returns popular items as recommendations. \n",
    "\n",
    "Regardless of the use case, the algorithms all share a base of learning on user-item-interaction data which is defined by 3 core attributes:\n",
    "\n",
    "1. **UserID** - The user who interacted\n",
    "1. **ItemID** - The item the user interacted with\n",
    "1. **Timestamp** - The time at which the interaction occurred\n",
    "\n",
    "We also support optional event types and event values defined by:\n",
    "\n",
    "1. **Event Type** - Categorical label of an event (clicked, purchased, rated, listened, watched, etc).\n",
    "1. **Event Value** - A numeric value corresponding to the event type that occurred. This value can be used to filter interactions that are included in model training by specifying a minimum threshold. For example, suppose you have an event type of `Rated` and the value is the user rating on a scale of 0 to 5. Since Personalize models on positive interactions, you can use an event value threshold of, say, 3 to only include interactions with an event type of `Rated` that have an event value of 3 or higher.\n",
    "\n",
    "The event type and event value fields are additional data which can be used to filter the data sent for training the personalization model. In this particular exercise we will not have an event type or event value (More information on how to use the eventValue with eventValueThreshold in the [documentation](https://docs.aws.amazon.com/personalize/latest/dg/recording-events.html)). \n",
    "\n",
    "To run this notebook, you need to have run the previous notebooks, `01_Data_Layer.ipynb`, where you created a dataset and imported interaction and item metadata data into Amazon Personalize. At the end of that notebook, you saved some of the variable values, which you now need to load into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create solutions <a class=\"anchor\" id=\"solutions\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "In this notebook, you will create solutions with the following recipes:\n",
    "\n",
    "1. User Personalization\n",
    "1. SIMS\n",
    "1. Personalized-Ranking\n",
    "\n",
    "The Popularity-Count recipe is the simplest solution available in Amazon Personalize and it should only be used as a fallback, so it will also not be covered in this notebook.\n",
    "\n",
    "Similar to the previous notebook, start by importing the relevant packages, and set up a connection to Amazon Personalize using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Amazon Personalize, a specific variation of an algorithm is called a recipe. Different recipes are suitable for different situations. A trained model is called a solution, and each solution can have many versions that relate to a given volume of data when the model was trained.\n",
    "\n",
    "To start, we will list all the recipes that are supported. This will allow you to select one and use that to build your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipes': [{'name': 'aws-hrnn',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2021, 1, 5, 0, 8, 53, 800000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-coldstart',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-coldstart',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2021, 1, 5, 0, 8, 53, 800000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-metadata',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-metadata',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2021, 1, 5, 0, 8, 53, 800000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-personalized-ranking',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-personalized-ranking',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2021, 1, 5, 0, 8, 53, 800000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-popularity-count',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-popularity-count',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2021, 1, 5, 0, 8, 53, 800000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-sims',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-sims',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2021, 1, 5, 0, 8, 53, 800000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-user-personalization',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-user-personalization',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2021, 1, 5, 0, 8, 53, 800000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': 'adcc50f9-cf7c-4ee6-bb86-b3463f67c839',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Fri, 29 Jan 2021 20:03:07 GMT',\n",
       "   'x-amzn-requestid': 'adcc50f9-cf7c-4ee6-bb86-b3463f67c839',\n",
       "   'content-length': '1245',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalize.list_recipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is just a JSON representation of all of the algorithms mentioned in the introduction.\n",
    "\n",
    "Next we will select specific recipes and build models with them.\n",
    "\n",
    "### User Personalization\n",
    "The User-Personalization (aws-user-personalization) recipe is optimized for all USER_PERSONALIZATION recommendation scenarios. When recommending items, it uses automatic item exploration.\n",
    "\n",
    "With automatic exploration, Amazon Personalize automatically tests different item recommendations, learns from how users interact with these recommended items, and boosts recommendations for items that drive better engagement and conversion. This improves item discovery and engagement when you have a fast-changing catalog, or when new items, such as news articles or promotions, are more relevant to users when fresh.\n",
    "\n",
    "You can balance how much to explore (where items with less interactions data or relevance are recommended more frequently) against how much to exploit previous interactions (where recommendations are based on what we know or relevance). Amazon Personalize automatically adjusts future recommendations based on implicit user feedback.\n",
    "\n",
    "First, select the recipe by finding the ARN in the list of recipes above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_personalization_recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the solution\n",
    "\n",
    "First you create a solution using the recipe. Although you provide the dataset ARN in this step, the model is not yet trained. See this as an identifier instead of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_personalization_create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-poc-userpersonalization\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = user_personalization_recipe_arn\n",
    ")\n",
    "\n",
    "user_personalization_solution_arn = user_personalization_create_solution_response['solutionArn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-userpersonalization\"\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(user_personalization_solution_arn, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the solution version\n",
    "\n",
    "Once you have a solution, you need to create a version in order to complete the model training. The training can take a while to complete, upwards of 25 minutes, and an average of 90 minutes for this recipe with our dataset. Normally, we would use a while loop to poll until the task is completed. However the task would block other cells from executing, and the goal here is to create many models and deploy them quickly. So we will set up the while loop for all of the solutions further down in the notebook. There, you will also find instructions for viewing the progress in the AWS console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "userpersonalization_create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = user_personalization_solution_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-userpersonalization\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"932aeb2f-d9be-4611-8bb8-5227f1696de2\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 20:14:15 GMT\",\n",
      "      \"x-amzn-requestid\": \"932aeb2f-d9be-4611-8bb8-5227f1696de2\",\n",
      "      \"content-length\": \"105\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "userpersonalization_solution_version_arn = userpersonalization_create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(userpersonalization_create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMS\n",
    "\n",
    "\n",
    "SIMS is one of the oldest algorithms used within Amazon for recommendation systems. A core use case for it is when you have one item and you want to recommend items that have been interacted with in similar ways over your entire user base. This means the result is not personalized per user. Sometimes this leads to recommending mostly popular items, so there is a hyperparameter ([popularity_discount_factor](https://docs.aws.amazon.com/personalize/latest/dg/native-recipe-sims.html)) that can be tweaked which will reduce the popular items in your results. \n",
    "\n",
    "For our use case, using the Movielens data, let's assume we pick a particular movie. We can then use SIMS to recommend other movies based on the interaction behavior of the entire user base. The results are not personalized per user, but instead, differ depending on the movie we chose as our input.\n",
    "\n",
    "Just like last time, we start by selecting the recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMS_recipe_arn = \"arn:aws:personalize:::recipe/aws-sims\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the solution\n",
    "\n",
    "As with User Personalization, start by creating the solution first. Although you provide the dataset ARN in this step, the model is not yet trained. See this as an identifier instead of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-sims\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"e329c7d2-5e16-4b4a-9ad9-9859864a1624\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 20:14:26 GMT\",\n",
      "      \"x-amzn-requestid\": \"e329c7d2-5e16-4b4a-9ad9-9859864a1624\",\n",
      "      \"content-length\": \"90\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sims_create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-poc-sims\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = SIMS_recipe_arn\n",
    ")\n",
    "\n",
    "sims_solution_arn = sims_create_solution_response['solutionArn']\n",
    "print(json.dumps(sims_create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the solution version\n",
    "\n",
    "Once you have a solution, you need to create a version in order to complete the model training. The training can take a while to complete, upwards of 25 minutes, and an average of 35 minutes for this recipe with our dataset. Normally, we would use a while loop to poll until the task is completed. However the task would block other cells from executing, and the goal here is to create many models and deploy them quickly. So we will set up the while loop for all of the solutions further down in the notebook. There, you will also find instructions for viewing the progress in the AWS console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = sims_solution_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-sims/43c1eddf\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"9eaaa908-6b99-49b6-a075-5e8b48258e3f\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 20:14:28 GMT\",\n",
      "      \"x-amzn-requestid\": \"9eaaa908-6b99-49b6-a075-5e8b48258e3f\",\n",
      "      \"content-length\": \"106\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sims_solution_version_arn = sims_create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(sims_create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personalized Ranking\n",
    "\n",
    "Personalized Ranking is an interesting application of HRNN. Instead of just recommending what is most probable for the user in question, this algorithm takes in a list of items as well as a user. The items are then returned back in the order of most probable relevance for the user. The use case here is for filtering on unique categories that you do not have item metadata to create a filter, or when you have a broad collection that you would like better ordered for a particular user.\n",
    "\n",
    "For our use case, using the MovieLens data, we could imagine that a Video on Demand application may want to create a shelf of comic book movies, or movies by a specific director. We can generate these lists based on metadata we have. We would use personalized ranking to re-order the list of movies for each user. \n",
    "\n",
    "Just like last time, we start by selecting the recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_recipe_arn = \"arn:aws:personalize:::recipe/aws-personalized-ranking\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the solution\n",
    "\n",
    "As with the previous solution, start by creating the solution first. Although you provide the dataset ARN in this step, the model is not yet trained. See this as an identifier instead of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-rerank\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"98878e7a-1de9-4faf-8944-2aa68ef310e6\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 20:14:34 GMT\",\n",
      "      \"x-amzn-requestid\": \"98878e7a-1de9-4faf-8944-2aa68ef310e6\",\n",
      "      \"content-length\": \"92\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rerank_create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-poc-rerank\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = rerank_recipe_arn\n",
    ")\n",
    "\n",
    "rerank_solution_arn = rerank_create_solution_response['solutionArn']\n",
    "print(json.dumps(rerank_create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the solution version\n",
    "\n",
    "Once you have a solution, you need to create a version in order to complete the model training. The training can take a while to complete, upwards of 25 minutes, and an average of 35 minutes for this recipe with our dataset. Normally, we would use a while loop to poll until the task is completed. However the task would block other cells from executing, and the goal here is to create many models and deploy them quickly. So we will set up the while loop for all of the solutions further down in the notebook. There, you will also find instructions for viewing the progress in the AWS console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = rerank_solution_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-rerank/ab00b6fb\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"2b4c6e17-8987-4140-98d3-cc921abfbb1f\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 20:14:37 GMT\",\n",
      "      \"x-amzn-requestid\": \"2b4c6e17-8987-4140-98d3-cc921abfbb1f\",\n",
      "      \"content-length\": \"108\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rerank_solution_version_arn = rerank_create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(rerank_create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View solution creation status\n",
    "\n",
    "As promised, how to view the status updates in the console:\n",
    "\n",
    "* In another browser tab you should already have the AWS Console up from opening this notebook instance. \n",
    "* Switch to that tab and search at the top for the service `Personalize`, then go to that service page. \n",
    "* Click `View dataset groups`.\n",
    "* Click the name of your dataset group, most likely something with POC in the name.\n",
    "* Click `Solutions and recipes`.\n",
    "* You will now see a list of all of the solutions you created above,  including a column with the status of the solution versions. Once it is `Active`, your solution is ready to be reviewed. It is also capable of being deployed.\n",
    "\n",
    "Or simply run the cell below to keep track of the solution version creation status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "Build succeeded for arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-sims/43c1eddf\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "At least one solution build is still in progress\n",
      "Build succeeded for arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-userpersonalization/4078e9b0\n",
      "At least one solution build is still in progress\n",
      "Build succeeded for arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-rerank/ab00b6fb\n"
     ]
    }
   ],
   "source": [
    "in_progress_solution_versions = [\n",
    "    userpersonalization_solution_version_arn,\n",
    "    sims_solution_version_arn,\n",
    "    rerank_solution_version_arn\n",
    "]\n",
    "\n",
    "max_time = time.time() + 10*60*60 # 10 hours\n",
    "while time.time() < max_time:\n",
    "    for solution_version_arn in in_progress_solution_versions:\n",
    "        version_response = personalize.describe_solution_version(\n",
    "            solutionVersionArn = solution_version_arn\n",
    "        )\n",
    "        status = version_response[\"solutionVersion\"][\"status\"]\n",
    "        \n",
    "        if status == \"ACTIVE\":\n",
    "            print(\"Build succeeded for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "        elif status == \"CREATE FAILED\":\n",
    "            print(\"Build failed for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "    \n",
    "    if len(in_progress_solution_versions) <= 0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"At least one solution build is still in progress\")\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "Personalize offers the option of running hyperparameter tuning when creating a solution. Because of the additional computation required to perform hyperparameter tuning, this feature is turned off by default. Therefore, the solutions we created above, will simply use the default values of the hyperparameters for each recipe. For more information about hyperparameter tuning, see the [documentation](https://docs.aws.amazon.com/personalize/latest/dg/customizing-solution-config-hpo.html).\n",
    "\n",
    "If you have settled on the correct recipe to use, and are ready to run hyperparameter tuning, the following code shows how you would do so, using SIMS as an example.\n",
    "\n",
    "```python\n",
    "sims_create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-poc-sims-hpo\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = SIMS_recipe_arn,\n",
    "    performHPO=True\n",
    ")\n",
    "\n",
    "sims_solution_arn = sims_create_solution_response['solutionArn']\n",
    "print(json.dumps(sims_create_solution_response, indent=2))\n",
    "```\n",
    "\n",
    "If you already know the values you want to use for a specific hyperparameter, you can also set this value when you create the solution. The code below shows how you could set the value for the `popularity_discount_factor` for the SIMS recipe.\n",
    "\n",
    "```python\n",
    "sims_create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-poc-sims-set-hp\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = SIMS_recipe_arn,\n",
    "    solutionConfig = {\n",
    "        'algorithmHyperParameters': {\n",
    "            'popularity_discount_factor': '0.7'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "sims_solution_arn = sims_create_solution_response['solutionArn']\n",
    "print(json.dumps(sims_create_solution_response, indent=2))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate solution versions <a class=\"anchor\" id=\"eval\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "It should not take more than an hour to train all the solutions from this notebook. While training is in progress, we recommend taking the time to read up on the various algorithms (recipes) and their behavior in detail. This is also a good time to consider alternatives to how the data was fed into the system and what kind of results you expect to see.\n",
    "\n",
    "When the solutions finish creating, the next step is to obtain the evaluation metrics. Personalize calculates these metrics based on a subset of the training data. The image below illustrates how Personalize splits the data. Given 10 users, with 10 interactions each (a circle represents an interaction), the interactions are ordered from oldest to newest based on the timestamp. Personalize uses all of the interaction data from 90% of the users (blue circles) to train the solution version, and the remaining 10% for evaluation. For each of the users in the remaining 10%, 90% of their interaction data (green circles) is used as input for the call to the trained model. The remaining 10% of their data (orange circle) is compared to the output produced by the model and used to calculate the evaluation metrics.\n",
    "\n",
    "![personalize metrics](../../static/imgs/personalize_metrics.png)\n",
    "\n",
    "We recommend reading [the documentation](https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html) to understand the metrics, but we have also copied parts of the documentation below for convenience.\n",
    "\n",
    "You need to understand the following terms regarding evaluation in Personalize:\n",
    "\n",
    "* *Relevant recommendation* refers to a recommendation that matches a value in the testing data for the particular user.\n",
    "* *Rank* refers to the position of a recommended item in the list of recommendations. Position 1 (the top of the list) is presumed to be the most relevant to the user.\n",
    "* *Query* refers to the internal equivalent of a GetRecommendations call.\n",
    "\n",
    "The metrics produced by Personalize are:\n",
    "* **coverage**: The proportion of unique recommended items from all queries out of the total number of unique items in the training data (includes both the Items and Interactions datasets).\n",
    "* **mean_reciprocal_rank_at_25**: The [mean of the reciprocal ranks](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) of the first relevant recommendation out of the top 25 recommendations over all queries. This metric is appropriate if you're interested in the single highest ranked recommendation.\n",
    "* **normalized_discounted_cumulative_gain_at_K**: Discounted gain assumes that recommendations lower on a list of recommendations are less relevant than higher recommendations. Therefore, each recommendation is discounted (given a lower weight) by a factor dependent on its position. To produce the [cumulative discounted gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) at K, each relevant discounted recommendation in the top K recommendations is summed together. The normalized discounted cumulative gain (NDCG) is the DCG divided by the ideal DCG such that NDCG is between 0 - 1. (The ideal DCG is where the top K recommendations are sorted by relevance.) Amazon Personalize uses a weighting factor of 1/log(1 + position), where the top of the list is position 1. This metric rewards relevant items that appear near the top of the list, because the top of a list usually draws more attention.\n",
    "* **precision_at_K**: The number of relevant recommendations out of the top K recommendations divided by K. This metric rewards precise recommendation of the relevant items.\n",
    "\n",
    "Let's take a look at the evaluation metrics for each of the solutions produced in this notebook. Please note that your results might differ from the results described in the text of this notebook, due to the quality of the Movielens dataset. \n",
    "\n",
    "### User Personalization metrics\n",
    "\n",
    "First, retrieve the evaluation metrics for the User Personalization solution version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-userpersonalization/4078e9b0\",\n",
      "  \"metrics\": {\n",
      "    \"coverage\": 0.0772,\n",
      "    \"mean_reciprocal_rank_at_25\": 0.2879,\n",
      "    \"normalized_discounted_cumulative_gain_at_10\": 0.3109,\n",
      "    \"normalized_discounted_cumulative_gain_at_25\": 0.3537,\n",
      "    \"normalized_discounted_cumulative_gain_at_5\": 0.2794,\n",
      "    \"precision_at_10\": 0.0571,\n",
      "    \"precision_at_25\": 0.0321,\n",
      "    \"precision_at_5\": 0.0821\n",
      "  },\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"349c6847-5364-4501-8692-a39847878633\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 21:00:54 GMT\",\n",
      "      \"x-amzn-requestid\": \"349c6847-5364-4501-8692-a39847878633\",\n",
      "      \"content-length\": \"419\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_personalization_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = userpersonalization_solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(user_personalization_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized discounted cumulative gain above tells us that at 5 items, we have less than a (38% for full 22% for small) chance in a recommendation being a part of a user's interaction history (in the hold out phase from training and validation). Around 13% of the recommended items are unique, and we have a precision of only (14% for full, 7.5% for small) in the top 5 recommended items. \n",
    "\n",
    "This is clearly not a great model, but keep in mind that we had to use rating data for our interactions because Movielens is an explicit dataset based on ratings. The Timestamps also were from the time that the movie was rated, not watched, so the order is not the same as the order a viewer would watch movies.\n",
    "\n",
    "### SIMS metrics\n",
    "\n",
    "Now, retrieve the evaluation metrics for the SIMS solution version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-sims/43c1eddf\",\n",
      "  \"metrics\": {\n",
      "    \"coverage\": 0.1858,\n",
      "    \"mean_reciprocal_rank_at_25\": 0.1682,\n",
      "    \"normalized_discounted_cumulative_gain_at_10\": 0.2278,\n",
      "    \"normalized_discounted_cumulative_gain_at_25\": 0.2939,\n",
      "    \"normalized_discounted_cumulative_gain_at_5\": 0.1869,\n",
      "    \"precision_at_10\": 0.0618,\n",
      "    \"precision_at_25\": 0.0429,\n",
      "    \"precision_at_5\": 0.0794\n",
      "  },\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"21bea9f7-129f-4bd3-9cab-beba23679976\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 21:00:56 GMT\",\n",
      "      \"x-amzn-requestid\": \"21bea9f7-129f-4bd3-9cab-beba23679976\",\n",
      "      \"content-length\": \"404\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sims_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = sims_solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(sims_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are seeing a slightly elevated precision at 5 items, a little over (4.5% for full, 6.4% for small) this time. Effectively this is probably within the margin of error, but given that no effort was made to mask popularity, it may just be returning super popular results that a large volume of users have interacted with in some way. \n",
    "\n",
    "### Personalized ranking metrics\n",
    "\n",
    "Now, retrieve the evaluation metrics for the personalized ranking solution version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:832194813872:solution/personalize-poc-rerank/ab00b6fb\",\n",
      "  \"metrics\": {\n",
      "    \"coverage\": 0.1091,\n",
      "    \"mean_reciprocal_rank_at_25\": 0.1428,\n",
      "    \"normalized_discounted_cumulative_gain_at_10\": 0.1823,\n",
      "    \"normalized_discounted_cumulative_gain_at_25\": 0.2514,\n",
      "    \"normalized_discounted_cumulative_gain_at_5\": 0.1599,\n",
      "    \"precision_at_10\": 0.0321,\n",
      "    \"precision_at_25\": 0.0272,\n",
      "    \"precision_at_5\": 0.0491\n",
      "  },\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"0f9ded34-6eb6-41d0-84f9-4530bc605e90\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 21:01:00 GMT\",\n",
      "      \"x-amzn-requestid\": \"0f9ded34-6eb6-41d0-84f9-4530bc605e90\",\n",
      "      \"content-length\": \"406\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rerank_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = rerank_solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(rerank_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick comment on this one, here we see again a precision of near (2.7% for full, 2.2% for small), as this is based on User Personalization, that is to be expected. However the sample items are not the same items used for validaiton, thus the low scoring.\n",
    "\n",
    "## Using evaluation metrics <a class=\"anchor\" id=\"use\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "It is important to use evaluation metrics carefully. There are a number of factors to keep in mind.\n",
    "\n",
    "* If there is an existing recommendation system in place, this will have influenced the user's interaction history which you use to train your new solutions. This means the evaluation metrics are biased to favor the existing solution. If you work to push the evaluation metrics to match or exceed the existing solution, you may just be pushing the User Personalization to behave like the existing solution and might not end up with something better.\n",
    "* The HRNN Coldstart recipe is difficult to evaluate using the metrics produced by Amazon Personalize. The aim of the recipe is to recommend items which are new to your business. Therefore, these items will not appear in the existing user transaction data which is used to compute the evaluation metrics. As a result, HRNN Coldstart will never appear to perform better than the other recipes, when compared on the evaluation metrics alone. Note: The User Personalization recipe also includes improved cold start functionality\n",
    "\n",
    "Keeping in mind these factors, the evaluation metrics produced by Personalize are generally useful for two cases:\n",
    "1. Comparing the performance of solution versions trained on the same recipe, but with different values for the hyperparameters and features (impression data etc)\n",
    "1. Comparing the performance of solution versions trained on different recipes (except HRNN Coldstart). Here also keep in mind that the recipes answer different use cases and comparing them to each other might not make sense in your solution.\n",
    "\n",
    "Properly evaluating a recommendation system is always best done through A/B testing while measuring actual business outcomes. Since recommendations generated by a system usually influence the user behavior which it is based on, it is better to run small experiments and apply A/B testing for longer periods of time. Over time, the bias from the existing model will fade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Campaigns and Filters<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "In this notebook, you will deploy and interact with campaigns in Amazon Personalize.\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "1. [Create campaigns](#create)\n",
    "1. [Interact with campaigns](#interact)\n",
    "1. [Batch recommendations](#batch)\n",
    "1. [Wrap up](#wrapup)\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "At this point, you should have several solutions and at least one solution version for each. Once a solution version is created, it is possible to get recommendations from them, and to get a feel for their overall behavior.\n",
    "\n",
    "This notebook starts off by deploying each of the solution versions from the previous notebook into individual campaigns. Once they are active, there are resources for querying the recommendations, and helper functions to digest the output into something more human-readable. \n",
    "\n",
    "As you with your customer on Amazon Personalize, you can modify the helper functions to fit the structure of their data input files to keep the additional rendering working.\n",
    "\n",
    "To get started, once again, we need to import libraries, load values from previous notebooks, and load the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "# Establish a connection to Personalize's event streaming\n",
    "personalize_events = boto3.client(service_name='personalize-events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create campaigns <a class=\"anchor\" id=\"create\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "A campaign is a hosted solution version; an endpoint which you can query for recommendations. Pricing is set by estimating throughput capacity (requests from users for personalization per second). When deploying a campaign, you set a minimum throughput per second (TPS) value. This service, like many within AWS, will automatically scale based on demand, but if latency is critical, you may want to provision ahead for larger demand. For this POC and demo, all minimum throughput thresholds are set to 1. For more information, see the [pricing page](https://aws.amazon.com/personalize/pricing/).\n",
    "\n",
    "Let's start deploying the campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Personalization\n",
    "\n",
    "Deploy a campaign for your User Personalization solution version. It can take around 10 minutes to deploy a campaign. Normally, we would use a while loop to poll until the task is completed. However the task would block other cells from executing, and the goal here is to create multiple campaigns. So we will set up the while loop for all of the campaigns further down in the notebook. There, you will also find instructions for viewing the progress in the AWS console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"campaignArn\": \"arn:aws:personalize:us-east-1:832194813872:campaign/personalize-poc-userpersonalization\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"a76d9f06-e1dd-4e55-89ae-4e047b2cac87\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 21:01:18 GMT\",\n",
      "      \"x-amzn-requestid\": \"a76d9f06-e1dd-4e55-89ae-4e047b2cac87\",\n",
      "      \"content-length\": \"105\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "userpersonalization_create_campaign_response = personalize.create_campaign(\n",
    "    name = \"personalize-poc-userpersonalization\",\n",
    "    solutionVersionArn = userpersonalization_solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "userpersonalization_campaign_arn = userpersonalization_create_campaign_response['campaignArn']\n",
    "print(json.dumps(userpersonalization_create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMS\n",
    "\n",
    "Deploy a campaign for your SIMS solution version. It can take around 10 minutes to deploy a campaign. Normally, we would use a while loop to poll until the task is completed. However the task would block other cells from executing, and the goal here is to create multiple campaigns. So we will set up the while loop for all of the campaigns further down in the notebook. There, you will also find instructions for viewing the progress in the AWS console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"campaignArn\": \"arn:aws:personalize:us-east-1:832194813872:campaign/personalize-poc-SIMS\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"e2b3b7d0-76d1-4f53-b54c-30325389cf61\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 21:01:20 GMT\",\n",
      "      \"x-amzn-requestid\": \"e2b3b7d0-76d1-4f53-b54c-30325389cf61\",\n",
      "      \"content-length\": \"90\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sims_create_campaign_response = personalize.create_campaign(\n",
    "    name = \"personalize-poc-SIMS\",\n",
    "    solutionVersionArn = sims_solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "sims_campaign_arn = sims_create_campaign_response['campaignArn']\n",
    "print(json.dumps(sims_create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personalized Ranking\n",
    "\n",
    "Deploy a campaign for your personalized ranking solution version. It can take around 10 minutes to deploy a campaign. Normally, we would use a while loop to poll until the task is completed. However the task would block other cells from executing, and the goal here is to create multiple campaigns. So we will set up the while loop for all of the campaigns further down in the notebook. There, you will also find instructions for viewing the progress in the AWS console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"campaignArn\": \"arn:aws:personalize:us-east-1:832194813872:campaign/personalize-poc-rerank\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"efb219b6-ca5a-4a1e-a3ff-11cf2d38271c\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Mon, 01 Feb 2021 21:01:23 GMT\",\n",
      "      \"x-amzn-requestid\": \"efb219b6-ca5a-4a1e-a3ff-11cf2d38271c\",\n",
      "      \"content-length\": \"92\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rerank_create_campaign_response = personalize.create_campaign(\n",
    "    name = \"personalize-poc-rerank\",\n",
    "    solutionVersionArn = rerank_solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "rerank_campaign_arn = rerank_create_campaign_response['campaignArn']\n",
    "print(json.dumps(rerank_create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View campaign creation status\n",
    "\n",
    "As promised, this is how you view the status updates in the console:\n",
    "\n",
    "* In another browser tab you should already have the AWS Console open from opening this notebook instance. \n",
    "* Switch to that tab and search at the top for the service `Personalize`, then go to that service page. \n",
    "* Click `View dataset groups`.\n",
    "* Click the name of your dataset group, most likely something with POC in the name.\n",
    "* Click `Campaigns`.\n",
    "* You will now see a list of all of the campaigns you created above, including a column with the status of the campaign. Once it is `Active`, your campaign is ready to be queried.\n",
    "\n",
    "Or simply run the cell below to keep track of the campaign creation status of the 3 campaigns we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one campaign build is still in progress\n",
      "At least one campaign build is still in progress\n",
      "At least one campaign build is still in progress\n",
      "At least one campaign build is still in progress\n",
      "At least one campaign build is still in progress\n",
      "At least one campaign build is still in progress\n",
      "At least one campaign build is still in progress\n",
      "At least one campaign build is still in progress\n",
      "Build succeeded for arn:aws:personalize:us-east-1:832194813872:campaign/personalize-poc-SIMS\n",
      "At least one campaign build is still in progress\n",
      "Build succeeded for arn:aws:personalize:us-east-1:832194813872:campaign/personalize-poc-rerank\n",
      "At least one campaign build is still in progress\n",
      "Build succeeded for arn:aws:personalize:us-east-1:832194813872:campaign/personalize-poc-userpersonalization\n"
     ]
    }
   ],
   "source": [
    "in_progress_campaigns = [\n",
    "    userpersonalization_campaign_arn,\n",
    "    sims_campaign_arn,\n",
    "    rerank_campaign_arn\n",
    "]\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    for campaign_arn in in_progress_campaigns:\n",
    "        version_response = personalize.describe_campaign(\n",
    "            campaignArn = campaign_arn\n",
    "        )\n",
    "        status = version_response[\"campaign\"][\"status\"]\n",
    "        \n",
    "        if status == \"ACTIVE\":\n",
    "            print(\"Build succeeded for {}\".format(campaign_arn))\n",
    "            in_progress_campaigns.remove(campaign_arn)\n",
    "        elif status == \"CREATE FAILED\":\n",
    "            print(\"Build failed for {}\".format(campaign_arn))\n",
    "            in_progress_campaigns.remove(campaign_arn)\n",
    "    \n",
    "    if len(in_progress_campaigns) <= 0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"At least one campaign build is still in progress\")\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Static Filters <a class=\"anchor\" id=\"interact\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Now that all campaigns are deployed and active, we can create filters. Filters can be created for fields of both Items and Events. Filters can also be created dynamically for \"IN\" and \"=\" operations. For range queries, you should use static filters. \n",
    "Range queries use the following operations: NOT IN, <, >, <=, and >=.\n",
    "\n",
    "A few common use cases for static filters in Video On Demand are:\n",
    "\n",
    "Categorical filters based on Item Metadata (that are range based) - Often your item metadata will have information about the title such as year, user rating, available date. Filtering on these can provide recommendations within that data, such as movies that are available after a specific date, movies rated over 3 stars, movies from the 1990s etc.\n",
    "\n",
    "User Demographic ranges - you may want to recommend content to specific age demographics, for this you can create a filter that is specific to a age range like over 18, over 18 AND under 30, etc).\n",
    "\n",
    "Lets look at the item metadata and user interactions, so we can get an idea what type of filters we can create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENRE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CREATION_TIMESTAMP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adventure|Children</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Action</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               GENRE  YEAR  CREATION_TIMESTAMP\n",
       "ITEM_ID                                                                       \n",
       "1        Adventure|Animation|Children|Comedy|Fantasy  1995                   0\n",
       "2                         Adventure|Children|Fantasy  1995                   0\n",
       "3                                     Comedy|Romance  1995                   0\n",
       "4                               Comedy|Drama|Romance  1995                   0\n",
       "5                                             Comedy  1995                   0\n",
       "6                              Action|Crime|Thriller  1995                   0\n",
       "7                                     Comedy|Romance  1995                   0\n",
       "8                                 Adventure|Children  1995                   0\n",
       "9                                             Action  1995                   0\n",
       "10                         Action|Adventure|Thriller  1995                   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe for the items by reading in the correct source CSV\n",
    "items_meta_df = pd.read_csv(data_dir + '/item-meta.csv', sep=',', index_col=0)\n",
    "\n",
    "# Render some sample data\n",
    "items_meta_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a lot of genres to filter on, we will create a dynamic filter using the dynamic variable $GENRE, this will allow us to pass in the variable at runtime rather than create a static filter for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "creategenrefilter_response = personalize.create_filter(name='Genre',\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    filterExpression='INCLUDE ItemID WHERE Items.GENRE IN ($GENRE)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_filter_arn = creategenrefilter_response['filterArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have added the year to our item metadata, lets create a decade filter to recommend only movies released in a given decade. A soft limit of Personalize at this time is 10 total filters, so we will create 7 decade filters for this workshop, leaving room for additional static and dynamic filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list for the metadata decade filters and then create the actual filters with the cells below. Note this will take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades_to_filter = [1950,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for the filters:\n",
    "meta_filter_decade_arns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: arn:aws:personalize:us-east-1:832194813872:filter/1950s\n",
      "Creating: arn:aws:personalize:us-east-1:832194813872:filter/1960s\n",
      "Creating: arn:aws:personalize:us-east-1:832194813872:filter/1970s\n",
      "Creating: arn:aws:personalize:us-east-1:832194813872:filter/1980s\n",
      "Creating: arn:aws:personalize:us-east-1:832194813872:filter/1990s\n",
      "Creating: arn:aws:personalize:us-east-1:832194813872:filter/2000s\n",
      "Creating: arn:aws:personalize:us-east-1:832194813872:filter/2010s\n"
     ]
    }
   ],
   "source": [
    "# Iterate through Genres\n",
    "for decade in decades_to_filter:\n",
    "    # Start by creating a filter\n",
    "    current_decade = str(decade)\n",
    "    next_decade = str(decade + 10)\n",
    "    try:\n",
    "        createfilter_response = personalize.create_filter(\n",
    "            name=current_decade + \"s\",\n",
    "            datasetGroupArn=dataset_group_arn,\n",
    "            filterExpression='INCLUDE ItemID WHERE Items.YEAR >= '+ current_decade +' AND Items.YEAR < '+ next_decade +''\n",
    "    )\n",
    "        # Add the ARN to the list\n",
    "        meta_filter_decade_arns.append(createfilter_response['filterArn'])\n",
    "        print(\"Creating: \" + createfilter_response['filterArn'])\n",
    "    \n",
    "    # If this fails, wait a bit\n",
    "    except ClientError as error:\n",
    "        # Here we only care about raising if it isnt the throttling issue\n",
    "        if error.response['Error']['Code'] != 'LimitExceededException':\n",
    "            print(error)\n",
    "        else:    \n",
    "            time.sleep(120)\n",
    "            createfilter_response = personalize.create_filter(\n",
    "                name=current_decade + \"s\",\n",
    "                datasetGroupArn=dataset_group_arn,\n",
    "                filterExpression='INCLUDE ItemID WHERE Items.YEAR >= '+ current_decade +' AND Items.YEAR < '+ next_decade +''\n",
    "    )\n",
    "            # Add the ARN to the list\n",
    "            meta_filter_decade_arns.append(createfilter_response['filterArn'])\n",
    "            print(\"Creating: \" + createfilter_response['filterArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also create 2 event filters for watched and unwatched content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USER_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>222</td>\n",
       "      <td>828124615</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>227</td>\n",
       "      <td>828124615</td>\n",
       "      <td>click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>595</td>\n",
       "      <td>828124615</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>592</td>\n",
       "      <td>828124615</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>590</td>\n",
       "      <td>828124615</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>434</td>\n",
       "      <td>828124615</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>421</td>\n",
       "      <td>828124615</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>225</td>\n",
       "      <td>828124615</td>\n",
       "      <td>click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>343</td>\n",
       "      <td>828124615</td>\n",
       "      <td>click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>222</td>\n",
       "      <td>828124615</td>\n",
       "      <td>click</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ITEM_ID  TIMESTAMP EVENT_TYPE\n",
       "USER_ID                               \n",
       "429          222  828124615      watch\n",
       "429          227  828124615      click\n",
       "429          595  828124615      watch\n",
       "429          592  828124615      watch\n",
       "429          590  828124615      watch\n",
       "429          434  828124615      watch\n",
       "429          421  828124615      watch\n",
       "429          225  828124615      click\n",
       "429          343  828124615      click\n",
       "429          222  828124615      click"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe for the interactions by reading in the correct source CSV\n",
    "interactions_df = pd.read_csv(data_dir + '/interactions.csv', sep=',', index_col=0)\n",
    "\n",
    "# Render some sample data\n",
    "interactions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "createwatchedfilter_response = personalize.create_filter(name='watched',\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    filterExpression='INCLUDE ItemID WHERE Interactions.event_type IN (\"watch\")'\n",
    "    )\n",
    "\n",
    "createunwatchedfilter_response = personalize.create_filter(name='unwatched',\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    filterExpression='EXCLUDE ItemID WHERE Interactions.event_type IN (\"watch\")'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on we want to add those filters to a list as well so they can be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_filter_arns = [createwatchedfilter_response['filterArn'], createunwatchedfilter_response['filterArn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing useful variables <a class=\"anchor\" id=\"vars\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Before exiting this notebook, run the following cells to save the version ARNs for use in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'userpersonalization_solution_version_arn' (str)\n",
      "Stored 'sims_solution_version_arn' (str)\n",
      "Stored 'rerank_solution_version_arn' (str)\n",
      "Stored 'user_personalization_solution_arn' (str)\n",
      "Stored 'sims_solution_arn' (str)\n",
      "Stored 'rerank_solution_arn' (str)\n"
     ]
    }
   ],
   "source": [
    "%store userpersonalization_solution_version_arn\n",
    "%store sims_solution_version_arn\n",
    "%store rerank_solution_version_arn\n",
    "%store user_personalization_solution_arn\n",
    "%store sims_solution_arn\n",
    "%store rerank_solution_arn\n",
    "%store sims_campaign_arn\n",
    "%store userpersonalization_campaign_arn\n",
    "%store rerank_campaign_arn\n",
    "%store meta_filter_decade_arns\n",
    "%store genre_filter_arn\n",
    "%store interaction_filter_arns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're all set to move on to the last exploratory notebook: `03_Inference_Layer.ipynb`. Open it from the browser and you can start interacting with the Campaigns and gettign recommendations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
