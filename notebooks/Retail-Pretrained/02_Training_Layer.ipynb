{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Recommenders and Solutions <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "1. [How to train your Use Case Optimized Recommenders and Solution Versions](#recommenders)\n",
    "1. [Create Solutions](#solutions)\n",
    "1. [Evaluate Solutions](#eval)\n",
    "1. [Using Evaluation Metrics](#use)\n",
    "1. [Deploy a Campaign](#deploy)\n",
    "1. [Create Filters](#filters)\n",
    "1. [Storing Useful Variables](#vars)\n",
    "\n",
    "To run this notebook, you need to have run [the previous notebook: `01_Data_Layer.ipynb`](01_Data_Layer.ipynb), where you prepared 3 datasets (interactions, items, and users) for use in Amazon Personalize. At the end of that notebook, you saved some variable values, which you now need to load into this notebook.\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "In the previous notebook we prepared 3 different datasets that represent our fictional retail store (User interactions, Product catalog data and buyer/user data) and created Datasets in Amazon Personalize for this data.\n",
    "\n",
    "In this notebook we will define our use-case, train models and create APIs to get recommendations.\n",
    "\n",
    "## Define your Use Case <a class=\"anchor\" id=\"usecase\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "There are a few guidelines for scoping a problem suitable for Personalize. We recommend the values below as a starting point. The [minimum data requirements](hhttps://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html) are.\n",
    "\n",
    "* At least 50 unique users (identified by a user_id)\n",
    "* At least 100 unique items\n",
    "* At least 2 dozen interactions for each user \n",
    "\n",
    "The [minimum data requirements](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html) can be found in the documentation.\n",
    "\n",
    "Most of the time this is easily attainable, and if you are low in one category, you can often make up for it by having a larger number in another category.\n",
    "\n",
    "The user-item-iteraction data is key for getting started with the service. This means we need to look for use cases that generate that kind of data, a few common examples are:\n",
    "\n",
    "1. Video-on-demand applications\n",
    "1. E-commerce platforms\n",
    "\n",
    "Defining your use-case will inform what data and what type of data you need.\n",
    "\n",
    "### Train Models and create APIs to get recommendations\n",
    "\n",
    "In this section we will be creating ECOMMERCE Use Case Optimized Recommenders for the following use cases:\n",
    "\n",
    "1. [Customers who viewed X also viewed](https://docs.aws.amazon.com/personalize/latest/dg/ECOMMERCE-use-cases.html#customers-also-viewed-use-case): Get recommendations for items that customers also viewed based on an item that you specify. With this use case, Amazon Personalize automatically filters items the user purchased based on the userId that you specify and `Purchase` events.\n",
    "\n",
    "1. [Recommended For You](https://docs.aws.amazon.com/personalize/latest/dg/ECOMMERCE-use-cases.html#recommended-for-you-use-case): Get personalized recommendations for items based on a user that you specify. With this use case, Amazon Personalize automatically filters items the user purchased based on the userId that you specify and Purchase events. For better performance, include `Purchase` events along with the required `View` events.\n",
    "\n",
    "in addition we will create a custom solution, solution version and campaign for the following use case:\n",
    "\n",
    "3. [Personalized Ranking](https://docs.aws.amazon.com/personalize/latest/dg/personalized-ranking-recipes.html): will be used to rank a list of items.\n",
    "\n",
    "All of these will be created within the same dataset group and with the same input data.\n",
    "\n",
    "The following diagram shows the resources that we will create in this section. The part we are building  in this notebook is highlighted in blue with a dashed outline.\n",
    "\n",
    "![Workflow](images/02_Training_Layer_Resources.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous notebook, start by importing the relevant packages, and set up a connection to Amazon Personalize using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import random\n",
    "import boto3\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train your Use Case Optimized Recommenders and Solution Versions <a class=\"anchor\" id=\"recommenders\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "As mentioned previously, a dataset group, schemas, datasets, solutions, and campaigns have already been created for you. You can open another browser tab/window to view these resources in the Personalize AWS Console.\n",
    "\n",
    "Below, we will walk you through the steps we used to create these resources. Since they are already created, we will only be retrieving the automated deployment variables, however you can also run this code to train resources if you have not run the automation.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Please take into account that creating these resources in your own account will incur a cost. If you are not using the CloudFormation template, it will take upload and training time to do these steps through this notebook (this can be several hours).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready... Set... Train! :\n",
    "\n",
    "Now that the data is imported and ready for use, we will create ECOMMERCE Use Case Optimized Recommenders for the following use cases: [Customers who viewed X also viewed](https://docs.aws.amazon.com/personalize/latest/dg/ECOMMERCE-use-cases.html#customers-also-viewed-use-case) and [Recommended for you](hhttps://docs.aws.amazon.com/personalize/latest/dg/ECOMMERCE-use-cases.html#recommended-for-you-use-case).\n",
    "\n",
    "We will also create a custom solution and solution versions for the use case [Personalized-Ranking](https://docs.aws.amazon.com/personalize/latest/dg/personalized-ranking-recipes.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Use Case Optimized Recommenders <a class=\"anchor\" id=\"recommenders\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "We'll start with pre-configured ECOMMERCE Recommenders that match some of our core use cases. Each domain has different use cases. When you create a recommender you create it for a specific use case, and each use case has different requirements for getting recommendations.\n",
    "\n",
    "Let us look at the recommenders supported for the ECOMMERCE domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_recipes = personalize.list_recipes(domain='ECOMMERCE')\n",
    "display_available_recipes = available_recipes ['recipes']\n",
    "available_recipes = personalize.list_recipes(domain='ECOMMERCE',nextToken=available_recipes['nextToken'])#paging to get the rest of the recipes \n",
    "display_available_recipes = display_available_recipes + available_recipes['recipes']\n",
    "display(display_available_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[More use cases per domain](https://docs.aws.amazon.com/personalize/latest/dg/domain-use-cases.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a \"Customers who viewed X also viewed\" Recommender\n",
    "\n",
    "We are going to create a recommender of the type [Customers who viewed X also viewed](https://docs.aws.amazon.com/personalize/latest/dg/ECOMMERCE-use-cases.html#customers-also-viewed-use-case). This recommender gives recommendations for items that customers also viewed based on an item that you specify. With this use case, Amazon Personalize automatically filters items the user purchased based on the userId that you specify and `Purchase` events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_recommender_response = personalize.create_recommender(\n",
    "      name = recommender_customers_who_viewed_name,\n",
    "      recipeArn = 'arn:aws:personalize:::recipe/aws-ecomm-customers-who-viewed-x-also-viewed',\n",
    "      datasetGroupArn = workshop_dataset_group_arn\n",
    "    )\n",
    "    workshop_recommender_customers_who_viewed_arn = create_recommender_response[\"recommenderArn\"]\n",
    "    \n",
    "    print (json.dumps(create_recommender_response))\n",
    "    print ('\\nCreating the Customers who viewed X also Viewed recommender with workshop_recommender_customers_who_viewed_arn = {}'.format(workshop_recommender_customers_who_viewed_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException as e:\n",
    "    workshop_recommender_customers_who_viewed_arn =  'arn:aws:personalize:'+region+':'+account_id+':recommender/'+recommender_customers_who_viewed_name\n",
    "    print('The Customers who viewed X also Viewed recommender {} already exists.'.format(recommender_customers_who_viewed_name))\n",
    "    print ('\\nWe will be using the existing Customers who viewed X also Viewed recommender with workshop_recommender_customers_who_viewed_arn = {}'.format(workshop_recommender_customers_who_viewed_arn))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a \"Recommended For You\" Recommender\n",
    "\n",
    "We are going to create a second recommender of the type [Recommended for you](hhttps://docs.aws.amazon.com/personalize/latest/dg/ECOMMERCE-use-cases.html#recommended-for-you-use-case). This type of recommender offers personalized recommendations for items based on a user that you specify. With this use case, Amazon Personalize automatically filters items the user purchased based on the userId that you specify and `Purchase` events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_recommender_response = personalize.create_recommender(\n",
    "      name = recommender_recommended_for_you_name,\n",
    "      recipeArn = 'arn:aws:personalize:::recipe/aws-ecomm-recommended-for-you',\n",
    "      datasetGroupArn = workshop_dataset_group_arn\n",
    "    )\n",
    "    workshop_recommender_recommended_for_you_arn = create_recommender_response[\"recommenderArn\"]\n",
    "    \n",
    "    print (json.dumps(create_recommender_response))\n",
    "    print ('\\nCreating the Recommended For You recommender with workshop_recommender_recommended_for_you_arn = {}'.format(workshop_recommender_recommended_for_you_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException as e:\n",
    "    workshop_recommender_recommended_for_you_arn =  'arn:aws:personalize:'+region+':'+account_id+':recommender/'+recommender_recommended_for_you_name\n",
    "    print('The Recommended For You For You recommender {} already exists.'.format(workshop_recommender_recommended_for_you_arn))\n",
    "    print ('\\nWe will be using the existing Recommended For You recommender with workshop_recommender_top_picks_arn = {}'.format(workshop_recommender_recommended_for_you_arn))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Solutions <a class=\"anchor\" id=\"solutions\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Some use cases require a custom implementation. \n",
    "\n",
    "In Amazon Personalize, a specific variation of an algorithm is called a recipe. Different recipes are suitable for different situations. A trained model is called a solution, and each solution can have many versions that relate to a given volume of data when the model was trained.\n",
    "\n",
    "Let's look at all available recipes that are not of a specific domain and can be used to create cusom solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_recipes = personalize.list_recipes()\n",
    "display_available_recipes = available_recipes ['recipes']\n",
    "available_recipes = personalize.list_recipes(nextToken=available_recipes['nextToken'])#paging to get the rest of the recipes \n",
    "display_available_recipes = display_available_recipes + available_recipes['recipes']\n",
    "\n",
    "display ([recipe  for recipe in display_available_recipes if 'domain' not in recipe])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to rank a list of items for a specific user. This is useful if you have a collection of ordered items, such as search results, promotions, or curated lists, and you want to provide a personalized re-ranking for each of your users. To implement this use case, we will create a custom solution using the recipe.\n",
    "\n",
    "The [Personalized-Ranking](https://docs.aws.amazon.com/personalize/latest/dg/personalized-ranking-recipes.html) recipe provides recommendations in ranked order based on predicted interest level. This recipe generates personalized rankings of items. A personalized ranking is a list of recommended items that are re-ranked for a specific user. This is useful if you have a collection of ordered items, such as search results, promotions, or curated lists, and you want to provide a personalized re-ranking for each of your users.\n",
    "\n",
    "These custom solution will use the same datasets that we already implemented so all we need to do is create a solution and solution version for this recipe.\n",
    "\n",
    "### Personalized Ranking\n",
    "\n",
    "[Personalized-Ranking](https://docs.aws.amazon.com/personalize/latest/dg/personalized-ranking-recipes.html) is an interesting application of HRNN. Instead of just recommending what is most probable for the user in question, this algorithm takes in a list of items as well as a user. The items are then returned back in the order of most probable relevance for the user. The use case here is for filtering on unique categories that you do not have item metadata to create a filter, or when you have a broad collection that you would like better ordered for a particular user.\n",
    "\n",
    "For our use case, using the product data, we could imagine that a retail application may want to create a shelf of Halloween products. We can generate these lists based on metadata we have. We would use personalized ranking to re-order the list of products for each user. \n",
    "\n",
    "We start by selecting the recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_rerank_recipe_arn = \"arn:aws:personalize:::recipe/aws-personalized-ranking\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the solution\n",
    "\n",
    "First you create a solution using the recipe. Although you provide the dataset ARN in this step, the model is not yet trained. See this as an identifier instead of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rerank_create_solution_response = personalize.create_solution(\n",
    "        name = workshop_rerank_solution_name,\n",
    "        datasetGroupArn = workshop_dataset_group_arn,\n",
    "        recipeArn = workshop_rerank_recipe_arn\n",
    "    )\n",
    "\n",
    "    workshop_rerank_solution_arn = rerank_create_solution_response['solutionArn']\n",
    "    print(json.dumps(rerank_create_solution_response, indent=2))\n",
    "\n",
    "    print ('\\nCreating the Personalize Ranking Solution with workshop_rerank_solution_arn = {}'.format(workshop_rerank_solution_arn))\n",
    "\n",
    "except personalize.exceptions.ResourceAlreadyExistsException as e:\n",
    "    workshop_rerank_solution_arn =  'arn:aws:personalize:'+region+':'+account_id+':solution/'+workshop_rerank_solution_name\n",
    "    print('The Personalize Ranking Solution {} already exists.'.format(workshop_rerank_solution_arn))\n",
    "    print ('\\nWe will be using the existing Personalize Ranking Solution with workshop_rerank_solution_arn = {}'.format(workshop_rerank_solution_arn))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the Solution to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 6*60*60 # 6 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_response = personalize.describe_solution(\n",
    "        solutionArn = workshop_rerank_solution_arn\n",
    "    )\n",
    "    status_solution =  describe_solution_response[\"solution\"]['status']\n",
    "    print(\"Solution: {}\".format(status_solution))\n",
    "    \n",
    "    if status_solution == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_interactions_dataset_arn))\n",
    "        break\n",
    "        \n",
    "    elif status_solution == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_interactions_dataset_arn))\n",
    "        break\n",
    "        \n",
    "    if not status_solution == \"ACTIVE\":\n",
    "        print(\"The Solution creation is still in progress\")\n",
    "    else:\n",
    "        print(\"The Solution dataset is ACTIVE\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the solution version\n",
    "\n",
    "Once you have a solution, you need to create a version in order to complete the model training. The training can take a while to complete, upwards of 25 minutes, and an average of 35 minutes for this recipe with our dataset. Normally, we would use a while loop to poll until the task is completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_rerank_solution_version_arn = None\n",
    "\n",
    "solution_versions_list = personalize.list_solution_versions(\n",
    "    solutionArn=workshop_rerank_solution_arn,\n",
    "    maxResults=10\n",
    ")['solutionVersions']\n",
    "\n",
    "for solution_vers in solution_versions_list:\n",
    "    if solution_vers['status'] in ['CREATE PENDING', 'CREATE IN_PROGRESS', 'ACTIVE']:\n",
    "        workshop_rerank_solution_version_arn = solution_vers['solutionVersionArn']\n",
    "    if workshop_rerank_solution_version_arn:\n",
    "        break\n",
    "\n",
    "if workshop_rerank_solution_version_arn:\n",
    "    print ('\\nWe will be using the existing Personalize Ranking Solution Version with workshop_rerank_solution_version_arn = {}'.format(workshop_rerank_solution_version_arn))\n",
    "else:\n",
    "    rerank_create_solution_version_response = personalize.create_solution_version(\n",
    "        solutionArn = workshop_rerank_solution_arn\n",
    "    )\n",
    "    workshop_rerank_solution_version_arn = rerank_create_solution_version_response['solutionVersionArn']\n",
    "    print(json.dumps(rerank_create_solution_version_response, indent=2))\n",
    "    \n",
    "    print ('\\nTraining the Personalize Ranking Solution Version with workshop_rerank_solution_version_arn = {}'.format(workshop_rerank_solution_version_arn))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View solution and Recommender creation status\n",
    "\n",
    "To view the status updates in the console:\n",
    "\n",
    "* In another browser tab you should already have the AWS Console up from opening this notebook instance. \n",
    "* Switch to that tab and search at the top for the service `Personalize`, then go to that service page. \n",
    "* Click `Dataset groups`.\n",
    "* Click the name of your dataset group, if you did not change it, it is \"personalize-poc-retail\".\n",
    "* Click `Recommenders`.\n",
    "* You will see a list of the two recommenders you created above, including a column with the status of the recommender. Once it is `Active`, your recommender is ready.\n",
    "* Click on `Custom Resources`. This opens up the list of custom resources that you have created.\n",
    "* Click on `Solutions and Recipes` to see your re-ranking solutions. If you click on `workshop_personalized_ranking_retail` you can see the status of the solution versions. Once it is `Active`, your solution is ready to be reviewed. It is also capable of being deployed.\n",
    "\n",
    "Or simply run the cell below to keep track of the recommenders and solution version creation status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 10*60*60 # 10 hours\n",
    "while time.time() < max_time:\n",
    "\n",
    "    # Recommender viewed_x_also_viewed\n",
    "    version_response = personalize.describe_recommender(\n",
    "        recommenderArn = workshop_recommender_customers_who_viewed_arn\n",
    "    )\n",
    "    status_viewed_x_also_viewed = version_response[\"recommender\"][\"status\"]\n",
    "\n",
    "    if status_viewed_x_also_viewed == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_recommender_customers_who_viewed_arn))\n",
    "        \n",
    "    elif status_viewed_x_also_viewed == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_recommender_customers_who_viewed_arn))\n",
    "        break\n",
    "\n",
    "    if not status_viewed_x_also_viewed == \"ACTIVE\":\n",
    "        print('The recommender \"Customers who viewed X also viewed\" build is still in progress')\n",
    "    else:\n",
    "        print('The recommender \"Customers who viewed X also viewed\" is ACTIVE')\n",
    "\n",
    "    # Recommender recommended_for_you\n",
    "    version_response = personalize.describe_recommender(\n",
    "        recommenderArn = workshop_recommender_recommended_for_you_arn\n",
    "    )\n",
    "    status_recommended_for_you = version_response[\"recommender\"][\"status\"]\n",
    "\n",
    "    if status_recommended_for_you == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_recommender_recommended_for_you_arn))\n",
    "    elif status_recommended_for_you == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_recommender_recommended_for_you_arn))\n",
    "        break\n",
    "\n",
    "    if not status_recommended_for_you == \"ACTIVE\":\n",
    "        print('The recommender \"Recommended for you\" build is still in progress')\n",
    "    else:\n",
    "        print('The recommender \"Recommended for you\" is ACTIVE')\n",
    "        \n",
    "    # Reranking Solution \n",
    "    version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = workshop_rerank_solution_version_arn\n",
    "    )\n",
    "    status_rerank_solution = version_response[\"solutionVersion\"][\"status\"]\n",
    "\n",
    "    if status_rerank_solution == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_rerank_solution_version_arn))\n",
    "        \n",
    "    elif status_rerank_solution == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_rerank_solution_version_arn))\n",
    "        break\n",
    "\n",
    "    if not status_rerank_solution == \"ACTIVE\":\n",
    "        print(\"Rerank Solution Version build is still in progress\")\n",
    "    else:\n",
    "        print(\"The Rerank solution is ACTIVE\")\n",
    "        \n",
    "    if status_viewed_x_also_viewed == \"ACTIVE\" and status_recommended_for_you == 'ACTIVE' and status_rerank_solution == \"ACTIVE\":\n",
    "        break\n",
    "\n",
    "    print()\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Campaign <a class=\"anchor\" id=\"deploy\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Once a solution version is created, it is possible to get recommendations from them, and to get a feel for their overall behavior.\n",
    "\n",
    "For real-time recommendations, after you prepare and import data and creating a solution, you are ready to deploy your solution version to generate recommendations. You deploy a solution version by creating an Amazon Personalize campaign. If you are getting batch recommendations, you don't need to create a campaign. For more information, see [Getting batch recommendations and user segments](https://docs.aws.amazon.com/personalize/latest/dg/recommendations-batch.html).\n",
    "\n",
    "We will deploy a campaign for the personalized ranking solution version. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a campaign\n",
    "\n",
    "A campaign is a hosted solution version: an endpoint which you can query for recommendations. Pricing is set by estimating throughput capacity (requests from users for personalization per second). When deploying a campaign, you set a minimum throughput per second (TPS) value. This service, like many within AWS, will automatically scale based on demand, but if latency is critical, you may want to provision ahead for larger demand. For this workshop, all minimum throughput thresholds are set to 1. For more information, see the [pricing page](https://aws.amazon.com/personalize/pricing/).\n",
    "\n",
    "Once we're satisfied with our solution version, we need to create Campaigns for each solution version. When creating a campaign you specify the minimum transactions per second (`minProvisionedTPS`) that you expect to make against the service for this campaign. Personalize will automatically scale the inference endpoint up and down for the campaign to match demand but will never scale below `minProvisionedTPS`.\n",
    "\n",
    "Let's create a campaign for our solution versions set at `minProvisionedTPS` of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rerank_create_campaign_response = personalize.create_campaign(\n",
    "        name = workshop_rerank_campaign_name,\n",
    "        solutionVersionArn = workshop_rerank_solution_version_arn,\n",
    "        minProvisionedTPS = 1\n",
    "    )\n",
    "\n",
    "    workshop_rerank_campaign_arn = rerank_create_campaign_response['campaignArn']\n",
    "    print(json.dumps(rerank_create_campaign_response, indent=2))\n",
    "\n",
    "    print ('\\nCreating the personalize ranking campaign with workshop_rerank_campaign_arn = {}'.format(workshop_rerank_campaign_arn))\n",
    "\n",
    "except personalize.exceptions.ResourceAlreadyExistsException as e:\n",
    "    workshop_rerank_campaign_arn =  'arn:aws:personalize:'+region+':'+account_id+':campaign/'+workshop_rerank_campaign_name\n",
    "    print('The personalize ranking campaign {} already exists.'.format(workshop_rerank_campaign_arn))\n",
    "    print ('\\nWe will be using the existing personalize ranking campaign with workshop_rerank_campaign_arn = {}'.format(workshop_rerank_campaign_arn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View campaign creation status\n",
    "\n",
    "This is how you view the status updates in the console:\n",
    "\n",
    "* In another browser tab you should already have the AWS Console open from opening this notebook instance. \n",
    "* Switch to that tab and search at the top for the service `Personalize`, then go to that service page. \n",
    "* Click `Manage dataset groups`.\n",
    "* Click the name of your dataset group.\n",
    "* Click `Custom Resources`\n",
    "* Click `Campaigns`.\n",
    "* You will now see a list of all of the campaigns you created above, including a column with the status of the campaign. Once it is `Active`, your campaign is ready to be queried.\n",
    "\n",
    "Or simply run the cell below to keep track of the campaign creation status of the campaign we created.\n",
    "\n",
    "While you are waiting for this to complete you can learn more about campaigns in [the documentation](https://docs.aws.amazon.com/personalize/latest/dg/campaigns.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "\n",
    "    version_response = personalize.describe_campaign(\n",
    "        campaignArn = workshop_rerank_campaign_arn\n",
    "    )\n",
    "    status = version_response['campaign']['status']\n",
    "\n",
    "    if status == 'ACTIVE':\n",
    "        print('Build succeeded for {}'.format(workshop_rerank_campaign_arn))\n",
    "    elif status == \"CREATE FAILED\":\n",
    "        print('Build failed for {}'.format(workshop_rerank_campaign_arn))\n",
    "        in_progress_campaigns.remove(workshop_rerank_campaign_arn)\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "    else:\n",
    "        print('The campaign build is still in progress')\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate solution versions and recommenders <a class=\"anchor\" id=\"eval\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Personalize calculates these metrics based on a subset of the training data. The image below illustrates how Personalize splits the data. Given 10 users, with 10 interactions each (a circle represents an interaction), the interactions are ordered from oldest to newest based on the timestamp. Personalize uses all the interaction data from 90% of the users (blue circles) to train the solution version, and the remaining 10% for evaluation. For each of the users in the remaining 10%, 90% of their interaction data (green circles) is used as input for the call to the trained model. The remaining 10% of their data (orange circle) is compared to the output produced by the model and used to calculate the evaluation metrics.\n",
    "\n",
    "![personalize metrics](../../static/imgs/personalize_metrics.png)\n",
    "\n",
    "We recommend reading [the documentation](https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html) to understand the metrics, but we have also copied parts of the documentation below for convenience.\n",
    "\n",
    "You need to understand the following terms regarding evaluation in Personalize:\n",
    "\n",
    "* *Relevant recommendation* refers to a recommendation that matches a value in the testing data for the particular user.\n",
    "* *Rank* refers to the position of a recommended item in the list of recommendations. Position 1 (the top of the list) is presumed to be the most relevant to the user.\n",
    "* *Query* refers to the internal equivalent of a GetRecommendations call.\n",
    "\n",
    "The metrics produced by Personalize are:\n",
    "* **coverage**: The proportion of unique recommended items from all queries out of the total number of unique items in the training data (includes both the Items and Interactions datasets).\n",
    "* **mean_reciprocal_rank_at_25**: The [mean of the reciprocal ranks](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) of the first relevant recommendation out of the top 25 recommendations over all queries. This metric is appropriate if you're interested in the single highest ranked recommendation.\n",
    "* **normalized_discounted_cumulative_gain_at_K**: Discounted gain assumes that recommendations lower on a list of recommendations are less relevant than higher recommendations. Therefore, each recommendation is discounted (given a lower weight) by a factor dependent on its position. To produce the [cumulative discounted gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) at K, each relevant discounted recommendation in the top K recommendations is summed together. The normalized discounted cumulative gain (NDCG) is the DCG divided by the ideal DCG such that NDCG is between 0 - 1. (The ideal DCG is where the top K recommendations are sorted by relevance.) Amazon Personalize uses a weighting factor of 1/log(1 + position), where the top of the list is position 1. This metric rewards relevant items that appear near the top of the list, because the top of a list usually draws more attention.\n",
    "* **precision_at_K**: The number of relevant recommendations out of the top K recommendations divided by K. This metric rewards precise recommendation of the relevant items.\n",
    "\n",
    "Let's take a look at the evaluation metrics for each of the solutions produced in this notebook. Please note that your results might differ from the results described in the text of this notebook, due to the quality of the synthetic dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Customers who viewed X also viewed\" recommender metrics\n",
    "\n",
    "Retrieve the evaluation metrics for the \"Customers who viewed X also viewed\" recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_recommender_customers_who_viewed_metrics_response = personalize.describe_recommender(\n",
    "    recommenderArn = workshop_recommender_customers_who_viewed_arn\n",
    ")\n",
    "\n",
    "for metric in workshop_recommender_customers_who_viewed_metrics_response['recommender']['modelMetrics']:\n",
    "    print (\"{}: {}\".format(metric, workshop_recommender_customers_who_viewed_metrics_response['recommender']['modelMetrics'][metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **coverage**: The proportion of unique recommended items from all queries out of the total number of unique items in the training data (includes both the Items and Interactions datasets).\n",
    "* **mean_reciprocal_rank_at_25**: The [mean of the reciprocal ranks](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) of the first relevant recommendation out of the top 25 recommendations over all queries. This metric is appropriate if you're interested in the single highest ranked recommendation.\n",
    "* **normalized_discounted_cumulative_gain_at_K**: Discounted gain assumes that recommendations lower on a list of recommendations are less relevant than higher recommendations. Therefore, each recommendation is discounted (given a lower weight) by a factor dependent on its position. To produce the [cumulative discounted gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) at K, each relevant discounted recommendation in the top K recommendations is summed together. The normalized discounted cumulative gain (NDCG) is the DCG divided by the ideal DCG such that NDCG is between 0 - 1. (The ideal DCG is where the top K recommendations are sorted by relevance.) Amazon Personalize uses a weighting factor of 1/log(1 + position), where the top of the list is position 1. This metric rewards relevant items that appear near the top of the list, because the top of a list usually draws more attention.\n",
    "* **precision_at_K**: The number of relevant recommendations out of the top K recommendations divided by K. This metric rewards precise recommendation of the relevant items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Recommended for you\" recommender metrics\n",
    "\n",
    "Retrieve the evaluation metrics for the \"Recommended for you\" Recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_recommender_recommended_for_you_metrics_response = personalize.describe_recommender(\n",
    "    recommenderArn = workshop_recommender_recommended_for_you_arn\n",
    ")\n",
    "\n",
    "for metric in workshop_recommender_recommended_for_you_metrics_response['recommender']['modelMetrics']:\n",
    "    print (\"{}: {}\".format(metric, workshop_recommender_recommended_for_you_metrics_response['recommender']['modelMetrics'][metric]))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **coverage**: The proportion of unique recommended items from all queries out of the total number of unique items in the training data (includes both the Items and Interactions datasets).\n",
    "* **mean_reciprocal_rank_at_25**: The [mean of the reciprocal ranks](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) of the first relevant recommendation out of the top 25 recommendations over all queries. This metric is appropriate if you're interested in the single highest ranked recommendation.\n",
    "* **normalized_discounted_cumulative_gain_at_K**: Discounted gain assumes that recommendations lower on a list of recommendations are less relevant than higher recommendations. Therefore, each recommendation is discounted (given a lower weight) by a factor dependent on its position. To produce the [cumulative discounted gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) at K, each relevant discounted recommendation in the top K recommendations is summed together. The normalized discounted cumulative gain (NDCG) is the DCG divided by the ideal DCG such that NDCG is between 0 - 1. (The ideal DCG is where the top K recommendations are sorted by relevance.) Amazon Personalize uses a weighting factor of 1/log(1 + position), where the top of the list is position 1. This metric rewards relevant items that appear near the top of the list, because the top of a list usually draws more attention.\n",
    "* **precision_at_K**: The number of relevant recommendations out of the top K recommendations divided by K. This metric rewards precise recommendation of the relevant items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized Ranking Metrics\n",
    "Retrieve the evaluation metrics for the personalized ranking solution version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = workshop_rerank_solution_version_arn\n",
    ")\n",
    "\n",
    "for metric in rerank_solution_metrics_response[\"metrics\"]:\n",
    "    print (\"{}: {}\".format(metric,rerank_solution_metrics_response[\"metrics\"][metric] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **coverage**: The proportion of unique recommended items from all queries out of the total number of unique items in the training data (includes both the Items and Interactions datasets).\n",
    "* **mean_reciprocal_rank_at_25**: The [mean of the reciprocal ranks](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) of the first relevant recommendation out of the top 25 recommendations over all queries. This metric is appropriate if you're interested in the single highest ranked recommendation.\n",
    "* **normalized_discounted_cumulative_gain_at_K**: Discounted gain assumes that recommendations lower on a list of recommendations are less relevant than higher recommendations. Therefore, each recommendation is discounted (given a lower weight) by a factor dependent on its position. To produce the [cumulative discounted gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) at K, each relevant discounted recommendation in the top K recommendations is summed together. The normalized discounted cumulative gain (NDCG) is the DCG divided by the ideal DCG such that NDCG is between 0 - 1. (The ideal DCG is where the top K recommendations are sorted by relevance.) Amazon Personalize uses a weighting factor of 1/log(1 + position), where the top of the list is position 1. This metric rewards relevant items that appear near the top of the list, because the top of a list usually draws more attention.\n",
    "* **precision_at_K**: The number of relevant recommendations out of the top K recommendations divided by K. This metric rewards precise recommendation of the relevant items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using evaluation metrics <a class=\"anchor\" id=\"usemetrics\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "It is important to use evaluation metrics carefully. There are a number of factors to keep in mind.\n",
    "\n",
    "* If there is an existing recommendation system in place, this will have influenced the user's interaction history which you use to train your new solutions. This means the evaluation metrics are biased to favor the existing solution. If you work to push the evaluation metrics to match or exceed the existing solution, you may just be pushing the User Personalization to behave like the existing solution and might not end up with something better.\n",
    "\n",
    "\n",
    "Keeping in mind these factors, the evaluation metrics produced by Personalize are generally useful for two cases:\n",
    "1. Comparing the performance of solution versions trained on the same recipe, but with different values for the hyperparameters and features (impression data etc)\n",
    "1. Comparing the performance of solution versions trained on different recipes. Here also keep in mind that the recipes answer different use cases and comparing them to each other might not make sense in your solution.\n",
    "\n",
    "Properly evaluating a recommendation system is always best done through A/B testing while measuring actual business outcomes. Since recommendations generated by a system usually influence the user behavior which it is based on, it is better to run small experiments and apply A/B testing for longer periods of time. Over time, the bias from the existing model will fade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing useful variables <a class=\"anchor\" id=\"vars\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Before exiting this notebook, run the following cells to save the version ARNs for use in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store workshop_recommender_customers_who_viewed_arn\n",
    "%store workshop_recommender_recommended_for_you_arn\n",
    "%store workshop_rerank_campaign_arn\n",
    "%store workshop_rerank_solution_arn\n",
    "%store workshop_rerank_solution_version_arn\n",
    "%store workshop_rerank_campaign_arn\n",
    "%store region\n",
    "%store role_name\n",
    "%store account_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're all set to move on to [the exploratory notebook `03_Inference_Layer.ipynb`](03_Inference_Layer.ipynb). Open it from the browser and you can start interacting with the Recommenders and Campaign and getting recommendations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
