{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Retail Demo Store <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "Congratulations! You have just been hired by the Retail Demo Store, which is a new online retail store that launched and is jumping into the crowded space of online sales. You have been hired into the Search & Discovery team, which leads efforts around personalization. Currently, most of your app does not provide a personalized experience, the products are presented in a static order for all users. In order to prevent customer churn and increase sales, you are looking to add personalized experiences. \n",
    "\n",
    "You’ve been asked by the founders to:\n",
    "\n",
    "- Increase subscriber engagement by tailoring every experience to individual users\n",
    "- Help users discover newly released products\n",
    "- Increase the breadth of content offered to them from the Retail Demo Store catalog\n",
    "- Reduce the time to value by creating valuable recommendations in a short time\n",
    "\n",
    "Throughout the course of this workshop you will be exploring your datasets, building/training several recommendation models and implementing recommendations with API's.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> importing and training the datasets will take longer than we have in this workshop. In order to complete this workshop within the time set, we have already created several resources on your behalf.  However, the notebooks are designed in such a way that all the steps are included. If the resources have already been created, the cell will return information about the resources, if the resources have not been created, it will create them for you. \n",
    "</div>\n",
    "\n",
    "\n",
    "## In this notebook\n",
    "In this notebook, you will choose a dataset and prepare it for use with Amazon Personalize.\n",
    "\n",
    "1. [How to Use the Notebook](#usenotebook)\n",
    "1. [Introduction to Amazon Personalize Datasets](#datasets)\n",
    "1. [Choose a Dataset or Data Source](#source)\n",
    "1. [Configure an S3 bucket and an IAM role](#bucket_role)\n",
    "1. [Create dataset group](#group_dataset)\n",
    "1. [Create the Interactions Schema](#interact_schema)\n",
    "1. [Create the Items Schema](#items_schema)\n",
    "1. [Create the Users Schema](#users_schema)\n",
    "1. [Import the Interactions Data](#import_interactions)\n",
    "1. [Import the Items Metadata](#import_items)\n",
    "1. [Import the User Metadata](#import_users)\n",
    "1. [Storing Useful Variables](#vars)\n",
    "\n",
    "## How to Use the Notebook <a class=\"anchor\" id=\"usenotebook\"></a>\n",
    "\n",
    "### Executing cells\n",
    "\n",
    "The code is broken up into cells like the one below. There's a triangular **Run** button at the top of this page that you can click to execute each cell and move onto the next, or you can press `Shift` + `Enter` while in the cell to execute it and move onto the next one.\n",
    "\n",
    "As a cell is executing, you'll notice an `*` in the checkbox beside the cell. When the cell has finished running, the checkbox will contain a number to indicate the order the cell was executed in with respect to all the other cells in the notebook.\n",
    "\n",
    "Simply follow the instructions below and execute the cells to get started with Amazon Personalize.\n",
    "\n",
    "### Understanding the code\n",
    "\n",
    "This notebook can be used in two modalities:\n",
    "\n",
    "1. Train as you go by executing each cell. Some cells may take a long time to finish executing as they wait for resources to be created.\n",
    "2. Use this notebook with previously created resources. All or the majority of the resources will already be created, and cells will just retrieve the information of these existing resources to use them in following steps.\n",
    "\n",
    "Because of this, you will find that some cells have `try` and `except` blocks. In particular, most of them are handling a `ResourceAlreadyExistsException` exception. \n",
    "\n",
    "You can look at the code in the `try` block to get a good idea of how you can create a resource and understand how to use the Amazon Personalize SDK. The `except` block will let you know that the resource has been created and record the corresponding ARN, which is the Amazon unique identifier.\n",
    "\n",
    "This is an example of the `try` block for creating a dataset group, this code will execute without exceptions if the dataset group does not exist and raise an exception if the dataset group does already exist:\n",
    "\n",
    "```python\n",
    "try:     \n",
    "    # Try to create the dataset group, this block with exectute fully if the dataset group does not exist yet\n",
    "    \n",
    "    create_dataset_group_response = personalize.create_dataset_group(\n",
    "        name = workshop_dataset_group_name,\n",
    "        domain='ECOMMERCE'\n",
    "    )\n",
    "    workshop_dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "    print(json.dumps(create_dataset_group_response, indent=2))\n",
    "    print ('\\nCreating the Dataset Group with dataset_group_arn = {}'.format(workshop_dataset_group_arn))\n",
    "```\n",
    "and this is the corresponding `except` block that will be executed if an exception is raised because the dataset group already exists. This block saves the ARN for the existing dataset group to use later and lets you know the resource already exists.\n",
    "\n",
    "```python\n",
    "except personalize.exceptions.ResourceAlreadyExistsException as e:\n",
    "    workshop_dataset_group_arn = 'arn:aws:personalize:'+region+':'+account_id+':dataset group/' + \n",
    "        workshop_dataset_group_name \n",
    "    print ('\\nThe the Dataset Group with dataset_group_arn = {} already exists'.format(\n",
    "        workshop_dataset_group_arn))\n",
    "    print ('\\nWe will be using the existing Dataset Group dataset_group_arn = {}'.format(\n",
    "        workshop_dataset_group_arn))\n",
    "```\n",
    "\n",
    "Depending on the resource, you may also find that sometimes the code will check from a list of resources to find if a resource exists and then use `if` and `else` blocks to either use the existing resource or create it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build!\n",
    "\n",
    "Python ships with a broad collection of libraries and we need to import those as well as the ones installed to help us like [boto3](https://aws.amazon.com/sdk-for-python/) (AWS SDK for python) and [Pandas](https://pandas.pydata.org/)/[Numpy](https://numpy.org/)  which are core data science tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (24.2)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.35.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading botocore-1.35.4-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.35.3\n",
      "    Uninstalling botocore-1.35.3:\n",
      "      Successfully uninstalled botocore-1.35.3\n",
      "Successfully installed botocore-1.35.4\n",
      "Requirement already satisfied: seaborn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "mkdir: cannot create directory ‘poc_data’: File exists\n",
      "mkdir: cannot create directory ‘poc_data/data’: File exists\n",
      "mkdir: cannot create directory ‘poc_data/metadata’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Get the latest version of botocore to ensure we have the latest features in the SDK\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade --no-deps --force-reinstall botocore\n",
    "import os.path\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from time import sleep\n",
    "import csv\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "data_dir = \"poc_data\"\n",
    "\n",
    "!mkdir $data_dir\n",
    "!mkdir $data_dir/data\n",
    "!mkdir $data_dir/metadata\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account id: 809697808660\n",
      "region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Get the account id and region to use later\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "print(\"account id:\", account_id)\n",
    "\n",
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(\"region:\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is a workshop and the resources were created for you, we will retrieve the variables of the resources created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Opening JSON files\n",
    "f = open('params.json')\n",
    "parameters = json.load(f)\n",
    "\n",
    "f = open('params_data.json')\n",
    "parameters_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying User metadata\n",
      "--2024-08-22 20:24:11--  https://code.retaildemostore.retail.aws.dev/data/users.json.gz\n",
      "Resolving code.retaildemostore.retail.aws.dev (code.retaildemostore.retail.aws.dev)... 18.165.83.109, 18.165.83.120, 18.165.83.129, ...\n",
      "Connecting to code.retaildemostore.retail.aws.dev (code.retaildemostore.retail.aws.dev)|18.165.83.109|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1197415 (1.1M) [application/json]\n",
      "Saving to: ‘poc_data/metadata/users.json.gz’\n",
      "\n",
      "100%[======================================>] 1,197,415   --.-K/s   in 0.01s   \n",
      "\n",
      "2024-08-22 20:24:12 (98.6 MB/s) - ‘poc_data/metadata/users.json.gz’ saved [1197415/1197415]\n",
      "\n",
      "Copying Item metadata\n",
      "--2024-08-22 20:24:12--  https://code.retaildemostore.retail.aws.dev/data/products.yaml\n",
      "Resolving code.retaildemostore.retail.aws.dev (code.retaildemostore.retail.aws.dev)... 18.165.83.69, 18.165.83.129, 18.165.83.120, ...\n",
      "Connecting to code.retaildemostore.retail.aws.dev (code.retaildemostore.retail.aws.dev)|18.165.83.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1426674 (1.4M) [binary/octet-stream]\n",
      "Saving to: ‘poc_data/metadata/products.yaml.1’\n",
      "\n",
      "100%[======================================>] 1,426,674   --.-K/s   in 0.02s   \n",
      "\n",
      "2024-08-22 20:24:12 (54.8 MB/s) - ‘poc_data/metadata/products.yaml.1’ saved [1426674/1426674]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workshop_dataset_group_name = parameters['datasetGroup']['serviceConfig']['name']\n",
    "\n",
    "interactions_schema_name = parameters['datasets']['interactions']['schema']['serviceConfig']['name']\n",
    "interactions_dataset_name = parameters['datasets']['interactions']['dataset']['serviceConfig']['name']\n",
    "\n",
    "items_schema_name = parameters['datasets']['items']['schema']['serviceConfig']['name']\n",
    "items_dataset_name = parameters['datasets']['items']['dataset']['serviceConfig']['name']\n",
    "\n",
    "users_schema_name = parameters['datasets']['users']['schema']['serviceConfig']['name']\n",
    "users_dataset_name = parameters['datasets']['users']['dataset']['serviceConfig']['name']\n",
    "\n",
    "#The following job names are the starting Strings of the job names that can be created\n",
    "interactions_import_job_name = 'dataset_import_interaction'\n",
    "items_import_job_name = 'dataset_import_item'\n",
    "users_import_job_name = 'dataset_import_user'\n",
    "\n",
    "for recommender in parameters['recommenders']:\n",
    "    # This is currently configured assuming only one recommender of each type, if there are multiple \n",
    "    # recommenders of the same type further configuration is needed.\n",
    "    if (recommender['serviceConfig']['recipeArn'] == 'arn:aws:personalize:::recipe/aws-ecomm-customers-who-viewed-x-also-viewed'):\n",
    "        recommender_customers_who_viewed_name =recommender['serviceConfig']['name'] \n",
    "    if (recommender['serviceConfig']['recipeArn'] == 'arn:aws:personalize:::recipe/aws-ecomm-recommended-for-you'):\n",
    "        recommender_recommended_for_you_name =recommender['serviceConfig']['name']\n",
    "        \n",
    "for solution in parameters['solutions']:\n",
    "    # This is currently configured assuming only one solution of this type, if there are multiple \n",
    "    # solutions of the same type further configuration is needed.\n",
    "    if (solution['serviceConfig']['recipeArn'] == 'arn:aws:personalize:::recipe/aws-personalized-ranking'):\n",
    "        workshop_rerank_solution_name = solution['serviceConfig']['name'] \n",
    "        # This is currently configured assuming only one campaign, if there are multiple campaigns \n",
    "        # further configuration is needed.\n",
    "        workshop_rerank_campaign_name = solution['campaigns'][0]['serviceConfig']['name'] \n",
    "\n",
    "print (\"Copying User metadata\")\n",
    "user_metadata_file_path = parameters_data['data_files'][\"user_metadata_file_path\"]\n",
    "!wget -P poc_data/metadata $user_metadata_file_path\n",
    "# this will delete the zipped file. -k is not supported with the current version of gzip on this instance.\n",
    "\n",
    "user_metadata_file_name = './poc_data/metadata/users.json'\n",
    "if (os.path.isfile(user_metadata_file_name)):\n",
    "    !rm $user_metadata_file_name  \n",
    "    \n",
    "zipped_user_user_metadata_file_name = user_metadata_file_name+'.gz'\n",
    "    \n",
    "!gzip -d $zipped_user_user_metadata_file_name\n",
    "\n",
    "print (\"Copying Item metadata\")\n",
    "item_metadata_file_path = parameters_data['data_files'][\"item_metadata_file_path\"]\n",
    "!wget -P poc_data/metadata $item_metadata_file_path\n",
    "item_metadata_file_name = './poc_data/metadata/products.yaml'\n",
    "\n",
    "raw_interactions_file_path = parameters_data['data_files'][\"interactions_file_path\"]\n",
    "raw_items_file_path = parameters_data['data_files'][\"items_file_path\"]\n",
    "raw_users_file_path = parameters_data['data_files'][\"users_file_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will make sure we can use the SDK to interact with Amazon Personalize by describing some of the pre-created resources used in the workshop. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> If you have not pre-deployed resources and are building them as you go with this notebook, the below cell will raise an exception. You can continue with the notebook and create resources and train models as you go.\n",
    "</div>\n",
    "\n",
    "If you have not pre-deployed resources and are building them as you go with this notebook, the below cell will raise an exception. You can continue with the notebook and create resources and train models as you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK and resource check SUCCEEDED!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Describe a few resources using the SDK\n",
    "    recommender_customers_who_viewed_arn = 'arn:aws:personalize:'+region+':'+account_id+':recommender/'+recommender_customers_who_viewed_name \n",
    "    describe_response = personalize.describe_recommender(recommenderArn = recommender_customers_who_viewed_arn)\n",
    "\n",
    "    recommender_recommended_for_you_arn = 'arn:aws:personalize:'+region+':'+account_id+':recommender/'+recommender_recommended_for_you_name\n",
    "    describe_response = personalize.describe_recommender(recommenderArn = recommender_recommended_for_you_arn)\n",
    "\n",
    "    workshop_rerank_solution_arn = 'arn:aws:personalize:'+region+':'+account_id+':solution/'+workshop_rerank_solution_name\n",
    "    describe_response = personalize.describe_solution(solutionArn = workshop_rerank_solution_arn)\n",
    "    \n",
    "    print(\"SDK and resource check SUCCEEDED!\")\n",
    "    \n",
    "except:\n",
    "    print(\"SDK check FAILED. Proceed to the next cell if you will be uploading data and training models as you go.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Amazon Personalize Datasets <a class=\"anchor\" id=\"datasets\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "[Amazon Personalize](https://aws.amazon.com/personalize/) is a fully managed machine learning service that uses your data to generate item recommendations for your users. It can also generate user segments based on users’ affinity for certain items or item metadata.\n",
    "\n",
    "Regardless of the use case, the algorithms all learn user-item-interaction data, which is defined by 3 core attributes:\n",
    "\n",
    "1. **UserID** - The user who interacted\n",
    "1. **ItemID** - The item the user interacted with\n",
    "1. **Timestamp** - The time at which the interaction occurred\n",
    "\n",
    "Very often, your data will not arrive in a perfect form for Amazon Personalize from other systems (such as a product catalog, Customer Relationship Management (CRM) System, ...) and you will have to modify it to be structured correctly. This notebook guides you through that process.\n",
    "\n",
    "### Items data\n",
    "\n",
    "The item data consists of information about the products that users interact with, this data typically comes from the product catalog found in a Product Information Management (PIM) platform or an e-commerce system. For the purpose of this workshop, our items are products sold in the on-line retail store. To simulate our items data, we will be using a synthetic item dataset. This dataset is not mandatory, but providing good user metadata will ensure the best results in your trained models.\n",
    "\n",
    "### Interactions data\n",
    "\n",
    "The interaction data consists of information about the interactions the users of the fictional e-commerce store will have with the products sold there. This usually comes from analytics tools or Customer Data Platform's (CDP). The best interaction data for use for Amazon Personalize would include the sequential order of user behavior, what content was clicked on/purchased and the order it was interacted with. To simulate our interaction data, we will be using a synthetic interactions dataset. \n",
    "\n",
    "### User data\n",
    "\n",
    "The user data is what information you have about your users, it typically comes from Customer Relationship Management (CRM) system. We will be generating a small synthetic dataset to simulate this component of the workshop. This dataset is not mandatory, but providing good user metadata will ensure the best results in your trained models.\n",
    "\n",
    "In this notebook we will be importing interactions, user and item data into your environment, inspecting it and converting it to a format that allows you to use it in Amazon Personalize to train models to get personalized recommendations.\n",
    "\n",
    "In this notebook you will: upload and inspect your interaction, item and user data, create a dataset group and upload the data to the different datasets.\n",
    "\n",
    "![Workflow](images/01_Data_Layer_Resources.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and Explore the Simulated Retail Interactions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DISCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b93b7b15-9bb3-407c-b80b-517e7c45e090</td>\n",
       "      <td>3156</td>\n",
       "      <td>View</td>\n",
       "      <td>1716368030</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b93b7b15-9bb3-407c-b80b-517e7c45e090</td>\n",
       "      <td>3156</td>\n",
       "      <td>View</td>\n",
       "      <td>1716368035</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3946f4c8-1b5b-4161-b794-70b33affb671</td>\n",
       "      <td>2122</td>\n",
       "      <td>View</td>\n",
       "      <td>1716368053</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3946f4c8-1b5b-4161-b794-70b33affb671</td>\n",
       "      <td>2122</td>\n",
       "      <td>View</td>\n",
       "      <td>1716368063</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e9daa7cd-8230-4544-9f07-86fa84d7c3c1</td>\n",
       "      <td>2485</td>\n",
       "      <td>View</td>\n",
       "      <td>1716368073</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ITEM_ID  USER_ID EVENT_TYPE   TIMESTAMP  \\\n",
       "0  b93b7b15-9bb3-407c-b80b-517e7c45e090     3156       View  1716368030   \n",
       "1  b93b7b15-9bb3-407c-b80b-517e7c45e090     3156       View  1716368035   \n",
       "2  3946f4c8-1b5b-4161-b794-70b33affb671     2122       View  1716368053   \n",
       "3  3946f4c8-1b5b-4161-b794-70b33affb671     2122       View  1716368063   \n",
       "4  e9daa7cd-8230-4544-9f07-86fa84d7c3c1     2485       View  1716368073   \n",
       "\n",
       "  DISCOUNT  \n",
       "0       No  \n",
       "1       No  \n",
       "2       No  \n",
       "3       No  \n",
       "4       No  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_data = pd.read_csv(raw_interactions_file_path)\n",
    "interaction_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us see a few lines of the raw CSV data:\n",
    "\n",
    "- An ITEM_ID column of the item interacted with\n",
    "- A USER_ID column of the user who interacted\n",
    "- An EVENT_TYPE column which can be used to train different Personalize campaigns and also to filter on recommendations.\n",
    "- The custom DISCOUNT column, which is a contextual metadata field, that Personalize ranking and user recommendation campaigns can take into account to guess on the best next product.\n",
    "- A TIMESTAMP of when the interaction happened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chart the counts of each `EVENT_TYPE` generated for the interactions dataset. We're simulating a site where visitors heavily view/browse products and to a lesser degree add products to their cart and checkout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABT4AAAF8CAYAAADmcaTVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABV/ElEQVR4nO3de1iUdf7/8dcIMqLCiHJyjPWQxYrYprgpWoEH0E2y02a7GEYSHTSJ8LTWt9LW0EzNws3KUlbTqF2j7SSrWaJoeEBJMTUrTVxATBE8AsL8/mid346oKaA3TM/Hdd3X5XzuNzOvma5JfXkfTDabzSYAAAAAAAAAcCJNjA4AAAAAAAAAAPWN4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATsfV6AC/NtXV1SooKJCHh4dMJpPRcQAAAAAAAIBGxWaz6dixY7JarWrS5CLHddoMduDAAdvw4cNtrVu3trm7u9t+97vf2TZv3mzfX11dbXvuuedsbdu2tTVr1swWFhZmy8vLc3iO06dP2x5//HFbmzZtbM2bN7fdfvvttvz8fIeZI0eO2O6//36bp6enzdPT03b//ffbSkpKHGZ+/PFHW1RUlK158+a2Nm3a2MaMGWMrLy93mNm2bZvt1ltvtTVr1sxmtVptU6ZMsVVXV1/y+83Pz7dJYmNjY2NjY2NjY2NjY2NjY2NjY6vDdm7/dy5Dj/gsKSlR37591a9fPy1fvly+vr76/vvv1apVK/vMjBkzNHv2bKWmpur666/X1KlTFRERod27d8vDw0OSlJiYqI8//lhpaWlq06aNxo4dq6ioKOXk5MjFxUWSFB0drQMHDigjI0OS9PDDDysmJkYff/yxJKmqqkpDhgyRj4+PsrKydPjwYT3wwAOy2WxKSUmRJJWVlSkiIkL9+vXTpk2b9O233yo2NlYtWrTQ2LFjL+k9n82cn58vT0/PevkcAQAAAAAAgF+LsrIyBQQE2Hu2CzHZbDbbVcpUw1/+8hetW7dOa9euPe9+m80mq9WqxMRETZw4UZJUXl4uPz8/vfjii3rkkUdUWloqHx8fLV68WPfdd58kqaCgQAEBAfrss880aNAg7dy5U0FBQcrOzlavXr0kSdnZ2QoNDdWuXbsUGBio5cuXKyoqSvn5+bJarZKktLQ0xcbGqri4WJ6enpo3b54mTZqkgwcPymw2S5KmT5+ulJQUHThw4JJOXS8rK5PFYlFpaSnFJwAAAAAAAHCZLrVfM/TmRh999JF69uype++9V76+vurevbvmz59v3793714VFRUpMjLSvmY2mxUWFqb169dLknJyclRZWekwY7VaFRwcbJ/56quvZLFY7KWnJPXu3VsWi8VhJjg42F56StKgQYNUXl6unJwc+0xYWJi99Dw7U1BQoH379p33PZaXl6usrMxhAwAAAAAAAHBlGVp8/vDDD5o3b56uu+46/fvf/9ajjz6qhIQELVq0SJJUVFQkSfLz83P4OT8/P/u+oqIiubm5ycvL66Izvr6+NV7f19fXYebc1/Hy8pKbm9tFZ84+PjtzrmnTpslisdi3gICAX/hUAAAAAAAAANSVocVndXW1evTooeTkZHXv3l2PPPKI4uPjNW/ePIe5c08ht9lsv3ha+bkz55uvj5mzVwq4UJ5JkyaptLTUvuXn5180NwAAAAAAAIC6M7T4bNu2rYKCghzWunTpov3790uS/P39JdU8mrK4uNh+pKW/v78qKipUUlJy0ZmDBw/WeP1Dhw45zJz7OiUlJaqsrLzoTHFxsaSaR6WeZTab5enp6bABAAAAAAAAuLIMLT779u2r3bt3O6x9++23at++vSSpY8eO8vf318qVK+37KyoqlJmZqT59+kiSQkJC1LRpU4eZwsJC5eXl2WdCQ0NVWlqqjRs32mc2bNig0tJSh5m8vDwVFhbaZ1asWCGz2ayQkBD7zJo1a1RRUeEwY7Va1aFDh/r4SAAAAAAAAADUA0OLzyeffFLZ2dlKTk7Wd999p6VLl+rNN9/U6NGjJf18+nhiYqKSk5OVnp6uvLw8xcbGqnnz5oqOjpYkWSwWxcXFaezYsVq1apW2bt2q+++/X926ddPAgQMl/XwU6eDBgxUfH6/s7GxlZ2crPj5eUVFRCgwMlCRFRkYqKChIMTEx2rp1q1atWqVx48YpPj7efpRmdHS0zGazYmNjlZeXp/T0dCUnJyspKemS7ugOAAAAAAAA4Oow2c5epNIgn3zyiSZNmqQ9e/aoY8eOSkpKUnx8vH2/zWbTlClT9MYbb6ikpES9evXS3/72NwUHB9tnTp8+rfHjx2vp0qU6deqUBgwYoNdee83hRkJHjhxRQkKCPvroI0nS0KFDNXfuXLVq1co+s3//fo0aNUpffPGF3N3dFR0drZkzZzrcxX379u0aPXq0Nm7cKC8vLz366KN69tlnL7n4LCsrk8ViUWlpKae9AwAAAAAAAJfpUvs1w4vPXxuKTwAAAAAAAKD2LrVfc72KmXCVhIxfZHQEoEHKeWmE0REAAAAAAMBVYug1PgEAAAAAAADgSqD4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0DC0+J0+eLJPJ5LD5+/vb99tsNk2ePFlWq1Xu7u4KDw/Xjh07HJ6jvLxcY8aMkbe3t1q0aKGhQ4fqwIEDDjMlJSWKiYmRxWKRxWJRTEyMjh496jCzf/9+3X777WrRooW8vb2VkJCgiooKh5nt27crLCxM7u7uateunZ5//nnZbLb6/VAAAAAAAAAA1JnhR3x27dpVhYWF9m379u32fTNmzNDs2bM1d+5cbdq0Sf7+/oqIiNCxY8fsM4mJiUpPT1daWpqysrJ0/PhxRUVFqaqqyj4THR2t3NxcZWRkKCMjQ7m5uYqJibHvr6qq0pAhQ3TixAllZWUpLS1Ny5Yt09ixY+0zZWVlioiIkNVq1aZNm5SSkqKZM2dq9uzZV/gTAgAAAAAAAHC5XA0P4OrqcJTnWTabTXPmzNHTTz+tu+++W5L097//XX5+flq6dKkeeeQRlZaW6u2339bixYs1cOBASdI777yjgIAAff755xo0aJB27typjIwMZWdnq1evXpKk+fPnKzQ0VLt371ZgYKBWrFihb775Rvn5+bJarZKkWbNmKTY2Vi+88II8PT21ZMkSnT59WqmpqTKbzQoODta3336r2bNnKykpSSaT6Sp9YgAAAAAAAAB+ieFHfO7Zs0dWq1UdO3bUn/70J/3www+SpL1796qoqEiRkZH2WbPZrLCwMK1fv16SlJOTo8rKSocZq9Wq4OBg+8xXX30li8ViLz0lqXfv3rJYLA4zwcHB9tJTkgYNGqTy8nLl5OTYZ8LCwmQ2mx1mCgoKtG/fvgu+v/LycpWVlTlsAAAAAAAAAK4sQ4vPXr16adGiRfr3v/+t+fPnq6ioSH369NHhw4dVVFQkSfLz83P4GT8/P/u+oqIiubm5ycvL66Izvr6+NV7b19fXYebc1/Hy8pKbm9tFZ84+PjtzPtOmTbNfW9RisSggIODiHwoAAAAAAACAOjO0+PzDH/6ge+65R926ddPAgQP16aefSvr5lPazzj2F3Gaz/eJp5efOnG++PmbO3tjoYnkmTZqk0tJS+5afn3/R7AAAAAAAAADqzvBT3f9XixYt1K1bN+3Zs8d+3c9zj6YsLi62H2np7++viooKlZSUXHTm4MGDNV7r0KFDDjPnvk5JSYkqKysvOlNcXCyp5lGp/8tsNsvT09NhAwAAAAAAAHBlNajis7y8XDt37lTbtm3VsWNH+fv7a+XKlfb9FRUVyszMVJ8+fSRJISEhatq0qcNMYWGh8vLy7DOhoaEqLS3Vxo0b7TMbNmxQaWmpw0xeXp4KCwvtMytWrJDZbFZISIh9Zs2aNaqoqHCYsVqt6tChQ/1/GAAAAAAAAABqzdDic9y4ccrMzNTevXu1YcMG/fGPf1RZWZkeeOABmUwmJSYmKjk5Wenp6crLy1NsbKyaN2+u6OhoSZLFYlFcXJzGjh2rVatWaevWrbr//vvtp85LUpcuXTR48GDFx8crOztb2dnZio+PV1RUlAIDAyVJkZGRCgoKUkxMjLZu3apVq1Zp3Lhxio+Ptx+hGR0dLbPZrNjYWOXl5Sk9PV3Jycnc0R0AAAAAAABogFyNfPEDBw7oz3/+s3766Sf5+Piod+/eys7OVvv27SVJEyZM0KlTpzRq1CiVlJSoV69eWrFihTw8POzP8fLLL8vV1VXDhg3TqVOnNGDAAKWmpsrFxcU+s2TJEiUkJNjv/j506FDNnTvXvt/FxUWffvqpRo0apb59+8rd3V3R0dGaOXOmfcZisWjlypUaPXq0evbsKS8vLyUlJSkpKelKf0wAAAAAAAAALpPJdvYOPbgqysrKZLFYVFpaesWu9xkyftEVeV6gsct5aYTREQAAAAAAQB1dar/WoK7xCQAAAAAAAAD1geITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdBpM8Tlt2jSZTCYlJiba12w2myZPniyr1Sp3d3eFh4drx44dDj9XXl6uMWPGyNvbWy1atNDQoUN14MABh5mSkhLFxMTIYrHIYrEoJiZGR48edZjZv3+/br/9drVo0ULe3t5KSEhQRUWFw8z27dsVFhYmd3d3tWvXTs8//7xsNlu9fg4AAAAAAAAA6q5BFJ+bNm3Sm2++qRtuuMFhfcaMGZo9e7bmzp2rTZs2yd/fXxERETp27Jh9JjExUenp6UpLS1NWVpaOHz+uqKgoVVVV2Weio6OVm5urjIwMZWRkKDc3VzExMfb9VVVVGjJkiE6cOKGsrCylpaVp2bJlGjt2rH2mrKxMERERslqt2rRpk1JSUjRz5kzNnj37Cn4yAAAAAAAAAGrD1egAx48f1/DhwzV//nxNnTrVvm6z2TRnzhw9/fTTuvvuuyVJf//73+Xn56elS5fqkUceUWlpqd5++20tXrxYAwcOlCS98847CggI0Oeff65BgwZp586dysjIUHZ2tnr16iVJmj9/vkJDQ7V7924FBgZqxYoV+uabb5Sfny+r1SpJmjVrlmJjY/XCCy/I09NTS5Ys0enTp5Wamiqz2azg4GB9++23mj17tpKSkmQymc77/srLy1VeXm5/XFZWdkU+RwAAAAAAAAD/n+FHfI4ePVpDhgyxF5dn7d27V0VFRYqMjLSvmc1mhYWFaf369ZKknJwcVVZWOsxYrVYFBwfbZ7766itZLBZ76SlJvXv3lsVicZgJDg62l56SNGjQIJWXlysnJ8c+ExYWJrPZ7DBTUFCgffv2XfD9TZs2zX6KvcViUUBAwOV+RAAAAAAAAAAuk6HFZ1pamrZs2aJp06bV2FdUVCRJ8vPzc1j38/Oz7ysqKpKbm5u8vLwuOuPr61vj+X19fR1mzn0dLy8vubm5XXTm7OOzM+czadIklZaW2rf8/PwLzgIAAAAAAACoH4ad6p6fn68nnnhCK1asULNmzS44d+4p5Dab7YKnlV9o5nzz9TFz9sZGF8tjNpsdjhIFAAAAAAAAcOUZdsRnTk6OiouLFRISIldXV7m6uiozM1OvvvqqXF1dL3g0ZXFxsX2fv7+/KioqVFJSctGZgwcP1nj9Q4cOOcyc+zolJSWqrKy86ExxcbGkmkelAgAAAAAAADCWYcXngAEDtH37duXm5tq3nj17avjw4crNzVWnTp3k7++vlStX2n+moqJCmZmZ6tOnjyQpJCRETZs2dZgpLCxUXl6efSY0NFSlpaXauHGjfWbDhg0qLS11mMnLy1NhYaF9ZsWKFTKbzQoJCbHPrFmzRhUVFQ4zVqtVHTp0qP8PCAAAAAAAAECtGXaqu4eHh4KDgx3WWrRooTZt2tjXExMTlZycrOuuu07XXXedkpOT1bx5c0VHR0uSLBaL4uLiNHbsWLVp00atW7fWuHHj1K1bN/vNkrp06aLBgwcrPj5eb7zxhiTp4YcfVlRUlAIDAyVJkZGRCgoKUkxMjF566SUdOXJE48aNU3x8vDw9PSVJ0dHRmjJlimJjY/XUU09pz549Sk5O1rPPPvuLp94DAAAAAAAAuLoMKz4vxYQJE3Tq1CmNGjVKJSUl6tWrl1asWCEPDw/7zMsvvyxXV1cNGzZMp06d0oABA5SamioXFxf7zJIlS5SQkGC/+/vQoUM1d+5c+34XFxd9+umnGjVqlPr27St3d3dFR0dr5syZ9hmLxaKVK1dq9OjR6tmzp7y8vJSUlKSkpKSr8EkAAAAAAAAAuBwm29k79OCqKCsrk8ViUWlpqf1o0voWMn7RFXleoLHLeWmE0REAAAAAAEAdXWq/Ztg1PgEAAAAAAADgSqH4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4nVoVn/3799fRo0drrJeVlal///51zQQAAAAAAAAAdVKr4nP16tWqqKiosX769GmtXbu2zqEAAAAAAAAAoC5cL2d427Zt9l9/8803Kioqsj+uqqpSRkaG2rVrV3/pAAAAAAAAAKAWLqv4vPHGG2UymWQymc57Sru7u7tSUlLqLRwAAAAAAAAA1MZlFZ979+6VzWZTp06dtHHjRvn4+Nj3ubm5ydfXVy4uLvUeEgAAAAAAAAAux2UVn+3bt5ckVVdXX5EwAAAAAAAAAFAfLqv4/F/ffvutVq9ereLi4hpF6LPPPlvnYAAAAAAAAABQW7UqPufPn6/HHntM3t7e8vf3l8lksu8zmUwUnwAAAAAAAAAMVavic+rUqXrhhRc0ceLE+s4DAAAAAAAAAHXWpDY/VFJSonvvvbe+swAAAAAAAABAvahV8XnvvfdqxYoV9Z0FAAAAAAAAAOpFrU5179y5s5555hllZ2erW7duatq0qcP+hISEegkHAAAAAAAAALVRq+LzzTffVMuWLZWZmanMzEyHfSaTieITAAAAAAAAgKFqVXzu3bu3vnMAAAAAAAAAQL2p1TU+AQAAAAAAAKAhq1XxOXLkyItul2revHm64YYb5OnpKU9PT4WGhmr58uX2/TabTZMnT5bVapW7u7vCw8O1Y8cOh+coLy/XmDFj5O3trRYtWmjo0KE6cOCAw0xJSYliYmJksVhksVgUExOjo0ePOszs379ft99+u1q0aCFvb28lJCSooqLCYWb79u0KCwuTu7u72rVrp+eff142m+2S3y8AAAAAAACAq6NWxWdJSYnDVlxcrC+++EIffPBBjULxYq655hpNnz5dmzdv1ubNm9W/f3/dcccd9nJzxowZmj17tubOnatNmzbJ399fEREROnbsmP05EhMTlZ6errS0NGVlZen48eOKiopSVVWVfSY6Olq5ubnKyMhQRkaGcnNzFRMTY99fVVWlIUOG6MSJE8rKylJaWpqWLVumsWPH2mfKysoUEREhq9WqTZs2KSUlRTNnztTs2bNr8xECAAAAAAAAuIJMtno6ZLG6ulqjRo1Sp06dNGHChFo/T+vWrfXSSy9p5MiRslqtSkxM1MSJEyX9fHSnn5+fXnzxRT3yyCMqLS2Vj4+PFi9erPvuu0+SVFBQoICAAH322WcaNGiQdu7cqaCgIGVnZ6tXr16SpOzsbIWGhmrXrl0KDAzU8uXLFRUVpfz8fFmtVklSWlqaYmNjVVxcLE9PT82bN0+TJk3SwYMHZTabJUnTp09XSkqKDhw4IJPJdEnvr6ysTBaLRaWlpfL09Kz153QxIeMXXZHnBRq7nJdGGB0BAAAAAADU0aX2a/V2jc8mTZroySef1Msvv1yrn6+qqlJaWppOnDih0NBQ7d27V0VFRYqMjLTPmM1mhYWFaf369ZKknJwcVVZWOsxYrVYFBwfbZ7766itZLBZ76SlJvXv3lsVicZgJDg62l56SNGjQIJWXlysnJ8c+ExYWZi89z84UFBRo3759F3xf5eXlKisrc9gAAAAAAAAAXFn1enOj77//XmfOnLmsn9m+fbtatmwps9msRx99VOnp6QoKClJRUZEkyc/Pz2Hez8/Pvq+oqEhubm7y8vK66Iyvr2+N1/X19XWYOfd1vLy85ObmdtGZs4/PzpzPtGnT7NcWtVgsCggIuPgHAgAAAAAAAKDOXGvzQ0lJSQ6PbTabCgsL9emnn+qBBx64rOcKDAxUbm6ujh49qmXLlumBBx5QZmamff+5p5DbbLZfPK383JnzzdfHzNmrBFwsz6RJkxw+r7KyMspPAAAAAAAA4AqrVfG5detWh8dNmjSRj4+PZs2adVl3dZckNzc3de7cWZLUs2dPbdq0Sa+88or9up5FRUVq27atfb64uNh+pKW/v78qKipUUlLicNRncXGx+vTpY585ePBgjdc9dOiQw/Ns2LDBYX9JSYkqKysdZs49srO4uFhSzaNS/5fZbHY4PR4AAAAAAADAlVerU92//PJLh23VqlVKS0vTww8/LFfXWnWpdjabTeXl5erYsaP8/f21cuVK+76KigplZmbaS82QkBA1bdrUYaawsFB5eXn2mdDQUJWWlmrjxo32mQ0bNqi0tNRhJi8vT4WFhfaZFStWyGw2KyQkxD6zZs0aVVRUOMxYrVZ16NChTu8ZAAAAAAAAQP2qU0t56NAh7d69WyaTSddff718fHwu6+efeuop/eEPf1BAQICOHTumtLQ0rV69WhkZGTKZTEpMTFRycrKuu+46XXfddUpOTlbz5s0VHR0tSbJYLIqLi9PYsWPVpk0btW7dWuPGjVO3bt00cOBASVKXLl00ePBgxcfH64033pAkPfzww4qKilJgYKAkKTIyUkFBQYqJidFLL72kI0eOaNy4cYqPj7ffGSo6OlpTpkxRbGysnnrqKe3Zs0fJycl69tlnL/mO7gAAAAAAAACujloVnydOnNCYMWO0aNEiVVdXS5JcXFw0YsQIpaSkqHnz5pf0PAcPHlRMTIwKCwtlsVh0ww03KCMjQxEREZKkCRMm6NSpUxo1apRKSkrUq1cvrVixQh4eHvbnePnll+Xq6qphw4bp1KlTGjBggFJTU+Xi4mKfWbJkiRISEux3fx86dKjmzp1r3+/i4qJPP/1Uo0aNUt++feXu7q7o6GjNnDnTPmOxWLRy5UqNHj1aPXv2lJeXl5KSkmpc7xQAAAAAAACA8Uy2s3fouQyPPPKIPv/8c82dO1d9+/aVJGVlZSkhIUERERGaN29evQd1FmVlZbJYLCotLbUfTVrfQsYvuiLPCzR2OS+NMDoCAAAAAACoo0vt12p1xOeyZcv0z3/+U+Hh4fa12267Te7u7ho2bBjFJwAAAAAAAABD1ermRidPnjzvncx9fX118uTJOocCAAAAAAAAgLqoVfEZGhqq5557TqdPn7avnTp1SlOmTFFoaGi9hQMAAAAAAACA2qjVqe5z5szRH/7wB11zzTX63e9+J5PJpNzcXJnNZq1YsaK+MwIAAAAAAADAZalV8dmtWzft2bNH77zzjnbt2iWbzaY//elPGj58uNzd3es7IwAAAAAAAABclloVn9OmTZOfn5/i4+Md1hcsWKBDhw5p4sSJ9RIOAAAAAAAAAGqjVtf4fOONN/Tb3/62xnrXrl31+uuv1zkUAAAAAAAAANRFrYrPoqIitW3btsa6j4+PCgsL6xwKAAAAAAAAAOqiVsVnQECA1q1bV2N93bp1slqtdQ4FAAAAAAAAAHVRq2t8PvTQQ0pMTFRlZaX69+8vSVq1apUmTJigsWPH1mtAAAAAAAAAALhctSo+J0yYoCNHjmjUqFGqqKiQJDVr1kwTJ07UpEmT6jUgAAAAAAAAAFyuWhWfJpNJL774op555hnt3LlT7u7uuu6662Q2m+s7HwAAAAAAAABctloVn2e1bNlSv//97+srCwAAAAAAAADUi1rd3AgAAAAAAAAAGjKKTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOx9Dic9q0afr9738vDw8P+fr66s4779Tu3bsdZmw2myZPniyr1Sp3d3eFh4drx44dDjPl5eUaM2aMvL291aJFCw0dOlQHDhxwmCkpKVFMTIwsFossFotiYmJ09OhRh5n9+/fr9ttvV4sWLeTt7a2EhARVVFQ4zGzfvl1hYWFyd3dXu3bt9Pzzz8tms9XfhwIAAAAAAACgzgwtPjMzMzV69GhlZ2dr5cqVOnPmjCIjI3XixAn7zIwZMzR79mzNnTtXmzZtkr+/vyIiInTs2DH7TGJiotLT05WWlqasrCwdP35cUVFRqqqqss9ER0crNzdXGRkZysjIUG5urmJiYuz7q6qqNGTIEJ04cUJZWVlKS0vTsmXLNHbsWPtMWVmZIiIiZLVatWnTJqWkpGjmzJmaPXv2Ff6kAAAAAAAAAFwOk60BHa546NAh+fr6KjMzU7feeqtsNpusVqsSExM1ceJEST8f3enn56cXX3xRjzzyiEpLS+Xj46PFixfrvvvukyQVFBQoICBAn332mQYNGqSdO3cqKChI2dnZ6tWrlyQpOztboaGh2rVrlwIDA7V8+XJFRUUpPz9fVqtVkpSWlqbY2FgVFxfL09NT8+bN06RJk3Tw4EGZzWZJ0vTp05WSkqIDBw7IZDL94nssKyuTxWJRaWmpPD09r8THqJDxi67I8wKNXc5LI4yOAAAAAAAA6uhS+7UGdY3P0tJSSVLr1q0lSXv37lVRUZEiIyPtM2azWWFhYVq/fr0kKScnR5WVlQ4zVqtVwcHB9pmvvvpKFovFXnpKUu/evWWxWBxmgoOD7aWnJA0aNEjl5eXKycmxz4SFhdlLz7MzBQUF2rdv33nfU3l5ucrKyhw2AAAAAAAAAFdWgyk+bTabkpKSdPPNNys4OFiSVFRUJEny8/NzmPXz87PvKyoqkpubm7y8vC464+vrW+M1fX19HWbOfR0vLy+5ublddObs47Mz55o2bZr9uqIWi0UBAQG/8EkAAAAAAAAAqKsGU3w+/vjj2rZtm959990a+849hdxms/3iaeXnzpxvvj5mzl4p4EJ5Jk2apNLSUvuWn59/0dwAAAAAAAAA6q5BFJ9jxozRRx99pC+//FLXXHONfd3f319SzaMpi4uL7Uda+vv7q6KiQiUlJRedOXjwYI3XPXTokMPMua9TUlKiysrKi84UFxdLqnlU6llms1menp4OGwAAAAAAAIAry9Di02az6fHHH9cHH3ygL774Qh07dnTY37FjR/n7+2vlypX2tYqKCmVmZqpPnz6SpJCQEDVt2tRhprCwUHl5efaZ0NBQlZaWauPGjfaZDRs2qLS01GEmLy9PhYWF9pkVK1bIbDYrJCTEPrNmzRpVVFQ4zFitVnXo0KGePhUAAAAAAAAAdWVo8Tl69Gi98847Wrp0qTw8PFRUVKSioiKdOnVK0s+njycmJio5OVnp6enKy8tTbGysmjdvrujoaEmSxWJRXFycxo4dq1WrVmnr1q26//771a1bNw0cOFCS1KVLFw0ePFjx8fHKzs5Wdna24uPjFRUVpcDAQElSZGSkgoKCFBMTo61bt2rVqlUaN26c4uPj7UdpRkdHy2w2KzY2Vnl5eUpPT1dycrKSkpIu6Y7uAAAAAAAAAK4OVyNffN68eZKk8PBwh/WFCxcqNjZWkjRhwgSdOnVKo0aNUklJiXr16qUVK1bIw8PDPv/yyy/L1dVVw4YN06lTpzRgwAClpqbKxcXFPrNkyRIlJCTY7/4+dOhQzZ07177fxcVFn376qUaNGqW+ffvK3d1d0dHRmjlzpn3GYrFo5cqVGj16tHr27CkvLy8lJSUpKSmpvj8aAAAAAAAAAHVgsp29Ow+uirKyMlksFpWWll6x632GjF90RZ4XaOxyXhphdAQAAAAAAFBHl9qvNYibGwEAAAAAAABAfaL4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB1Di881a9bo9ttvl9Vqlclk0ocffuiw32azafLkybJarXJ3d1d4eLh27NjhMFNeXq4xY8bI29tbLVq00NChQ3XgwAGHmZKSEsXExMhischisSgmJkZHjx51mNm/f79uv/12tWjRQt7e3kpISFBFRYXDzPbt2xUWFiZ3d3e1a9dOzz//vGw2W719HgAAAAAAAADqh6HF54kTJ/S73/1Oc+fOPe/+GTNmaPbs2Zo7d642bdokf39/RURE6NixY/aZxMREpaenKy0tTVlZWTp+/LiioqJUVVVln4mOjlZubq4yMjKUkZGh3NxcxcTE2PdXVVVpyJAhOnHihLKyspSWlqZly5Zp7Nix9pmysjJFRETIarVq06ZNSklJ0cyZMzV79uwr8MkAAAAAAAAAqAuTrYEcsmgymZSenq4777xT0s9He1qtViUmJmrixImSfj6608/PTy+++KIeeeQRlZaWysfHR4sXL9Z9990nSSooKFBAQIA+++wzDRo0SDt37lRQUJCys7PVq1cvSVJ2drZCQ0O1a9cuBQYGavny5YqKilJ+fr6sVqskKS0tTbGxsSouLpanp6fmzZunSZMm6eDBgzKbzZKk6dOnKyUlRQcOHJDJZLqk91lWViaLxaLS0lJ5enrW50doFzJ+0RV5XqCxy3lphNERAAAAAABAHV1qv9Zgr/G5d+9eFRUVKTIy0r5mNpsVFham9evXS5JycnJUWVnpMGO1WhUcHGyf+eqrr2SxWOylpyT17t1bFovFYSY4ONheekrSoEGDVF5erpycHPtMWFiYvfQ8O1NQUKB9+/Zd8H2Ul5errKzMYQMAAAAAAABwZTXY4rOoqEiS5Ofn57Du5+dn31dUVCQ3Nzd5eXlddMbX17fG8/v6+jrMnPs6Xl5ecnNzu+jM2cdnZ85n2rRp9muLWiwWBQQEXPyNAwAAAAAAAKizBlt8nnXuKeQ2m+0XTys/d+Z88/Uxc/YqARfLM2nSJJWWltq3/Pz8i2YHAAAAAAAAUHcNtvj09/eXVPNoyuLiYvuRlv7+/qqoqFBJSclFZw4ePFjj+Q8dOuQwc+7rlJSUqLKy8qIzxcXFkmoelfq/zGazPD09HTYAAAAAAAAAV1aDLT47duwof39/rVy50r5WUVGhzMxM9enTR5IUEhKipk2bOswUFhYqLy/PPhMaGqrS0lJt3LjRPrNhwwaVlpY6zOTl5amwsNA+s2LFCpnNZoWEhNhn1qxZo4qKCocZq9WqDh061P8HAAAAAAAAAKDWDC0+jx8/rtzcXOXm5kr6+YZGubm52r9/v0wmkxITE5WcnKz09HTl5eUpNjZWzZs3V3R0tCTJYrEoLi5OY8eO1apVq7R161bdf//96tatmwYOHChJ6tKliwYPHqz4+HhlZ2crOztb8fHxioqKUmBgoCQpMjJSQUFBiomJ0datW7Vq1SqNGzdO8fHx9iM0o6OjZTabFRsbq7y8PKWnpys5OVlJSUmXfEd3AAAAAAAAAFeHq5EvvnnzZvXr18/+OCkpSZL0wAMPKDU1VRMmTNCpU6c0atQolZSUqFevXlqxYoU8PDzsP/Pyyy/L1dVVw4YN06lTpzRgwAClpqbKxcXFPrNkyRIlJCTY7/4+dOhQzZ07177fxcVFn376qUaNGqW+ffvK3d1d0dHRmjlzpn3GYrFo5cqVGj16tHr27CkvLy8lJSXZMwMAAAAAAABoOEy2s3fowVVRVlYmi8Wi0tLSK3a9z5Dxi67I8wKNXc5LI4yOAAAAAAAA6uhS+7UGe41PAAAAAAAAAKgtik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE6H4hMAAAAAAACA06H4BAAAAAAAAOB0KD4BAAAAAAAAOB2KTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdV6MDAAAuXcj4RUZHABqknJdGGB0BAAAAQAPDEZ8AAAAAAAAAnA7FJwAAAAAAAACnQ/EJAAAAAAAAwOlQfAIAAAAAAABwOhSfAAAAAAAAAJwOxScAAAAAAAAAp+NqdAAAAABIIeMXGR0BaJByXhphdAQAANBIccQnAAAAAAAAAKdD8QkAAAAAAADA6VB8AgAAAAAAAHA6FJ8AAAAAAAAAnA7FJwAAAAAAAACnw13dAQAAAOAKChm/yOgIQIOU89IIoyMAcHIc8VkLr732mjp27KhmzZopJCREa9euNToSAAAAAAAAgP/BEZ+X6b333lNiYqJee+019e3bV2+88Yb+8Ic/6JtvvtFvfvMbo+MBAAAAAICrhCO6gfNrKEd0c8TnZZo9e7bi4uL00EMPqUuXLpozZ44CAgI0b948o6MBAAAAAAAA+C+O+LwMFRUVysnJ0V/+8heH9cjISK1fv/68P1NeXq7y8nL749LSUklSWVnZFctZVX7qij030Jhdye/d1cL3Gzg/vt+A8+L7DTgvvt+A87rS3++zz2+z2S46Z7L90gTsCgoK1K5dO61bt059+vSxrycnJ+vvf/+7du/eXeNnJk+erClTplzNmAAAAAAAAIDTy8/P1zXXXHPB/RzxWQsmk8nhsc1mq7F21qRJk5SUlGR/XF1drSNHjqhNmzYX/Bk4j7KyMgUEBCg/P1+enp5GxwFQj/h+A86L7zfgvPh+A86L7/evi81m07Fjx2S1Wi86R/F5Gby9veXi4qKioiKH9eLiYvn5+Z33Z8xms8xms8Naq1atrlRENFCenp78jxdwUny/AefF9xtwXny/AefF9/vXw2Kx/OIMNze6DG5ubgoJCdHKlSsd1leuXOlw6jsAAAAAAAAAY3HE52VKSkpSTEyMevbsqdDQUL355pvav3+/Hn30UaOjAQAAAAAAAPgvis/LdN999+nw4cN6/vnnVVhYqODgYH322Wdq37690dHQAJnNZj333HM1LncAoPHj+w04L77fgPPi+w04L77fOB/u6g4AAAAAAADA6XCNTwAAAAAAAABOh+ITAAAAAAAAgNOh+AQAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiE7hMK1eu1MmTJ42OAeAKcHFxUXFxcY31w4cPy8XFxYBEAOrLmjVrdObMmRrrZ86c0Zo1awxIBKC+9O/fX0ePHq2xXlZWpv79+1/9QACABsNks9lsRocAGhNPT0+Vl5crJCREYWFhCg8PV9++fdWyZUujowGooyZNmqioqEi+vr4O6wUFBbr22mt16tQpg5IBqCsXFxcVFhbW+H4fPnxYvr6+qqqqMigZgLq60O/fxcXFateunSorKw1KBqC+nDlzRqtXr9b333+v6OhoeXh4qKCgQJ6envxdHBflanQAoLEpKSnRxo0blZmZqdWrV+tvf/ubTp8+rR49eig8PFzTp083OiKAy/Tqq69Kkkwmk9566y2HPzxVVVVpzZo1+u1vf2tUPAD1wGazyWQy1Vg/fPiwWrRoYUAiAHW1bds2+6+/+eYbFRUV2R9XVVUpIyND7dq1MyIagHr0448/avDgwdq/f7/Ky8sVEREhDw8PzZgxQ6dPn9brr79udEQ0YBzxCdRRXl6eZs6cqSVLlqi6upojRoBGqGPHjpJ+/kPVNddc43Bau5ubmzp06KDnn39evXr1MioigFq6++67JUn/+te/NHjwYJnNZvu+qqoqbdu2TYGBgcrIyDAqIoBaatKkif0fNM7311p3d3elpKRo5MiRVzsagHp05513ysPDQ2+//bbatGmjr7/+Wp06dVJmZqYeeugh7dmzx+iIaMA44hO4TDt37rQf7ZmZmamqqirdfPPNmjVrlsLCwoyOB6AW9u7dK0nq16+f0tPT1apVK2MDAag3FotF0s+liIeHh9zd3e373Nzc1Lt3b8XHxxsVD0Ad7N27VzabTZ06ddLGjRvl4+Nj3+fm5iZfX1+u0Q04gaysLK1bt05ubm4O6+3bt9d//vMfg1KhsaD4BC5T165d5ePjo8TERD3zzDPq2rWr0ZEA1IPKykr9+OOPKigooPgEnMjChQtls9lks9mUkpIiDw8PoyMBqCft27eXJFVXVxucBMCVdKEzKw8cOMDv6/hFnOoOXKbExEStWbNGO3bs0I033qjw8HCFh4frlltu4aLKQCPXrl07ff755+rSpYvRUQDUo+rqajVr1kw7duzQddddZ3QcAPVs0aJFF90/YsSIq5QEwJVw3333yWKx6M0335SHh4e2bdsmHx8f3XHHHfrNb36jhQsXGh0RDRjFJ1BLR48e1dq1a5WZmanMzExt375dN954o7Kzs42OBqCWpk+frl27dumtt96SqysnRQDOpGvXrnr77bfVu3dvo6MAqGdeXl4OjysrK3Xy5Em5ubmpefPmOnLkiEHJANSHgoIC9evXTy4uLtqzZ4969uypPXv2yNvbW2vWrJGvr6/REdGA8bc6oJaqq6t15swZVVRUqLy8XJWVldq3b5/RsQDUwYYNG7Rq1SqtWLFC3bp1q3Gn5w8++MCgZADqasaMGRo/frzmzZun4OBgo+MAqEclJSU11vbs2aPHHntM48ePNyARgPpktVqVm5urtLQ05eTkqLq6WnFxcRo+fLjDtbuB8+GIT+AyPfHEE1q9erV27Nih1q1b69Zbb7Wf7s5fpIDG7cEHH7zofk6jARovLy8vnTx5UmfOnJGbm1uNvyhxRBjgfDZv3qz7779fu3btMjoKAMAgHPEJXKb//Oc/io+Pp+gEnBDFJuC85syZY3QEAFeZi4uLCgoKjI4BoI7+/ve/y9vbW0OGDJEkTZgwQW+++aaCgoL07rvv2m90BpwPR3wCAAAAABqtjz76yOGxzWZTYWGh5s6dq4CAAC1fvtygZADqQ2BgoObNm6f+/fvrq6++0oABAzRnzhx98skncnV15XJUuCiKT6AWFi9erNdff1179+7VV199pfbt22vOnDnq2LGj7rjjDqPjAaiDf/7zn3r//fe1f/9+VVRUOOzbsmWLQakA1KdTp06psrLSYc3T09OgNADqqkmTJg6PTSaTfHx81L9/f82aNUtt27Y1KBmA+tC8eXPt2rVLv/nNbzRx4kQVFhZq0aJF2rFjh8LDw3Xo0CGjI6IBa/LLIwD+17x585SUlKTbbrtNR48eVVVVlSSpVatWnEYHNHKvvvqqHnzwQfn6+mrr1q266aab1KZNG/3www/6wx/+YHQ8AHVw4sQJPf744/L19VXLli3l5eXlsAFovKqrqx22qqoqFRUVaenSpZSegBNo2bKlDh8+LElasWKFBg4cKElq1qyZTp06ZWQ0NAIUn8BlSklJ0fz58/X000/LxcXFvt6zZ09t377dwGQA6uq1117Tm2++qblz58rNzU0TJkzQypUrlZCQoNLSUqPjAaiDCRMm6IsvvtBrr70ms9mst956S1OmTJHVatWiRYuMjgegnthsNnFSI+BcIiIi9NBDD+mhhx7St99+a7/W544dO9ShQwdjw6HBo/gELtPevXvVvXv3Gutms1knTpwwIBGA+rJ//3716dNHkuTu7q5jx45JkmJiYvTuu+8aGQ1AHX388cd67bXX9Mc//lGurq665ZZb9H//939KTk7WkiVLjI4HoI4WLVqkbt26yd3dXe7u7rrhhhu0ePFio2MBqAd/+9vfFBoaqkOHDmnZsmVq06aNJCknJ0d//vOfDU6Hho67ugOXqWPHjsrNza1x57jly5crKCjIoFQA6oO/v78OHz6s9u3bq3379srOztbvfvc77d27l6NHgEbuyJEj6tixo6Sfr+d55MgRSdLNN9+sxx57zMhoAOpo9uzZeuaZZ/T444+rb9++stlsWrdunR599FH99NNPevLJJ42OCKAOWrVqpblz59ZYnzJligFp0NhQfAKXafz48Ro9erROnz4tm82mjRs36t1339W0adP01ltvGR0PQB30799fH3/8sXr06KG4uDg9+eST+uc//6nNmzfr7rvvNjoegDro1KmT9u3bp/bt2ysoKEjvv/++brrpJn388cdq1aqV0fEA1EFKSormzZunESNG2NfuuOMOde3aVZMnT6b4BJzEyZMnz3sD0htuuMGgRGgMuKs7UAvz58/X1KlTlZ+fL0lq166dJk+erLi4OIOTAaiLszdFcHX9+d8F33//fWVlZalz58569NFH5ebmZnBCALX18ssvy8XFRQkJCfryyy81ZMgQVVVV6cyZM5o9e7aeeOIJoyMCqKVmzZopLy9PnTt3dljfs2ePunXrptOnTxuUDEB9OHTokGJjY5WRkXHe/WdvOAycD8UnUAc//fSTqqur5evra3QUAABwGfbv36/Nmzfr2muv1e9+9zuj4wCog+DgYEVHR+upp55yWJ86daree+89bkAKNHLDhw/Xvn37NGfOHPXr10/p6ek6ePCgpk6dqlmzZtlvdgScD8UnAOBXb8+ePXr22Wf1xhtvyNPT02FfaWmpHnvsMU2dOlWdOnUyKCEAALiQZcuW6b777tPAgQPVt29fmUwmZWVladWqVXr//fd11113GR0RQB20bdtW//rXv3TTTTfJ09NTmzdv1vXXX6+PPvpIM2bMUFZWltER0YBxV3fgEvTo0UMlJSWSpO7du6tHjx4X3AA0Pi+99JICAgJqlJ6SZLFYFBAQoJdeesmAZADq6osvvlBQUJDKyspq7CstLVXXrl21du1aA5IBqC/33HOPNmzYIG9vb3344Yf64IMP5O3trY0bN1J6Ak7gxIkT9rMsW7durUOHDkmSunXrpi1bthgZDY0ANzcCLsEdd9yhb775Rn379tWdd95pdBwA9WzNmjVavHjxBfcPGzZM0dHRVzERgPoyZ84cxcfHX/AfNh555BHNnj1bt9xyiwHpANSHbdu2KSQkRO+8806NfR9++CF/fgcaucDAQO3evVsdOnTQjTfeqDfeeEMdOnTQ66+/rrZt2xodDw0cp7oDl6hJkybq3r274uLiNHz4cFksFqMjAagn7u7u2rVrl9q3b3/e/T/++KO6dOmikydPXuVkAOqqffv2ysjIUJcuXc67f9euXYqMjNT+/fuvcjIA9aVt27Zat25djUvSLFu2TCNGjNCJEycMSgagPixZskSVlZWKjY3V1q1bNWjQIB0+fFhubm5KTU3VfffdZ3RENGCc6g5conXr1qlHjx6aNGmS2rZtq5iYGH355ZdGxwJQDywWi77//vsL7v/uu+/Oe7QYgIbv4MGDatq06QX3u7q62k+ZA9A4PfbYYxowYIAKCwvta++9955GjBih1NRU44IBqBfDhw9XbGyspJ8vPbdv3z5t2rRJ+fn5lJ74RRSfwCUKDQ3V/PnzVVRUpHnz5ik/P18DBw7UtddeqxdeeEEHDhwwOiKAWrr11luVkpJywf2vvvoqp8ECjVS7du0uekfnbdu2cZoc0Mg9++yzGjp0qAYOHKgjR45o6dKlevDBB7Vo0SLde++9RscDUM+aN2+uHj16yNvb2+goaAQ41R2og++//14LFy7UokWLVFhYqIiICH322WdGxwJwmbZu3arQ0FBFRUVpwoQJCgwMlPTzKbAzZszQp59+qvXr13MDM6ARGjNmjFavXq1NmzapWbNmDvtOnTqlm266Sf369dOrr75qUEIA9SUmJkYbNmzQf/7zHy1dulR33HGH0ZEA1IOqqiqlpqZq1apVKi4uVnV1tcP+L774wqBkaAwoPoE6On78uJYsWaKnnnpKR48eVVVVldGRANTCJ598opEjR+rw4cMO623atNFbb72loUOHGpQMQF0cPHhQPXr0kIuLix5//HEFBgbKZDJp586d+tvf/qaqqipt2bJFfn5+RkcFcBk++uijGmuVlZV68sknFRkZ6fD7Nr+HA43b448/rtTUVA0ZMkRt27aVyWRy2P/yyy8blAyNAcUnUEuZmZlasGCBli1bJhcXFw0bNkxxcXHq3bu30dEA1NKpU6eUkZGh7777TjabTddff70iIyPVvHlzo6MBqIMff/xRjz32mP7973/r7B99TSaTBg0apNdee00dOnQwNiCAy9akyaVdtc1kMnFgAtDIeXt7a9GiRbrtttuMjoJGiOITuAz5+flKTU1Vamqq9u7dqz59+iguLk7Dhg1TixYtjI4HAAAuoqSkxP4PG9ddd528vLyMjgQAAH6B1WrV6tWrdf311xsdBY0QxSdwiSIiIvTll1/Kx8dHI0aM0MiRI+3XAQTgPDIzMzVz5kzt3LlTJpNJXbp00fjx47m5EdDIrVy5UjfffLPc3d2NjgIAAC7DrFmz9MMPP2ju3Lk1TnMHfgnFJ3CJhg4dqri4OEVFRcnFxcXoOACugHfeeUcPPvig7r77bvXt21c2m03r169Xenq6UlNTFR0dbXREALXk6emp8vJyhYSEKCwsTOHh4erbt69atmxpdDQAdZSQkKDOnTsrISHBYX3u3Ln67rvvNGfOHGOCAai1u+++2+HxF198odatW6tr165q2rSpw74PPvjgakZDI0PxCQDAf3Xp0kUPP/ywnnzySYf12bNna/78+dq5c6dByQDUVVVVlTZu3KjMzEytXr1a69ev1+nTp9WjRw+Fh4dr+vTpRkcEUEvt2rXTRx99pJCQEIf1LVu2aOjQoTpw4IBByQDU1oMPPnjJswsXLryCSdDYUXwCAPBfZrNZO3bsUOfOnR3Wv/vuOwUHB+v06dMGJQNQ3/Ly8jRz5kwtWbJE1dXV3PwEaMSaNWumvLw8fv8GANRwabfCAwDgVyAgIECrVq2qsb5q1SoFBAQYkAhAfdm5c6def/11/elPf1Lbtm3Vv39/lZWVadasWdqyZYvR8QDUQefOnZWRkVFjffny5erUqZMBiQDUp71792rPnj011vfs2aN9+/Zd/UBoVFyNDgAAgNFGjhypV155RWPHjlVCQoJyc3PVp08fmUwmZWVlKTU1Va+88orRMQHUQdeuXeXj46PExEQ988wz6tq1q9GRANSTpKQkPf744zp06JD69+8v6ed/tJw1axbX9wScQGxsrEaOHKnrrrvOYX3Dhg166623tHr1amOCoVHgVHcAwK+ei4uLCgsL5evrq/T0dM2aNct+Pc+zd3W/4447DE4JoC4SExO1Zs0a7dixQzfeeKPCw8MVHh6uW265hRscAU5g3rx5euGFF1RQUCBJ6tChgyZPnqwRI0YYnAxAXXl6emrLli3nvZxFz549dfToUWOCoVGg+AQA/Oo1adJERUVF8vX1NToKgCvs6NGjWrt2rTIzM5WZmant27frxhtvVHZ2ttHRANSDQ4cOyd3dnX/QAJyIxWLR6tWr1b17d4f1nJwchYeH69ixYwYlQ2PANT4BAJBkMpmMjgDgKqiurtaZM2dUUVGh8vJyVVZWcn0wwAmcOXNGn3/+uT744AOdPbanoKBAx48fNzgZgLq65ZZbNG3aNIcbEVZVVWnatGm6+eabDUyGxoAjPgEAv3pNmjSRxWL5xfLzyJEjVykRgPr2xBNPaPXq1dqxY4dat26tW2+91X66e3BwsNHxANTBjz/+qMGDB2v//v0qLy/Xt99+q06dOikxMVGnT5/W66+/bnREAHWwY8cOhYWFqVWrVrrlllskSWvXrlVZWZm++OILfh/HRXFzIwAAJE2ZMkUWi8XoGACukP/85z+Kj4+n6ASc0BNPPKGePXvq66+/Vps2bezrd911lx566CEDkwGoD127dtW2bds0d+5cff3113J3d9eIESP0+OOPq3Xr1kbHQwPHEZ8AgF89rvEJAEDj5e3trXXr1ikwMFAeHh76+uuv1alTJ+3bt09BQUE6efKk0REB1FJlZaUiIyP1xhtv6Prrrzc6DhohrvEJAPjV4/qewK/D4sWL1bdvX1mtVv3444+SpDlz5uhf//qXwckA1EV1dbXDtf/OOnDggDw8PAxIBKC+NG3aVHl5efx5HbVG8QkA+NXj5AfA+c2bN09JSUm67bbbdPToUXtJ0qpVK82ZM8fYcADqJCIiwuF7bDKZdPz4cT333HO67bbbjAsGoF6MGDFCb7/9ttEx0EhxqjsAAACcXlBQkJKTk3XnnXc6nAqbl5en8PBw/fTTT0ZHBFBLBQUF6tevn1xcXLRnzx717NlTe/bskbe3t9asWcOlbIBGbsyYMVq0aJE6d+6snj17qkWLFg77Z8+ebVAyNAbc3AgA8Kt29913X/LsBx98cAWTALiS9u7dq+7du9dYN5vNOnHihAGJANQXq9Wq3Nxcvfvuu9qyZYuqq6sVFxen4cOHy93d3eh4AOooLy9PPXr0kCR9++23Dvs4BR6/hOITAPCr9r93crfZbEpPT5fFYlHPnj0lSTk5OTp69OhlFaQAGp6OHTsqNzdX7du3d1hfvny5goKCDEoFoL64u7tr5MiRGjlypNFRANSzL7/80ugIaMQoPgEAv2oLFy60/3rixIkaNmyYXn/9dbm4uEiSqqqqNGrUKHl6ehoVEUA9GD9+vEaPHq3Tp0/LZrNp48aNevfddzVt2jS99dZbRscDUEfffvutVq9ereLiYlVXVzvse/bZZw1KBQAwGtf4BADgv3x8fJSVlaXAwECH9d27d6tPnz46fPiwQckA1If58+dr6tSpys/PlyS1a9dOkydPVlxcnMHJANTF/Pnz9dhjj8nb21v+/v4Op76aTCZt2bLFwHQA6qpfv34XPaX9iy++uIpp0NhwxCcAAP915swZ7dy5s0bxuXPnzhpHjwBofOLj4xUfH6+ffvpJ1dXV3PAEcBJTp07VCy+8oIkTJxodBcAVcOONNzo8rqysVG5urvLy8vTAAw8YEwqNBsUnAAD/9eCDD2rkyJH67rvv1Lt3b0lSdna2pk+frgcffNDgdADqi7e3t9ERANSjkpIS3XvvvUbHAHCFvPzyy+ddnzx5so4fP36V06Cx4VR3AAD+q7q6WjNnztQrr7yiwsJCSVLbtm31xBNPaOzYsfbrfgJoHHr06KFVq1bJy8tL3bt3v+hpcpwKCzRecXFx+v3vf69HH33U6CgArqLvvvtON910k44cOWJ0FDRgHPEJAMB/NWnSRBMmTNCECRNUVlYmSdzUCGjE7rjjDn3zzTfq27ev7rzzTqPjAKhHr776qv3XnTt31jPPPKPs7Gx169ZNTZs2dZhNSEi42vEAXAVfffWVmjVrZnQMNHAc8QkAAACn1aRJE3Xv3l1xcXEaPny4LBaL0ZEA1IOOHTte0pzJZNIPP/xwhdMAuJLuuusuh7M2bDabCgsLtXnzZj3zzDN67rnnDEyHho7iEwDwq/ZLp7/+L06FBRqfr776SgsWLND777+vyspK3XPPPRo5cqT69etndDQAAHAJHnzwQZlMJp2tr5o0aSIfHx/1799fkZGRBqdDQ0fxCQD4VZsyZYr916dPn9Zrr72moKAghYaGSvr55kY7duzQqFGjNG3aNKNiAqijU6dO6f3339fChQu1du1adejQQSNHjtQDDzyga665xuh4AGqprKxMLVu2VJMmTRzWq6urdfz4cS5ZAzRiJ0+e1Pjx45Wenq4zZ85owIABSklJ4SaFuCwUnwAA/NdDDz2ktm3b6q9//avD+nPPPaf8/HwtWLDAoGQA6tP333+vhQsXatGiRSosLFRERIQ+++wzo2MBuEzp6emaOHGicnNz1bx5c4d9J0+eVPfu3TVz5kzdfvvtBiUEUBfjx4/Xa6+9puHDh8vd3V1Lly5VeHi4/vGPfxgdDY0IxScAAP9lsVi0efNmXXfddQ7re/bsUc+ePVVaWmpQMgD17fjx41qyZImeeuopHT16VFVVVUZHAnCZIiMjNWzYMD300EPn3b9gwQK99957+ve//32VkwGoD9dee61eeOEF/elPf5Ikbdy4UX379tXp06fl4uJicDo0Fk1+eQQAgF8Hd3d3ZWVl1VjPysrijpGAk8jMzNQDDzwgf39/TZgwQXfffbfWrVtndCwAtZCXl6fw8PAL7r/11lu1ffv2qxcIQL3Kz8/XLbfcYn980003ydXVVQUFBQamQmPjanQAAAAaisTERD322GPKyclR7969Jf18jc+3336bu0UCjVh+fr5SU1OVmpqqvXv3qk+fPkpJSdGwYcPUokULo+MBqKWSkhKdOXPmgvsrKytVUlJyFRMBqE9VVVVyc3NzWHN1db3o9x44F8UnAAD/9Ze//EWdOnXSK6+8oqVLl0qSgoKCtGjRohqnvwNoHCIiIvTll1/Kx8dHI0aM0MiRIxUYGGh0LAD1oEOHDtq8ebN++9vfnnf/5s2b1b59+6ucCkB9sdlsio2Nldlstq+dPn1ajz76qMM/XH7wwQdGxEMjwTU+AQC4gKNHj2rJkiV6++239fXXX3MNQKARGjp0qOLi4hQVFcX1wAAn8/TTT+udd97Rxo0b5efn57CvqKhIvXr10v33368XXnjBoIQA6uLBBx+8pLmFCxde4SRozCg+AQA4xxdffKEFCxbogw8+UPv27XXPPffonnvuUffu3Y2OBgAA/uvYsWMKDQ3V/v37df/99yswMFAmk0k7d+7UkiVLFBAQoOzsbHl4eBgdFQBgEE51BwBA0oEDB5SamqoFCxboxIkTGjZsmCorK7Vs2TIFBQUZHQ8AAJzDw8ND69at06RJk/Tee+/Zr+fp5eWl+++/X8nJyZSeAPArxxGfAIBfvdtuu01ZWVmKiorS8OHDNXjwYLm4uKhp06b6+uuvKT4BAGjgbDabfvrpJ9lsNvn4+MhkMhkdCQDQADQxOgAAAEZbsWKFHnroIU2ZMkVDhgzhOoAAADQi/fv3V2lpqXx8fOTr62svPcvKytS/f3+D0wEAjETxCQD41Vu7dq2OHTumnj17qlevXpo7d64OHTpkdCwAAHAJVq9erYqKihrrp0+f1tq1aw1IBABoKLjGJwDgVy80NFShoaF65ZVXlJaWpgULFigpKUnV1dVauXKlAgICuEYYAAANzLZt2+y//uabb1RUVGR/XFVVpYyMDLVr186IaACABoJrfAIAcB67d+/W22+/rcWLF+vo0aOKiIjQRx99ZHQsAADwX02aNLGf1n6+v9a6u7srJSVFI0eOvNrRAAANBMUnAAAXUVVVpY8//lgLFiyg+AQAoAH58ccfZbPZ1KlTJ23cuFE+Pj72fW5ubvL19eW63QDwK0fxCQAAAABolCorKxUfH69nn31WnTp1MjoOAKCB4eZGAAAAAIBGqWnTpvrXv/5ldAwAQANF8QkAAAAAaLTuvPNOffjhh0bHAAA0QNzVHQAAAADQaHXu3Fl//etftX79eoWEhKhFixYO+xMSEgxKBgAwGtf4BAAAAAA0Wh07drzgPpPJpB9++OEqpgEANCQUnwAAAAAAAACcDtf4BAAAAAAAAOB0uMYnAAAAAKBRO3DggD766CPt379fFRUVDvtmz55tUCoAgNEoPgEAAAAAjdaqVas0dOhQdezYUbt371ZwcLD27dsnm82mHj16GB0PAGAgTnUHAAAAADRakyZN0tixY5WXl6dmzZpp2bJlys/PV1hYmO69916j4wEADMTNjQAAAAAAjZaHh4dyc3N17bXXysvLS1lZWeratau+/vpr3XHHHdq3b5/REQEABuGITwAAAABAo9WiRQuVl5dLkqxWq77//nv7vp9++smoWACABoBrfAIAAAAAGq3evXtr3bp1CgoK0pAhQzR27Fht375dH3zwgXr37m10PACAgTjVHQAAAADQaP3www86fvy4brjhBp08eVLjxo1TVlaWOnfurJdfflnt27c3OiIAwCAUnwAAAAAAAACcDtf4BAAAAAA0Wp06ddLhw4drrB89elSdOnUyIBEAoKGg+AQAAAAANFr79u1TVVVVjfXy8nL95z//MSARAKCh4OZGAAAAAIBG56OPPrL/+t///rcsFov9cVVVlVatWqUOHToYkAwA0FBwjU8AAAAAQKPTpMnPJzCaTCad+9fapk2bqkOHDpo1a5aioqKMiAcAaAAoPgEAAAAAjVbHjh21adMmeXt7Gx0FANDAcI1PAAAAAECjs2HDBi1fvlx79+61l56LFi1Sx44d5evrq4cffljl5eUGpwQAGIniEwAAAADQ6Dz33HPatm2b/fH27dsVFxengQMH6i9/+Ys+/vhjTZs2zcCEAACjcao7AAAAAKDRadu2rT7++GP17NlTkvT0008rMzNTWVlZkqR//OMfeu655/TNN98YGRMAYCCO+AQAAAAANDolJSXy8/OzP87MzNTgwYPtj3//+98rPz/fiGgAgAaC4hMAAAAA0Oj4+flp7969kqSKigpt2bJFoaGh9v3Hjh1T06ZNjYoHAGgAKD4BAAAAAI3O4MGD9Ze//EVr167VpEmT1Lx5c91yyy32/du2bdO1115rYEIAgNFcjQ4AAAAAAMDlmjp1qu6++26FhYWpZcuW+vvf/y43Nzf7/gULFigyMtLAhAAAo3FzIwAAAABAo1VaWqqWLVvKxcXFYf3IkSNq2bKlQxkKAPh1ofgEAAAAAAAA4HS4xicAAAAAAAAAp0PxCQAAAAAAAMDpUHwCAAAAAAAAcDoUnwAAAAAAAACcDsUnAAAAAAAAAKdD8QkAAICrIjY2ViaTqcbWv39/eXt7a+rUqef9uWnTpsnb21sVFRVKTU0973M0a9asxutMnz7d4Xk+/PBDmUymi2b53+1ifulno6Oj1bx5cy1dutTh56qrq9WnTx/dddddNXI0bdpUnTp10rhx43TixAlJ0r59+y74GtnZ2Zf3HwAAAOBXxtXoAAAAAPj1GDx4sBYuXOiwZjabNWXKFKWmpurpp5+uUTouXLhQMTExcnNzkyR5enpq9+7dDjPn/kyzZs304osv6pFHHpGXl1eNHK+88opDMdq2bVstXLhQgwcPvqT3UVhYaP/1e++9p2effdYhk7u7u3r37q0xY8aoX79+atu2rSRp1qxZ+u677/Thhx/aZ89+JpWVlVq7dq0eeughnThxQvPmzbPPfP755+ratatDhjZt2lxSVgAAgF8rik8AAABcNWazWf7+/jXW4+Li9Morr2jNmjUKCwuzr69du1Z79uxRXFycfc1kMp33Of7XwIED9d1332natGmaMWNGjf0Wi0UWi8VhrVWrVr/4vGf975zFYjlvpjFjxuhf//qX4uPj9cknn2jXrl169tln9e6778rX19c+97+fSXR0tL788kt9+OGHDsVnmzZtLjkbAAAAfsap7gAAADBct27d9Pvf/77G0aALFizQTTfdpODg4Mt6PhcXFyUnJyslJUUHDhyoz6iXzGQyaeHChVq7dq3mz5+v2NhY3Xfffbrzzjsv+nPu7u6qrKy8OiEBAACcGMUnAAAArppPPvlELVu2dNj++te/SpJGjhypf/7znzp+/Lgk6fjx4/rHP/7hcLSnJJWWltZ4jsjIyBqvddddd+nGG2/Uc889d+Xf2AX85je/0Zw5c/Too4+qoKBAr7zyykXnN27cqKVLl2rAgAEO63369Knxnquqqq5kdAAAgEaPU90BAABw1fTr18/hFG5Jat26tSTpz3/+s5KSkvTee+8pLi5O7733nmw2m/70pz85zHt4eGjLli0Oa+7u7ud9vRdffFH9+/fX2LFj6/FdXJ4HH3xQzzzzjBISEmqcXi/9/zL4zJkzqqys1B133KGUlBSHmffee09dunRxWHNxcbmiuQEAABo7ik8AAABcNS1atFDnzp3Pu89iseiPf/yjFi5cqLi4OC1cuFB//OMf5enp6TDXpEmTCz7HuW699VYNGjRITz31lGJjY+sav9ZcXV3l6nr+P3qfLYObNm0qq9Wqpk2b1pgJCAi45PcMAACAn1F8AgAAoMGIi4tTeHi4PvnkE61bt07Jycl1fs7p06frxhtv1PXXX18PCevfxcpgAAAA1B7FJwAAAK6a8vJyFRUVOay5urrK29tbkhQWFqbOnTtrxIgR6ty5s2699dYaz2Gz2Wo8hyT5+vqqSZOal7Dv1q2bhg8fXuP08cbk8OHDNd5zq1at1KxZM4MSAQAANHzc3AgAAABXTUZGhtq2beuw3XzzzQ4zI0eOVElJiUaOHHne5ygrK6vxHG3btlVxcfEFX/evf/2rbDZbvb6Xq2ngwIE13u+HH35odCwAAIAGzWRrzH8CBAAAAAAAAIDz4IhPAAAAAAAAAE6H4hMAAAA4x/79+9WyZcsLbvv37zc6IgAAAH4Bp7oDAAAA5zhz5oz27dt3wf0dOnSQqyv3CQUAAGjIKD4BAAAAAAAAOB1OdQcAAAAAAADgdCg+AQAAAAAAADgdik8AAAAAAAAATofiEwAAAAAAAIDTofgEAAAAAAAA4HQoPgEAAAAAAAA4HYpPAAAAAAAAAE7n/wGHIllQ6aT1HQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_attributes = interaction_data.select_dtypes(include = ['object'])\n",
    "\n",
    "plt.figure(figsize=(16,3))\n",
    "chart = sns.countplot(data = categorical_attributes, x = 'EVENT_TYPE')\n",
    "plt.xticks(rotation=90, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Amazon Personalize, you need to save timestamps in Unix Epoch format.\n",
    "\n",
    "Lets validate that the timestamp is actually in a Unix Epoch format by converting it into a more easily understood time/date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\n",
      "1716368521\n",
      "\n",
      "Date & Time\n",
      "2024-05-22 09:02:01\n"
     ]
    }
   ],
   "source": [
    "arb_time_stamp = interaction_data.iloc[50]['TIMESTAMP']\n",
    "print('timestamp')\n",
    "print(arb_time_stamp)\n",
    "print()\n",
    "print('Date & Time')\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some general summarization and inspection of the data to ensure that it will be helpful for Amazon Personalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITEM_ID       False\n",
       "USER_ID       False\n",
       "EVENT_TYPE    False\n",
       "TIMESTAMP     False\n",
       "DISCOUNT      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 675004 entries, 0 to 675003\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   ITEM_ID     675004 non-null  object\n",
      " 1   USER_ID     675004 non-null  int64 \n",
      " 2   EVENT_TYPE  675004 non-null  object\n",
      " 3   TIMESTAMP   675004 non-null  int64 \n",
      " 4   DISCOUNT    675004 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 25.7+ MB\n"
     ]
    }
   ],
   "source": [
    "interaction_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save to local storage\n",
    "interaction_data.to_csv((\"./poc_data/data/interactions.csv\"), index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Users Dataset\n",
    "[Back to top](#top)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This is a synthetic dataset and since it is randomly assigned, will be of little value to our model, in a real world scenario this data would be accurate to the user data.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID  AGE GENDER\n",
       "0        1   31      M\n",
       "1        2   58      F\n",
       "2        3   43      M\n",
       "3        4   38      M\n",
       "4        5   24      M"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data = pd.read_csv(raw_users_file_path)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also leverage some syntectic user metadata to get some additional information about our users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>selectable_user</th>\n",
       "      <th>gender</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>age</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>persona</th>\n",
       "      <th>discount_persona</th>\n",
       "      <th>traits</th>\n",
       "      <th>platforms</th>\n",
       "      <th>addresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>mark.johnson@example.com</td>\n",
       "      <td>31</td>\n",
       "      <td>Mark Johnson</td>\n",
       "      <td>user1</td>\n",
       "      <td>furniture_homedecor_housewares</td>\n",
       "      <td>lower_priced_products</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'ios': {'anonymous_id': '0822e8f3-6c03-4199-9...</td>\n",
       "      <td>[{'first_name': 'Mark', 'last_name': 'Johnson'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>Kristen</td>\n",
       "      <td>Calderon</td>\n",
       "      <td>kristen.calderon@example.com</td>\n",
       "      <td>58</td>\n",
       "      <td>Kristen Calderon</td>\n",
       "      <td>user2</td>\n",
       "      <td>tools_housewares_apparel</td>\n",
       "      <td>discount_indifferent</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'ios': {'anonymous_id': 'fc377a4c-4a15-444d-8...</td>\n",
       "      <td>[{'first_name': 'Kristen', 'last_name': 'Calde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>5249</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>Vincent</td>\n",
       "      <td>Wells</td>\n",
       "      <td>vincent.wells@example.com</td>\n",
       "      <td>33</td>\n",
       "      <td>Vincent Wells</td>\n",
       "      <td>user5249</td>\n",
       "      <td>housewares_floral_seasonal</td>\n",
       "      <td>discount_indifferent</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'ios': {'anonymous_id': 'e3214a29-7376-4691-b...</td>\n",
       "      <td>[{'first_name': 'Vincent', 'last_name': 'Wells...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>5250</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>Monica</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>monica.garcia@example.com</td>\n",
       "      <td>34</td>\n",
       "      <td>Monica Garcia</td>\n",
       "      <td>user5250</td>\n",
       "      <td>housewares_tools_beauty</td>\n",
       "      <td>discount_indifferent</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'ios': {'anonymous_id': 'c7d26d9d-2041-4dc6-a...</td>\n",
       "      <td>[{'first_name': 'Monica', 'last_name': 'Garcia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5250 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  selectable_user gender first_name last_name  \\\n",
       "0        1             True      M       Mark   Johnson   \n",
       "1        2             True      F    Kristen  Calderon   \n",
       "...    ...              ...    ...        ...       ...   \n",
       "5248  5249             True      M    Vincent     Wells   \n",
       "5249  5250             True      F     Monica    Garcia   \n",
       "\n",
       "                             email  age              name  username  \\\n",
       "0         mark.johnson@example.com   31      Mark Johnson     user1   \n",
       "1     kristen.calderon@example.com   58  Kristen Calderon     user2   \n",
       "...                            ...  ...               ...       ...   \n",
       "5248     vincent.wells@example.com   33     Vincent Wells  user5249   \n",
       "5249     monica.garcia@example.com   34     Monica Garcia  user5250   \n",
       "\n",
       "                             persona       discount_persona traits  \\\n",
       "0     furniture_homedecor_housewares  lower_priced_products     {}   \n",
       "1           tools_housewares_apparel   discount_indifferent     {}   \n",
       "...                              ...                    ...    ...   \n",
       "5248      housewares_floral_seasonal   discount_indifferent     {}   \n",
       "5249         housewares_tools_beauty   discount_indifferent     {}   \n",
       "\n",
       "                                              platforms  \\\n",
       "0     {'ios': {'anonymous_id': '0822e8f3-6c03-4199-9...   \n",
       "1     {'ios': {'anonymous_id': 'fc377a4c-4a15-444d-8...   \n",
       "...                                                 ...   \n",
       "5248  {'ios': {'anonymous_id': 'e3214a29-7376-4691-b...   \n",
       "5249  {'ios': {'anonymous_id': 'c7d26d9d-2041-4dc6-a...   \n",
       "\n",
       "                                              addresses  \n",
       "0     [{'first_name': 'Mark', 'last_name': 'Johnson'...  \n",
       "1     [{'first_name': 'Kristen', 'last_name': 'Calde...  \n",
       "...                                                 ...  \n",
       "5248  [{'first_name': 'Vincent', 'last_name': 'Wells...  \n",
       "5249  [{'first_name': 'Monica', 'last_name': 'Garcia...  \n",
       "\n",
       "[5250 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_metadata_df = pd.read_json (user_metadata_file_name)\n",
    "user_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save to local storage\n",
    "user_data.to_csv((\"./poc_data/data/users.csv\"), index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Items Dataset\n",
    "\n",
    "Let us look at the items dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>CATEGORY_L1</th>\n",
       "      <th>CATEGORY_L2</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>PRODUCT_DESCRIPTION</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>PROMOTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6579c22f-be2b-444c-a52b-0116dd82df6c</td>\n",
       "      <td>129.99</td>\n",
       "      <td>accessories</td>\n",
       "      <td>backpack</td>\n",
       "      <td>Adventure-Ready Expedition Backpack</td>\n",
       "      <td>Embark on your next outdoor journey with our r...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e852905-c6f4-47db-802c-654013571922</td>\n",
       "      <td>149.99</td>\n",
       "      <td>accessories</td>\n",
       "      <td>backpack</td>\n",
       "      <td>Mauve Leather Daypack</td>\n",
       "      <td>This stylish mauve leather daypack combines el...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ec7ff5c-f70f-4984-b6c4-c7ef37cc0c09</td>\n",
       "      <td>49.99</td>\n",
       "      <td>accessories</td>\n",
       "      <td>backpack</td>\n",
       "      <td>Lacy Crochet Summer Backpack</td>\n",
       "      <td>Embrace summer vibes with our Lacy Crochet Bac...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7977f680-2cf7-457d-8f4d-afa0aa168cb9</td>\n",
       "      <td>89.99</td>\n",
       "      <td>accessories</td>\n",
       "      <td>backpack</td>\n",
       "      <td>Adventure-Ready Rugged Backpack</td>\n",
       "      <td>Embark on your next journey with our Adventure...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5649d7c-4651-458d-a07f-912f253784ce</td>\n",
       "      <td>189.99</td>\n",
       "      <td>accessories</td>\n",
       "      <td>backpack</td>\n",
       "      <td>Chic Caramel Leather Backpack</td>\n",
       "      <td>Elevate your everyday style with our Chic Cara...</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ITEM_ID   PRICE  CATEGORY_L1 CATEGORY_L2  \\\n",
       "0  6579c22f-be2b-444c-a52b-0116dd82df6c  129.99  accessories    backpack   \n",
       "1  2e852905-c6f4-47db-802c-654013571922  149.99  accessories    backpack   \n",
       "2  4ec7ff5c-f70f-4984-b6c4-c7ef37cc0c09   49.99  accessories    backpack   \n",
       "3  7977f680-2cf7-457d-8f4d-afa0aa168cb9   89.99  accessories    backpack   \n",
       "4  b5649d7c-4651-458d-a07f-912f253784ce  189.99  accessories    backpack   \n",
       "\n",
       "                          PRODUCT_NAME  \\\n",
       "0  Adventure-Ready Expedition Backpack   \n",
       "1                Mauve Leather Daypack   \n",
       "2         Lacy Crochet Summer Backpack   \n",
       "3      Adventure-Ready Rugged Backpack   \n",
       "4        Chic Caramel Leather Backpack   \n",
       "\n",
       "                                 PRODUCT_DESCRIPTION GENDER PROMOTED  \n",
       "0  Embark on your next outdoor journey with our r...      F      NaN  \n",
       "1  This stylish mauve leather daypack combines el...      F      NaN  \n",
       "2  Embrace summer vibes with our Lacy Crochet Bac...      F      NaN  \n",
       "3  Embark on your next journey with our Adventure...      F      NaN  \n",
       "4  Elevate your everyday style with our Chic Cara...      F      NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data = pd.read_csv(raw_items_file_path)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "item_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save to local storage\n",
    "item_data.to_csv((\"./poc_data/data/items.csv\"), index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load some additional metadata about each item that will help make the recommended items more readable in this workshop. This is data you'd typically find in an item catalog system/database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>style</th>\n",
       "      <th>featured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6579c22f-be2b-444c-a52b-0116dd82df6c</td>\n",
       "      <td>Adventure-Ready Expedition Backpack</td>\n",
       "      <td>accessories</td>\n",
       "      <td>backpack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e852905-c6f4-47db-802c-654013571922</td>\n",
       "      <td>Mauve Leather Daypack</td>\n",
       "      <td>accessories</td>\n",
       "      <td>backpack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>7000f6e7-41f7-4957-878a-ccc42a39ca59</td>\n",
       "      <td>Elegant Aroma Espresso Cup</td>\n",
       "      <td>hot dispensed</td>\n",
       "      <td>hot chocolate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>9c1a2048-7aac-4565-b836-d8d4f726322c</td>\n",
       "      <td>Crispy Golden Delight Chips</td>\n",
       "      <td>salty snacks</td>\n",
       "      <td>potato chips</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2465 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  \\\n",
       "0     6579c22f-be2b-444c-a52b-0116dd82df6c   \n",
       "1     2e852905-c6f4-47db-802c-654013571922   \n",
       "...                                    ...   \n",
       "2463  7000f6e7-41f7-4957-878a-ccc42a39ca59   \n",
       "2464  9c1a2048-7aac-4565-b836-d8d4f726322c   \n",
       "\n",
       "                                     name       category          style  \\\n",
       "0     Adventure-Ready Expedition Backpack    accessories       backpack   \n",
       "1                   Mauve Leather Daypack    accessories       backpack   \n",
       "...                                   ...            ...            ...   \n",
       "2463           Elegant Aroma Espresso Cup  hot dispensed  hot chocolate   \n",
       "2464          Crispy Golden Delight Chips   salty snacks   potato chips   \n",
       "\n",
       "     featured  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "...       ...  \n",
       "2463      NaN  \n",
       "2464      NaN  \n",
       "\n",
       "[2465 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the item meta data\n",
    "with open(item_metadata_file_name) as f:\n",
    "    item_metadata_df = pd.json_normalize(yaml.load(f, Loader=yaml.FullLoader))[['id', 'name', 'category', 'style', 'featured']]\n",
    "    \n",
    "display(item_metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Amazon Personalize Resources and Importing data <a class=\"anchor\" id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure an S3 bucket and an IAM  role <a class=\"anchor\" id=\"bucket_role\"></a>\n",
    "\n",
    "So far, we have downloaded, manipulated, and saved the data onto the Amazon EBS instance attached to the instance running this Jupyter notebook.  \n",
    "\n",
    "By default, the Personalize service does not have permission to access the data we upload into  S3 buckets in our account. In order to grant access to the Amazon Personalize service to interact with our S3 Buckets, we need to set a Bucket Policy and create an IAM role that the Amazon Personalize service will assume. If you are running this notebook without also running the Pretrained cloud formation template in the root folder then you will need to grant this Notebook substantial permissions in order to be able to run the code correctly.\n",
    "\n",
    "If you are running this with the pretrained cloud formation template `PersonalizeIDPretrained.yaml` then the notebook will not need that level of permissioning and will obtain the permissions from the bucket created as part of the automation process for demonstration.\n",
    "\n",
    "Use the metadata stored on the instance underlying this Amazon SageMaker notebook, to determine the region it is operating in. If you are using a Jupyter notebook outside of Amazon SageMaker, simply define the region as a string below. The Amazon S3 bucket needs to be in the same region as the Amazon Personalize resources we have been creating so far.\n",
    "\n",
    "First, let us get the current notebook region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "\n",
    "# To use a different region use:\n",
    "# region = <your_region>\n",
    "\n",
    "print('region:', region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon S3 bucket names are globally unique. To create a unique bucket name, the code below will append the string `personalize-poc-retail` to your AWS account number. Then it creates a bucket with this name in the region discovered in the previous cell. Note if you have already created a bucket as part of the cloud formation automation then the cell below will return information on that previously created bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bucket already exists.\n",
      "bucket_name: 809697808660-us-east-1-personalize-poc-retail\n"
     ]
    }
   ],
   "source": [
    "# Configure the SDK to SSM:\n",
    "ssm = boto3.client('ssm')\n",
    "s3 = boto3.client('s3')\n",
    "bucket_found = False\n",
    "try:\n",
    "    personalizes3bucket = ssm.get_parameter(Name='/cloudformation/personalize-s3-bucket', WithDecryption=False)\n",
    "    bucket_name = personalizes3bucket['Parameter']['Value']\n",
    "    print('Bucket created as part of cloud formation template found')\n",
    "    print('bucket_name:', bucket_name)\n",
    "    bucket_found=True\n",
    "except:\n",
    "    \n",
    "    account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "    bucket_name = account_id + \"-\" + region + \"-\" + \"personalize-poc-retail\"\n",
    "\n",
    "    #getting existing buckets in the account\n",
    "    response = s3.list_buckets()\n",
    "\n",
    "    if bucket_name in [x['Name'] for x in response['Buckets']]:\n",
    "        print(\"The bucket already exists.\")\n",
    "    else:\n",
    "        if region == \"us-east-1\":\n",
    "            bucket_responese = s3.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            bucket_responese = s3.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                )\n",
    "    print('bucket_name:', bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Personalize needs to be able to read the contents of your S3 bucket. The policy which enables personalize to access the contents of the S3 bucket is below.\n",
    "\n",
    "```python\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "This S3 bucket policy allows Amazon Personalize to be able to read the contents of your S3 bucket. The code below creates and adds the policy to the bucket it created in the last step. If the bucket was created as part of the automation script then it merely shows the bucket that it created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The policy is already associated with the S3 Bucket.\n"
     ]
    }
   ],
   "source": [
    "if bucket_found:\n",
    "    bucket_current_policy = s3.get_bucket_policy(Bucket=bucket_name)['Policy']\n",
    "    print(\"Policy for bucket created as part of cloud formation template:\")\n",
    "    print(json.loads(bucket_current_policy))\n",
    "else:\n",
    "    policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"personalize.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": [\n",
    "                    \"s3:GetObject\",\n",
    "                    \"s3:ListBucket\",\n",
    "                    \"s3:PutObject\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                    \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    bucket_current_policy = None\n",
    "\n",
    "    try:\n",
    "        bucket_current_policy = s3.get_bucket_policy(Bucket=bucket_name)['Policy']\n",
    "\n",
    "    except s3.exceptions.from_code('NoSuchBucketPolicy') as e:    \n",
    "        print(\"There is no current Bucket Policy for bucket \" + bucket_name)\n",
    "\n",
    "    except Exception as e: \n",
    "        raise(e)\n",
    "\n",
    "    if (bucket_current_policy and policy == json.loads(bucket_current_policy)):\n",
    "        print (\"The policy is already associated with the S3 Bucket.\")\n",
    "    else:\n",
    "        print (\"Adding the policy to the bucket.\")\n",
    "        print(s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an IAM role\n",
    "\n",
    "Amazon Personalize also needs the ability to assume roles in AWS in order to have the permissions to execute certain tasks. Let's create an IAM role and attach the required policies to it. The code below attaches broad policies. You should use [more restrictive, least-privilege policies for production applications](https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege). If you have run the cloud formation template the role will have been automatically created and we will simply obtain that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The policy arn:aws:iam::809697808660:policy/restrictedS3Access already exists.\n",
      "Using the existing policy\n",
      "Warning: role already exists: An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name 809697808660-PersonalizeS3-Immersion-Day already exists.\n",
      "IAM Role: arn:aws:iam::809697808660:role/809697808660-PersonalizeS3-Immersion-Day\n",
      "\n",
      "The policy arn:aws:iam::809697808660:policy/restrictedS3Access is already attached to this role.\n"
     ]
    }
   ],
   "source": [
    "if bucket_found:\n",
    "    print(\"Cloud formation template used - skipping creation of IAM role and needed policies for Personalize as they were already created as part of the automation script\")\n",
    "    role_arn_info = ssm.get_parameter(Name='/cloudformation/personalize-iam-role-arn', WithDecryption=False)\n",
    "    role_arn = role_arn_info['Parameter']['Value']\n",
    "    role_name = role_arn.split('/')[1]\n",
    "    s3_access_policy_arn = 'arn:aws:iam::{}:policy/restrictedS3Access'.format(account_id)\n",
    "else:\n",
    "    iam = boto3.client(\"iam\")\n",
    "\n",
    "    role_name = account_id+\"-PersonalizeS3-Immersion-Day\"\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "              },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Create policy\n",
    "\n",
    "    s3_access_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": {\n",
    "                \"Sid\" : \"myStatement\" ,\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Resource\": [\n",
    "                    \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                    \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "                ],\n",
    "                \"Action\": \"s3:*\"\n",
    "            }\n",
    "    }\n",
    "\n",
    "    try: \n",
    "\n",
    "        policy_response = iam.create_policy(\n",
    "            PolicyName='restrictedS3Access',\n",
    "            PolicyDocument=json.dumps(s3_access_policy_document),\n",
    "            Description='Restricts access to only workshop S3 bucket'\n",
    "        )\n",
    "\n",
    "        s3_access_policy_arn = policy_response['Policy']['Arn']\n",
    "\n",
    "        print (\"s3_access_policy_arn:{}\".format(s3_access_policy_arn))\n",
    "    except:\n",
    "        s3_access_policy_arn = 'arn:aws:iam::{}:policy/restrictedS3Access'.format(account_id)\n",
    "        print ('The policy {} already exists.'.format(s3_access_policy_arn))\n",
    "        print ('Using the existing policy')\n",
    "\n",
    "\n",
    "    try:\n",
    "        create_role_response = iam.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps(assume_role_policy_document),\n",
    "        );\n",
    "        role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "\n",
    "        print (\"10s pause to allow role to be fully consistent.\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    except iam.exceptions.EntityAlreadyExistsException as e:\n",
    "        print('Warning: role already exists:', e)\n",
    "        role_arn = iam.get_role(\n",
    "            RoleName = role_name\n",
    "        )[\"Role\"][\"Arn\"];\n",
    "\n",
    "    print('IAM Role: {}\\n'.format(role_arn))\n",
    "\n",
    "    # Attach the policy if it is not previously attached:\n",
    "    if (s3_access_policy_arn in [ x['PolicyArn'] for x in iam.list_attached_role_policies( RoleName = role_name)['AttachedPolicies']]):\n",
    "        print ('The policy {} is already attached to this role.'.format(s3_access_policy_arn))\n",
    "    else:\n",
    "        print (\"Attaching the role_policy: {}\".format(s3_access_policy_arn))\n",
    "        attach_response = iam.attach_role_policy(\n",
    "            RoleName = role_name,\n",
    "            PolicyArn = s3_access_policy_arn\n",
    "        );\n",
    "        print (\"30s pause to allow role to be fully consistent.\")\n",
    "        time.sleep(30)\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3\n",
    "\n",
    "Now that your Amazon S3 bucket has been created, upload the CSV files of our 3 datasets (Item, Interaction and User).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> NOTE: We will cover how to import real-time data in a future notebook..\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retail/interactions.csv already exists in the bucket 809697808660-us-east-1-personalize-poc-retail\n",
      "retail/items.csv already exists in the bucket 809697808660-us-east-1-personalize-poc-retail\n",
      "retail/users.csv already exists in the bucket 809697808660-us-east-1-personalize-poc-retail\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3.get_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=\"retail/interactions.csv\",\n",
    "    )\n",
    "    print(\"{} already exists in the bucket {}\".format(\"retail/interactions.csv\", bucket_name))\n",
    "except s3.exceptions.NoSuchKey:\n",
    "    # Uploading the file if it does not already exist\n",
    "    boto3.Session().resource('s3').Bucket(bucket_name).Object(\"retail/interactions.csv\").upload_file(\"./poc_data/data/interactions.csv\")\n",
    "    print(\"File {} uploaded to bucket {}\".format(\"retail/interactions.csv\", bucket_name))\n",
    "\n",
    "try:\n",
    "    s3.get_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=\"retail/items.csv\",\n",
    "    )\n",
    "    print(\"{} already exists in the bucket {}\".format(\"retail/items.csv\", bucket_name))\n",
    "except s3.exceptions.NoSuchKey:\n",
    "    # Uploading the file if it does not already exist     \n",
    "    boto3.Session().resource('s3').Bucket(bucket_name).Object(\"retail/items.csv\").upload_file(\"./poc_data/data/items.csv\")\n",
    "    print(\"File {} uploaded to bucket {}\".format(\"retail/items.csv\", bucket_name))\n",
    "\n",
    "try:\n",
    "    s3.get_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=\"retail/users.csv\",\n",
    "    )\n",
    "    print(\"{} already exists in the bucket {}\".format(\"retail/users.csv\", bucket_name))\n",
    "except s3.exceptions.NoSuchKey:\n",
    "    # Uploading the file if it does not already exist\n",
    "    boto3.Session().resource('s3').Bucket(bucket_name).Object(\"retail/users.csv\").upload_file(\"./poc_data/data/users.csv\")\n",
    "    print(\"File {} uploaded to bucket {}\".format(\"retail/users.csv\", bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset group <a class=\"anchor\" id=\"group_dataset\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "The highest level of isolation and abstraction with Amazon Personalize is a *dataset group*. Information stored within one of these dataset groups has no impact on any other dataset group or models created from one – they are completely isolated. This allows you to run many experiments and is part of how we keep your models private and fully trained only on your data. \n",
    "\n",
    "Before importing the data prepared earlier, there needs to be a dataset group and a dataset added to it that handles the interactions.\n",
    "\n",
    "Dataset groups can house the following types of information:\n",
    "\n",
    "* User-item-interactions\n",
    "* Event streams (real-time interactions)\n",
    "* User metadata\n",
    "* Item metadata\n",
    "\n",
    "We need to create the dataset group that will contain our three datasets.\n",
    "\n",
    "Your dataset group can be one of the following types:\n",
    "\n",
    "* A Domain dataset group, where you create preconfigured resources for different business domains and use cases, such as getting recommendations for similar videos (VIDEO_ON_DEMAND domain) or best selling items (ECOMMERCE domain). You choose your business domain, import your data, and create recommenders. You use recommenders in your application to get recommendations. Use a [Domain dataset group](https://docs.aws.amazon.com/personalize/latest/dg/domain-dataset-groups.html) if you have a video on demand or e-commerce application and want Amazon Personalize to find the best configurations for your use cases. If you start with a Domain dataset group, you can also add custom resources such as solutions with solution versions trained with recipes for custom use cases.\n",
    "\n",
    "\n",
    "* A [Custom dataset group](https://docs.aws.amazon.com/personalize/latest/dg/custom-dataset-groups.html), where you create configurable resources for custom use cases and batch recommendation workflows. You select a recipe, train a solution version (model), and deploy the solution version with a campaign. You use a campaign in your application to get recommendations. Use a Custom dataset group if you don't have a video on demand or e-commerce application or want to configure and manage only custom resources, or want to get recommendations in a batch workflow. If you start with a Custom dataset group, you can't associate it with a domain later. Instead, create a new Domain dataset group.\n",
    "\n",
    "You can create and manage Domain dataset groups and Custom dataset groups with the AWS console, the AWS Command Line Interface (AWS CLI), or programmatically with the AWS SDKs.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> If you are running this as part of an AWS workshop, the resources have been created ahead of time, this is to eliminate the time spent waiting for the data to import, models to train and recommenders to deploy. In these notebooks will check to see if the resources exist and use them. You may see “Resource X Already exists” messages, if you run these notebooks in your own account, it will create these resources, which will add approximately 90 minutes to this workshop.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Group\n",
    "The following cell will create a new dataset group with the name `personalize-poc-retail`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The the Dataset Group with dataset_group_arn = arn:aws:personalize:us-east-1:809697808660:dataset-group/personalize-immersion-day-retail already exists\n",
      "\n",
      "We will be using the existing Dataset Group dataset_group_arn = arn:aws:personalize:us-east-1:809697808660:dataset-group/personalize-immersion-day-retail\n"
     ]
    }
   ],
   "source": [
    "try:     \n",
    "    # Try to create the dataset group, this block with exectute fully if the dataset group does not exist yet\n",
    "    \n",
    "    create_dataset_group_response = personalize.create_dataset_group(\n",
    "        name = workshop_dataset_group_name,\n",
    "        domain='ECOMMERCE'\n",
    "    )\n",
    "    workshop_dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "    print(json.dumps(create_dataset_group_response, indent=2))\n",
    "    print ('\\nCreating the Dataset Group with dataset_group_arn = {}'.format(workshop_dataset_group_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException as e:\n",
    "    # if the dataset group already exists, get the unique identifier workshop_dataset_group_arn \n",
    "    # from the existing resource\n",
    "    \n",
    "    workshop_dataset_group_arn = 'arn:aws:personalize:'+region+':'+account_id+':dataset-group/'+workshop_dataset_group_name \n",
    "    print ('\\nThe the Dataset Group with dataset_group_arn = {} already exists'.format(workshop_dataset_group_arn))\n",
    "    print ('\\nWe will be using the existing Dataset Group dataset_group_arn = {}'.format(workshop_dataset_group_arn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Dataset Group to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the dataset group, it must be active. This can take a minute or two. Execute the cell below and wait for it to show the ACTIVE status. It checks the status of the dataset group every 60 seconds, up to a maximum of 3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = workshop_dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a dataset group, you can create a dataset for the interaction data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Interactions Schema <a class=\"anchor\" id=\"interact_schema\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Now that we've loaded and prepared our three datasets, we'll need to configure the Amazon Personalize service to understand our data so that it can be used to train models for generating recommendations. Amazon Personalize requires a schema for each dataset, so it can map the columns in our CSVs to fields for model training. Each schema is declared in JSON using the [Apache Avro](https://avro.apache.org/) format. \n",
    "\n",
    "First, define a schema to tell Amazon Personalize what type of dataset you are uploading. There are several reserved and mandatory keywords required in the schema, based on the type of dataset. More detailed information can be found in the [documentation](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html).\n",
    "\n",
    "Here, you will create a schema for interactions data, which requires the `USER_ID`, `ITEM_ID`, and `TIMESTAMP` fields. These must be defined in the same order in the schema as they appear in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset we also have an `EVENT_TYPE` column that includes multiple common eCommerce event types (`View`, `AddToCart`, `Purchase`, and so on).\n",
    "\n",
    "The interactions dataset supports metadata columns. Interaction metadata columns are a way to provide contextual details that are specific to an interaction, such as the user's current device type (phone, tablet, desktop, set-top box, etc), the user's current location (city, region, metro code, etc), current weather conditions, and so on. For this dataset, we have a `DISCOUNT` column that indicates whether the user is interacting with an item that is currently discounted (`Yes`/`No`). It's being used to learn a user's affinity for items that are on sale or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The schema arn:aws:personalize:us-east-1:809697808660:schema/workshop_retail_interactions_schema already exists.\n",
      "\n",
      "We will be using the existing Interactions Schema with workshop_interactions_schema_arn = arn:aws:personalize:us-east-1:809697808660:schema/workshop_retail_interactions_schema\n"
     ]
    }
   ],
   "source": [
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_TYPE\",  # \"View\", \"Purchase\", etc.\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"DISCOUNT\",  # This is the contextual metadata - \"Yes\" or \"No\".\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True,\n",
    "        },\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Try to create the interactions dataset schema, this block with exectute fully \n",
    "    # if the interactions dataset schema does not exist yet\n",
    "    create_schema_response = personalize.create_schema(\n",
    "        name = interactions_schema_name,\n",
    "        schema = json.dumps(interactions_schema),\n",
    "        domain='ECOMMERCE'\n",
    "    )\n",
    "    print(json.dumps(create_schema_response, indent=2))\n",
    "    workshop_interactions_schema_arn = create_schema_response['schemaArn']\n",
    "    print ('\\nCreating the Interactions Schema with workshop_interactions_schema_arn = {}'.format(workshop_interactions_schema_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException:\n",
    "    # if the interactions dataset schema already exists, get the unique identifier workshop_interactions_schema_arn\n",
    "    # from the existing resource \n",
    "    \n",
    "    workshop_interactions_schema_arn = 'arn:aws:personalize:'+region+':'+account_id+':schema/'+interactions_schema_name \n",
    "    print('The schema {} already exists.'.format(workshop_interactions_schema_arn))\n",
    "    print ('\\nWe will be using the existing Interactions Schema with workshop_interactions_schema_arn = {}'.format(workshop_interactions_schema_arn))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the interactions dataset\n",
    "\n",
    "With a schema created, you can create a dataset within the dataset group. Note that this does not load the data yet, but creates a schema of what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Interactions Dataset arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/INTERACTIONS already exists.\n",
      "\n",
      "We will be using the existing Interactions Dataset with workshop_interactions_dataset_arn = arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/INTERACTIONS\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try to create the interactions dataset, this block with exectute fully \n",
    "    # if the interactions dataset does not exist yet\n",
    "    \n",
    "    dataset_type = 'INTERACTIONS'\n",
    "    create_dataset_response = personalize.create_dataset(\n",
    "        name = interactions_dataset_name,\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = workshop_dataset_group_arn,\n",
    "        schemaArn = workshop_interactions_schema_arn\n",
    "    )\n",
    "\n",
    "    workshop_interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "    print(json.dumps(create_dataset_response, indent=2))\n",
    "    print ('\\nCreating the Interactions Dataset with workshop_interactions_dataset_arn = {}'.format(workshop_interactions_dataset_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException:\n",
    "    # if the interactions dataset already exists, get the unique identifier workshop_interactions_dataset_arn \n",
    "    # from the existing resource \n",
    "    workshop_interactions_dataset_arn =  'arn:aws:personalize:'+region+':'+account_id+':dataset/'+workshop_dataset_group_name+'/INTERACTIONS'\n",
    "    print('The Interactions Dataset {} already exists.'.format(workshop_interactions_dataset_arn))\n",
    "    print ('\\nWe will be using the existing Interactions Dataset with workshop_interactions_dataset_arn = {}'.format(workshop_interactions_dataset_arn))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Items (Products) schema<a class=\"anchor\" id=\"items_schema\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "First, define a schema to tell Amazon Personalize what type of dataset you are uploading. There are several reserved and mandatory keywords required in the schema, based on the type of dataset. More detailed information can be found in the [documentation](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html).\n",
    "\n",
    "The items dataset schema requires an `ITEM_ID` column and at least one metadata column. Up to 50 metadata columns can be added to the items dataset.\n",
    "\n",
    "For this dataset we have three metadata columns: `PRICE`, `CATEGORY_L1`, `CATEGORY_L2`, `PRODUCT_DESCRIPTION`, and `GENDER` (see schema definition in the cell below). \n",
    "\n",
    "We mapped the `category` and `style` fields from the items catalog to the `CATEGORY_L1` and `CATEGORY_L2` columns to indicate category levels. The `gender_affinity` field used to indicate Women's and Men's products (clothing, footwear, etc.) has been mapped to the `GENDER` column in the schema. \n",
    "\n",
    "Note that `CATEGORY_L1`, `CATEGORY_L2`, and `GENDER` are annotated as being categorical (`\"categorical\": true`). This tells Personalize to interpret the column value for each row as one or more categorical values, where the `|` character can be used to separate values. For example, `value1|value2|value3`. The `PRODUCT_DESCRIPTION` column is annotated as being a text column (`\"textual\": true`). This tells Personalize that this column contains unstructured text. A natural language processing (NLP) model is used to extract features from the textual column to use as features in the model. Including a textual column in your items dataset can significantly enhance the relevancy of recommendations. Currently, only one textual column can be included in the items dataset and the text must be in English. For more information, please refer to [the documentation](https://docs.aws.amazon.com/personalize/latest/dg/items-datasets.html#text-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The schema arn:aws:personalize:us-east-1:809697808660:schema/workshop_retail_items_schema already exists.\n",
      "\n",
      "We will be using the existing Items Schema with workshop_items_schema_arn = arn:aws:personalize:us-east-1:809697808660:schema/workshop_retail_items_schema\n"
     ]
    }
   ],
   "source": [
    "items_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Items\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRICE\",\n",
    "            \"type\": \"float\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CATEGORY_L1\",\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CATEGORY_L2\",\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRODUCT_DESCRIPTION\",\n",
    "            \"type\": \"string\",\n",
    "            \"textual\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"GENDER\",\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Try to create the items dataset schema, this block with exectute fully \n",
    "    # if the items dataset schema does not exist yet\n",
    "    \n",
    "    create_schema_response = personalize.create_schema(\n",
    "        name = items_schema_name,\n",
    "        schema = json.dumps(items_schema),\n",
    "        domain='ECOMMERCE'\n",
    "    )\n",
    "    workshop_items_schema_arn = create_schema_response['schemaArn']\n",
    "    print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "    print ('\\nCreating the Items Schema with workshop_items_schema_arn = {}'.format(workshop_items_schema_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException:\n",
    "    # if the items dataset schema already exists, get the unique identifier workshop_items_schema_arn \n",
    "    # from the existing resource \n",
    "    \n",
    "    workshop_items_schema_arn = 'arn:aws:personalize:'+region+':'+account_id+':schema/'+items_schema_name \n",
    "    print('The schema {} already exists.'.format(workshop_items_schema_arn))\n",
    "    print ('\\nWe will be using the existing Items Schema with workshop_items_schema_arn = {}'.format(workshop_items_schema_arn))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Items Dataset\n",
    "With a schema created, you can create a dataset within the dataset group. Note that this does not load the data yet, but creates a schema of what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Items Dataset arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/ITEMS already exists.\n",
      "\n",
      "We will be using the existing Items Dataset with workshop_items_dataset_arn = arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/ITEMS\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try to create the items dataset, this block with execute fully if the items dataset does not exist yet\n",
    "    \n",
    "    dataset_type = \"ITEMS\"\n",
    "    create_dataset_response = personalize.create_dataset(\n",
    "        name = items_dataset_name,\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = workshop_dataset_group_arn,\n",
    "        schemaArn = workshop_items_schema_arn\n",
    "    )\n",
    "\n",
    "    workshop_items_dataset_arn = create_dataset_response['datasetArn']\n",
    "    print(json.dumps(create_dataset_response, indent=2))\n",
    "\n",
    "    print ('\\nCreating the Items Dataset with workshop_items_dataset_arn = {}'.format(workshop_items_dataset_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException:\n",
    "    # if the items dataset already exists, get the unique identifier workshop_items_dataset_arn \n",
    "    # from the existing resource \n",
    "    \n",
    "    workshop_items_dataset_arn =  'arn:aws:personalize:'+region+':'+account_id+':dataset/'+workshop_dataset_group_name+'/ITEMS'\n",
    "    print('The Items Dataset {} already exists.'.format(workshop_items_dataset_arn))\n",
    "    print ('\\nWe will be using the existing Items Dataset with workshop_items_dataset_arn = {}'.format(workshop_items_dataset_arn))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Users schema<a class=\"anchor\" id=\"users_schema\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "First, define a schema to tell Amazon Personalize what type of dataset you are uploading. There are several reserved and mandatory keywords required in the schema, based on the type of dataset. More detailed information can be found in the [documentation](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html).\n",
    "\n",
    "Here, you will create a schema for user data, which requires the `USER_ID`, and an additonal metadata field. For this dataset we have metadata columns for `AGE` and `GENDER`. These must be defined in the same order in the schema as they appear in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The schema arn:aws:personalize:us-east-1:809697808660:schema/workshop_retail_users_schema already exists.\n",
      "\n",
      "We will be using the existing Users Schema with workshop_users_schema_arn = arn:aws:personalize:us-east-1:809697808660:schema/workshop_retail_users_schema\n"
     ]
    }
   ],
   "source": [
    "users_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AGE\",\n",
    "            \"type\": \"int\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"GENDER\",\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True,\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Try to create the users dataset schema, this block with exectute fully \n",
    "    # if the users dataset schema does not exist yet\n",
    "    \n",
    "    create_schema_response = personalize.create_schema(\n",
    "        name = users_schema_name,\n",
    "        schema = json.dumps(users_schema),\n",
    "        domain='ECOMMERCE'\n",
    "    )\n",
    "    \n",
    "    workshop_users_schema_arn = create_schema_response['schemaArn']\n",
    "    print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "    print ('\\nCreating the Users Schema with workshop_users_schema_arn = {}'.format(workshop_users_schema_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException:\n",
    "    # if the users dataset schema already exists, get the unique identifier workshop_users_schema_arn \n",
    "    # from the existing resource \n",
    "\n",
    "    workshop_users_schema_arn = 'arn:aws:personalize:'+region+':'+account_id+':schema/'+users_schema_name \n",
    "    print('The schema {} already exists.'.format(workshop_users_schema_arn))\n",
    "    print ('\\nWe will be using the existing Users Schema with workshop_users_schema_arn = {}'.format(workshop_users_schema_arn))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Users Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Users Dataset arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/USERS already exists.\n",
      "\n",
      "We will be using the existing Users Dataset with workshop_users_dataset_arn = arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/USERS\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try to create the users dataset, this block with exectute fully if the users dataset does not exist yet\n",
    "    \n",
    "    dataset_type = \"USERS\"\n",
    "    create_dataset_response = personalize.create_dataset(\n",
    "        name = users_dataset_name,\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = workshop_dataset_group_arn,\n",
    "        schemaArn = workshop_users_schema_arn\n",
    "    )\n",
    "\n",
    "    workshop_users_dataset_arn = create_dataset_response['datasetArn']\n",
    "    print(json.dumps(create_dataset_response, indent=2))\n",
    "\n",
    "    print ('\\nCreating the Users Dataset with workshop_users_dataset_arn = {}'.format(workshop_users_dataset_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException:\n",
    "    # if the users dataset already exists, get the unique identifier workshop_users_dataset_arn\n",
    "    # from the existing resource \n",
    "    \n",
    "    workshop_users_dataset_arn =  'arn:aws:personalize:'+region+':'+account_id+':dataset/'+workshop_dataset_group_name+'/USERS'\n",
    "    print('The Users Dataset {} already exists.'.format(workshop_users_dataset_arn))\n",
    "    print ('\\nWe will be using the existing Users Dataset with workshop_users_dataset_arn = {}'.format(workshop_users_dataset_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wait untill all the datasets have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions Dataset: ACTIVE\n",
      "Build succeeded for arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/INTERACTIONS\n",
      "The interaction dataset  is ACTIVE\n",
      "Items Dataset: ACTIVE\n",
      "Build succeeded for arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/ITEMS\n",
      "The item dataset  is ACTIVE\n",
      "Users Dataset: ACTIVE\n",
      "Build succeeded for arn:aws:personalize:us-east-1:809697808660:dataset/personalize-immersion-day-retail/USERS\n",
      "The user dataset  is ACTIVE\n",
      "CPU times: user 8.73 ms, sys: 117 μs, total: 8.84 ms\n",
      "Wall time: 70.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 6*60*60 # 6 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_response = personalize.describe_dataset(\n",
    "        datasetArn = workshop_interactions_dataset_arn\n",
    "    )\n",
    "    status_interaction_dataset =  describe_dataset_response[\"dataset\"]['status']\n",
    "    print(\"Interactions Dataset: {}\".format(status_interaction_dataset))\n",
    "    \n",
    "    if status_interaction_dataset == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_interactions_dataset_arn))\n",
    "        \n",
    "    elif status_interaction_dataset == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_interactions_dataset_arn))\n",
    "        break\n",
    "        \n",
    "    if not status_interaction_dataset == \"ACTIVE\":\n",
    "        print(\"The interaction dataset creation is still in progress\")\n",
    "    else:\n",
    "        print(\"The interaction dataset  is ACTIVE\")\n",
    "        \n",
    "\n",
    "    describe_dataset_response = personalize.describe_dataset(\n",
    "        datasetArn = workshop_items_dataset_arn\n",
    "    )\n",
    "    status_item_dataset =  describe_dataset_response[\"dataset\"]['status']\n",
    "    print(\"Items Dataset: {}\".format(status_item_dataset))\n",
    "    \n",
    "    if status_item_dataset == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_items_dataset_arn))\n",
    "        \n",
    "    elif status_item_dataset == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_items_dataset_arn))\n",
    "        break\n",
    "        \n",
    "    if not status_item_dataset == \"ACTIVE\":\n",
    "        print(\"The item dataset creation is still in progress\")\n",
    "    else:\n",
    "        print(\"The item dataset  is ACTIVE\")\n",
    "    \n",
    "    describe_dataset_response = personalize.describe_dataset(\n",
    "        datasetArn = workshop_users_dataset_arn\n",
    "    )\n",
    "    status_user_dataset =  describe_dataset_response[\"dataset\"]['status']\n",
    "    print(\"Users Dataset: {}\".format(status_user_dataset))\n",
    "    \n",
    "    if status_user_dataset == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_users_dataset_arn))\n",
    "        \n",
    "    elif status_user_dataset == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_users_dataset_arn))\n",
    "        break\n",
    "        \n",
    "    if not status_user_dataset == \"ACTIVE\":\n",
    "        print(\"The user dataset creation is still in progress\")\n",
    "    else:\n",
    "        print(\"The user dataset  is ACTIVE\")\n",
    "    \n",
    "    if status_interaction_dataset == \"ACTIVE\" and status_item_dataset == \"ACTIVE\" and status_user_dataset == 'ACTIVE':\n",
    "        break\n",
    "        \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Interactions <a class=\"anchor\" id=\"import_interactions\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Earlier you created the dataset group and dataset to house your information, now you will execute an import job that will load the item data from the S3 bucket into the Amazon Personalize dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Interactions Import Job arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_interaction already exists.\n",
      "\n",
      "We will be using the existing Interactions Import Job with workshop_interactions_dataset_import_job_arn = arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_interaction\n"
     ]
    }
   ],
   "source": [
    "# Check if the import job already exists\n",
    "\n",
    "# List the import jobs\n",
    "interactions_dataset_import_jobs = personalize.list_dataset_import_jobs(\n",
    "    datasetArn=workshop_interactions_dataset_arn,\n",
    "    maxResults=100\n",
    ")['datasetImportJobs']\n",
    "\n",
    "#check if there is an existing job with the prefix\n",
    "job_exists = False  \n",
    "job_arn = None\n",
    "\n",
    "for job in interactions_dataset_import_jobs:\n",
    "    if (interactions_import_job_name in job['jobName']):\n",
    "        job_exists = True\n",
    "        job_arn = job['datasetImportJobArn']\n",
    "    \n",
    "if (job_exists):\n",
    "    workshop_interactions_dataset_import_job_arn = job_arn\n",
    "    print('The Interactions Import Job {} already exists.'.format(workshop_interactions_dataset_import_job_arn))\n",
    "    print ('\\nWe will be using the existing Interactions Import Job with workshop_interactions_dataset_import_job_arn = {}'.format(workshop_interactions_dataset_import_job_arn))\n",
    "        \n",
    "else:\n",
    "    # If there is no import job with the prefix, create it:   \n",
    "    create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "        jobName = interactions_import_job_name,\n",
    "        datasetArn = workshop_interactions_dataset_arn,\n",
    "        dataSource = {\n",
    "            \"dataLocation\": \"s3://{}/{}\".format(bucket_name, \"retail/interactions.csv\")\n",
    "        },\n",
    "        roleArn = role_arn\n",
    "    )\n",
    "    workshop_interactions_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "    print(json.dumps(create_dataset_import_job_response, indent=2))\n",
    "    \n",
    "    print ('\\nImporting the Interactions Data with workshop_interactions_dataset_import_job_arn = {}'.format(workshop_interactions_dataset_import_job_arn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Item Metadata <a class=\"anchor\" id=\"import_items\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Earlier you created the dataset group and dataset to house your information, now you will execute an import job that will load the item data from the S3 bucket into the Amazon Personalize dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Items Import Job arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_item already exists.\n",
      "\n",
      "We will be using the existing Items Import Job with workshop_items_dataset_import_job_arn = arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_item\n"
     ]
    }
   ],
   "source": [
    "# Checking if the import job already exists\n",
    "\n",
    "# List the import jobs\n",
    "items_dataset_import_jobs = personalize.list_dataset_import_jobs(\n",
    "    datasetArn=workshop_items_dataset_arn,\n",
    "    maxResults=100\n",
    ")['datasetImportJobs']\n",
    "\n",
    "job_exists = False\n",
    "job_arn = None\n",
    "\n",
    "#check if there is an existing job with the prefix\n",
    "for job in items_dataset_import_jobs:\n",
    "    if (items_import_job_name in job['jobName']):\n",
    "        job_exists = True\n",
    "        job_arn = job['datasetImportJobArn']\n",
    "    \n",
    "if (job_exists):\n",
    "    workshop_items_dataset_import_job_arn =  job_arn\n",
    "    print('The Items Import Job {} already exists.'.format(workshop_items_dataset_import_job_arn))\n",
    "    print ('\\nWe will be using the existing Items Import Job with workshop_items_dataset_import_job_arn = {}'.format(workshop_items_dataset_import_job_arn))\n",
    "        \n",
    "else:\n",
    "    # If there is no import job with the prefix, create it:    \n",
    "    create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "        jobName = items_import_job_name,\n",
    "        datasetArn = workshop_items_dataset_arn,\n",
    "        dataSource = {\n",
    "            \"dataLocation\": \"s3://{}/{}\".format(bucket_name, \"retail/items.csv\")\n",
    "        },\n",
    "        roleArn = role_arn\n",
    "    )\n",
    "\n",
    "    workshop_items_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "    print(json.dumps(create_dataset_import_job_response, indent=2))\n",
    "    print ('\\nImporting the Items Data with workshop_items_dataset_import_job_arn = {}'.format(workshop_items_dataset_import_job_arn))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the User Metadata <a class=\"anchor\" id=\"import_users\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Earlier you created the dataset group and dataset to house your information, now you will execute an import job that will load the user data from the S3 bucket into the Amazon Personalize dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Users Import Job arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_user already exists.\n",
      "\n",
      "We will be using the existing Users Import Job with workshop_users_dataset_import_job_arn = arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_user\n"
     ]
    }
   ],
   "source": [
    "# Checking if the import job already exists\n",
    "\n",
    "# List the import jobs\n",
    "users_dataset_import_jobs = personalize.list_dataset_import_jobs(\n",
    "    datasetArn=workshop_users_dataset_arn,\n",
    "    maxResults=100\n",
    ")['datasetImportJobs']\n",
    "\n",
    "#check if there is an existing job with the prefix\n",
    "job_exists = False \n",
    "job_arn = None      \n",
    "for job in users_dataset_import_jobs:\n",
    "    if (users_import_job_name in job['jobName']):\n",
    "        job_exists = True\n",
    "        job_arn = job['datasetImportJobArn']\n",
    "\n",
    "if (job_exists):\n",
    "    workshop_users_dataset_import_job_arn =  job_arn\n",
    "    print('The Users Import Job {} already exists.'.format(workshop_users_dataset_import_job_arn))\n",
    "    print ('\\nWe will be using the existing Users Import Job with workshop_users_dataset_import_job_arn = {}'.format(workshop_users_dataset_import_job_arn))\n",
    "        \n",
    "else:\n",
    "    # If there is no import job with the prefix, create it:  \n",
    "    create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "        jobName = users_import_job_name,\n",
    "        datasetArn = workshop_users_dataset_arn,\n",
    "        dataSource = {\n",
    "            \"dataLocation\": \"s3://{}/{}\".format(bucket_name, \"retail/users.csv\")\n",
    "        },\n",
    "        roleArn = role_arn\n",
    "    )\n",
    "\n",
    "    workshop_users_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "    print(json.dumps(create_dataset_import_job_response, indent=2))\n",
    "    \n",
    "    print ('\\nImporting the Users Data with workshop_users_dataset_import_job_arn = {}'.format(workshop_users_dataset_import_job_arn))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for Import Jobs to Complete\n",
    "\n",
    "Before we can use the dataset, the import job must be active. Execute the cell below and wait for it to show the ACTIVE status. It checks the status of the import job every minute, up to a maximum of 6 hours.\n",
    "\n",
    "It will take 10-15 minutes for the import jobs to complete. While you're waiting you can learn more about Datasets and Schemas in [the documentation](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html).\n",
    "\n",
    "We will wait for all three jobs to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build succeeded for arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_interaction\n",
      "The interactions dataset import is ACTIVE\n",
      "Build succeeded for arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_item\n",
      "The items dataset import is ACTIVE\n",
      "Build succeeded for arn:aws:personalize:us-east-1:809697808660:dataset-import-job/dataset_import_user\n",
      "The user dataset import is ACTIVE\n"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 6*60*60 # 10 hours\n",
    "while time.time() < max_time:\n",
    "\n",
    "    # Interactions dataset import\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = workshop_interactions_dataset_import_job_arn\n",
    "    )\n",
    "    status_interactions_import = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    \n",
    "    if status_interactions_import == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_interactions_dataset_import_job_arn))\n",
    "        \n",
    "    elif status_interactions_import == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_interactions_dataset_import_job_arn))\n",
    "        break\n",
    "        \n",
    "    if not status_interactions_import == \"ACTIVE\":\n",
    "        print(\"The interactions dataset import is still in progress\")\n",
    "    else:\n",
    "        print(\"The interactions dataset import is ACTIVE\")\n",
    "\n",
    "    # Items dataset import\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = workshop_items_dataset_import_job_arn\n",
    "    )\n",
    "    status_items_import = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    \n",
    "    if status_items_import == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_items_dataset_import_job_arn))\n",
    "        \n",
    "    elif status_items_import == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_items_dataset_import_job_arn))\n",
    "        break\n",
    "        \n",
    "    if not status_items_import == \"ACTIVE\":\n",
    "        print(\"The items dataset import is still in progress\")\n",
    "    else:\n",
    "        print(\"The items dataset import is ACTIVE\")\n",
    "        \n",
    "        \n",
    "   # Users dataset import  \n",
    "    describe_users_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = workshop_users_dataset_import_job_arn\n",
    "    )\n",
    "    status_users_import = describe_users_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    \n",
    "    if status_users_import == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_users_dataset_import_job_arn))\n",
    "        \n",
    "    elif status_users_import == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_users_dataset_import_job_arn))\n",
    "        break\n",
    "        \n",
    "    if not status_users_import == \"ACTIVE\":\n",
    "        print(\"The user dataset import is still in progress\")\n",
    "    else:\n",
    "        print(\"The user dataset import is ACTIVE\")\n",
    "        \n",
    "\n",
    "    if status_interactions_import == \"ACTIVE\" and status_items_import == 'ACTIVE' and status_users_import  == 'ACTIVE':\n",
    "        break\n",
    "\n",
    "    print()\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all imports now complete you can  start training recommenders and solutions. Run the cell below before moving on to store a few values for usage in the next notebooks. After completing that cell open notebook `02_Training_Layer.ipynb` to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Useful Variables <a class=\"anchor\" id=\"vars\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Before exiting this notebook, run the following cells to save the version ARNs for use in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_dir' (str)\n",
      "Stored 'workshop_dataset_group_arn' (str)\n",
      "Stored 'workshop_interactions_dataset_arn' (str)\n",
      "Stored 'workshop_items_dataset_arn' (str)\n",
      "Stored 'workshop_users_dataset_arn' (str)\n",
      "Stored 'workshop_interactions_schema_arn' (str)\n",
      "Stored 'workshop_items_schema_arn' (str)\n",
      "Stored 'workshop_users_schema_arn' (str)\n",
      "Stored 'workshop_rerank_solution_name' (str)\n",
      "Stored 'workshop_rerank_campaign_name' (str)\n",
      "Stored 'recommender_customers_who_viewed_name' (str)\n",
      "Stored 'recommender_recommended_for_you_name' (str)\n",
      "Stored 'region' (str)\n",
      "Stored 'account_id' (str)\n",
      "Stored 'role_name' (str)\n",
      "Stored 'role_arn' (str)\n",
      "Stored 'bucket_name' (str)\n",
      "Stored 'item_metadata_df' (DataFrame)\n",
      "Stored 'user_metadata_df' (DataFrame)\n",
      "Stored 's3_access_policy_arn' (str)\n"
     ]
    }
   ],
   "source": [
    "%store data_dir\n",
    "%store workshop_dataset_group_arn\n",
    "%store workshop_interactions_dataset_arn\n",
    "%store workshop_items_dataset_arn\n",
    "%store workshop_users_dataset_arn\n",
    "%store workshop_interactions_schema_arn\n",
    "%store workshop_items_schema_arn\n",
    "%store workshop_users_schema_arn\n",
    "%store workshop_rerank_solution_name\n",
    "%store workshop_rerank_campaign_name\n",
    "\n",
    "%store recommender_customers_who_viewed_name\n",
    "%store recommender_recommended_for_you_name\n",
    "\n",
    "%store region\n",
    "%store account_id\n",
    "%store role_name\n",
    "%store role_arn\n",
    "\n",
    "%store bucket_name\n",
    "\n",
    "%store item_metadata_df\n",
    "%store user_metadata_df\n",
    "\n",
    "%store s3_access_policy_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to the next notebook `Retail_02_Training_Layer.ipynb`](Retail_02_Training_Layer.ipynb) to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
